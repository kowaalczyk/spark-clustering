

Container: container_1586849858644_0008_02_000001 on 178.62.198.251_42461
===========================================================================
LogType:pyspark.log
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:1402
Log Contents:
[PYTHON] 2020-04-14 08:20:04,714.714 INFO clustering - wrapper: perform_experiment keyword arguments:
[PYTHON] 2020-04-14 08:20:04,714.714 INFO clustering - wrapper: in_files: ['/data/df_5-shingles_sparse-count-vectors.parquet']
[PYTHON] 2020-04-14 08:20:04,714.714 INFO clustering - wrapper: distances: ['cosine', 'euclidean']
[PYTHON] 2020-04-14 08:20:04,714.714 INFO clustering - wrapper: ks: [2, 4, 6]
[PYTHON] 2020-04-14 08:20:04,714.714 INFO clustering - wrapper: models: [<class 'pyspark.ml.clustering.KMeans'>, <class 'pyspark.ml.clustering.BisectingKMeans'>]
[PYTHON] 2020-04-14 08:20:04,714.714 INFO clustering - wrapper: result_dfs_list: []
[PYTHON] 2020-04-14 08:20:04,714.714 INFO clustering - wrapper: perform_clustering_kmeans keyword arguments:
[PYTHON] 2020-04-14 08:20:04,714.714 INFO clustering - wrapper: in_file: /data/df_5-shingles_sparse-count-vectors.parquet
[PYTHON] 2020-04-14 08:20:04,714.714 INFO clustering - wrapper: distance: cosine
[PYTHON] 2020-04-14 08:20:04,714.714 INFO clustering - wrapper: k: 2
[PYTHON] 2020-04-14 08:20:04,714.714 INFO clustering - wrapper: ModelCls: <class 'pyspark.ml.clustering.KMeans'>
[PYTHON] 2020-04-14 08:20:04,716.716 INFO clustering - read_and_repartition: reading /data/df_5-shingles_sparse-count-vectors.parquet into 18 partitions
[PYTHON] 2020-04-14 08:20:07,929.929 INFO clustering - wrapper: read_and_repartition finished in 3.21s
End of LogType:pyspark.log

LogType:stderr
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:79015
Log Contents:
20/04/14 08:19:56 INFO util.SignalUtils: Registered signal handler for TERM
20/04/14 08:19:56 INFO util.SignalUtils: Registered signal handler for HUP
20/04/14 08:19:56 INFO util.SignalUtils: Registered signal handler for INT
20/04/14 08:19:56 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:19:56 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:19:56 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:19:56 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:19:56 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:19:57 INFO yarn.ApplicationMaster: Preparing Local resources
20/04/14 08:19:57 INFO yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1586849858644_0008_000002
20/04/14 08:19:57 INFO yarn.ApplicationMaster: Starting the user application in a separate Thread
20/04/14 08:19:57 INFO yarn.ApplicationMaster: Waiting for spark context initialization...
20/04/14 08:19:58 INFO spark.SparkContext: Running Spark version 2.4.5
20/04/14 08:19:58 INFO spark.SparkContext: Submitted application: ClusteringExperiment
20/04/14 08:19:58 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:19:58 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:19:58 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:19:58 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:19:58 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:19:58 INFO util.Utils: Successfully started service 'sparkDriver' on port 42739.
20/04/14 08:19:58 INFO spark.SparkEnv: Registering MapOutputTracker
20/04/14 08:19:58 INFO spark.SparkEnv: Registering BlockManagerMaster
20/04/14 08:19:58 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/04/14 08:19:58 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/04/14 08:19:58 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/blockmgr-a1af5b08-dcd0-4746-8e2e-8160e373be4a
20/04/14 08:19:58 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/14 08:19:58 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/04/14 08:19:58 INFO util.log: Logging initialized @2714ms
20/04/14 08:19:58 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/04/14 08:19:58 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
20/04/14 08:19:58 INFO server.Server: Started @2783ms
20/04/14 08:19:58 INFO server.AbstractConnector: Started ServerConnector@12b46e14{HTTP/1.1,[http/1.1]}{0.0.0.0:32915}
20/04/14 08:19:58 INFO util.Utils: Successfully started service 'SparkUI' on port 32915.
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7102c8bd{/jobs,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@24099e37{/jobs/json,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@622d06ac{/jobs/job,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@53d9d3af{/jobs/job/json,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3bc907c5{/stages,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@31db6e76{/stages/json,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c33988e{/stages/stage,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@582ccc2e{/stages/stage/json,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@181bd84d{/stages/pool,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@a83dd5e{/stages/pool/json,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4dccb0b1{/storage,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@73bf489a{/storage/json,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35202f10{/storage/rdd,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@215d6dc7{/storage/rdd/json,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@93c1865{/environment,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4e7a40{/environment/json,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@34229df6{/executors,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7edbede0{/executors/json,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@17cd2d6e{/executors/threadDump,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@64a2d9ad{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44cf35e2{/static,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6b24214b{/,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@693f0f3f{/api,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48fb159b{/jobs/job/kill,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d39e373{/stages/stage/kill,null,AVAILABLE,@Spark}
20/04/14 08:19:58 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://178.62.198.251:32915
20/04/14 08:19:58 INFO cluster.YarnClusterScheduler: Created YarnClusterScheduler
20/04/14 08:19:58 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1586849858644_0008 and attemptId Some(appattempt_1586849858644_0008_000002)
20/04/14 08:19:58 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36493.
20/04/14 08:19:58 INFO netty.NettyBlockTransferService: Server created on 178.62.198.251:36493
20/04/14 08:19:58 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/14 08:19:58 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 178.62.198.251, 36493, None)
20/04/14 08:19:58 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.198.251:36493 with 3.0 GB RAM, BlockManagerId(driver, 178.62.198.251, 36493, None)
20/04/14 08:19:58 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 178.62.198.251, 36493, None)
20/04/14 08:19:58 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 178.62.198.251, 36493, None)
20/04/14 08:19:59 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/04/14 08:19:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@320353f0{/metrics/json,null,AVAILABLE,@Spark}
20/04/14 08:19:59 INFO client.RMProxy: Connecting to ResourceManager at /178.62.197.79:8030
20/04/14 08:19:59 INFO yarn.YarnRMClient: Registering the ApplicationMaster
20/04/14 08:19:59 INFO yarn.ApplicationMaster: 
===============================================================================
YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>$HADOOP_CONF_DIR<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/*<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/lib/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<CPS>/usr/src/hadoop-2.8.5/etc/hadoop:/usr/src/hadoop-2.8.5/share/hadoop/common/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/common/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/*:/usr/src/hadoop-2.8.5/contrib/capacity-scheduler/*.jar<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_DIST_CLASSPATH -> /usr/src/hadoop-2.8.5/etc/hadoop:/usr/src/hadoop-2.8.5/share/hadoop/common/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/common/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/*:/usr/src/hadoop-2.8.5/contrib/capacity-scheduler/*.jar
    SPARK_YARN_STAGING_DIR -> hdfs://178.62.197.79:9000/user/root/.sparkStaging/application_1586849858644_0008
    SPARK_USER -> root
    PYTHONPATH -> /usr/src/spark-2.4.5-bin-without-hadoop/python:/usr/src/spark-2.4.5-bin-without-hadoop/python/build:/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/pyspark.zip:/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.7-src.zip

  command:
    {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx6144m \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.ui.port=0' \ 
      '-Dspark.driver.port=42739' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.CoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@178.62.198.251:42739 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      3 \ 
      --app-id \ 
      application_1586849858644_0008 \ 
      --user-class-path \ 
      file:$PWD/__app__.jar \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    pyspark.zip -> resource { scheme: "hdfs" host: "178.62.197.79" port: 9000 file: "/user/root/.sparkStaging/application_1586849858644_0008/pyspark.zip" } size: 591945 timestamp: 1586852232230 type: FILE visibility: PRIVATE
    py4j-0.10.7-src.zip -> resource { scheme: "hdfs" host: "178.62.197.79" port: 9000 file: "/user/root/.sparkStaging/application_1586849858644_0008/py4j-0.10.7-src.zip" } size: 42437 timestamp: 1586852232254 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "178.62.197.79" port: 9000 file: "/user/root/.sparkStaging/application_1586849858644_0008/__spark_libs__7819176082137010407.zip" } size: 168822862 timestamp: 1586852232079 type: ARCHIVE visibility: PRIVATE
    __spark_conf__ -> resource { scheme: "hdfs" host: "178.62.197.79" port: 9000 file: "/user/root/.sparkStaging/application_1586849858644_0008/__spark_conf__.zip" } size: 233325 timestamp: 1586852232377 type: ARCHIVE visibility: PRIVATE

===============================================================================
20/04/14 08:19:59 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@178.62.198.251:42739)
20/04/14 08:19:59 INFO yarn.YarnAllocator: Will request 3 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/14 08:19:59 INFO yarn.YarnAllocator: Submitted 3 unlocalized container requests.
20/04/14 08:19:59 INFO yarn.ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
20/04/14 08:20:00 INFO impl.AMRMClientImpl: Received new token for : 178.62.199.118:35057
20/04/14 08:20:00 INFO impl.AMRMClientImpl: Received new token for : 178.62.198.251:42461
20/04/14 08:20:00 INFO yarn.YarnAllocator: Launching container container_1586849858644_0008_02_000002 on host 178.62.198.251 for executor with ID 1
20/04/14 08:20:00 INFO yarn.YarnAllocator: Launching container container_1586849858644_0008_02_000003 on host 178.62.199.118 for executor with ID 2
20/04/14 08:20:00 INFO yarn.YarnAllocator: Received 2 containers from YARN, launching executors on 2 of them.
20/04/14 08:20:00 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/14 08:20:00 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/14 08:20:01 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.199.118:33168) with ID 2
20/04/14 08:20:01 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.198.251:58374) with ID 1
20/04/14 08:20:01 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.199.118:37771 with 3.0 GB RAM, BlockManagerId(2, 178.62.199.118, 37771, None)
20/04/14 08:20:01 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.198.251:45803 with 3.0 GB RAM, BlockManagerId(1, 178.62.198.251, 45803, None)
20/04/14 08:20:02 INFO yarn.YarnAllocator: Launching container container_1586849858644_0008_02_000005 on host 178.62.199.118 for executor with ID 3
20/04/14 08:20:02 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/14 08:20:02 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/14 08:20:04 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.199.118:33172) with ID 3
20/04/14 08:20:04 INFO cluster.YarnClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
20/04/14 08:20:04 INFO cluster.YarnClusterScheduler: YarnClusterScheduler.postStartHook done
20/04/14 08:20:04 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.199.118:37619 with 3.0 GB RAM, BlockManagerId(3, 178.62.199.118, 37619, None)
20/04/14 08:20:04 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/container_1586849858644_0008_02_000001/spark-warehouse').
20/04/14 08:20:04 INFO internal.SharedState: Warehouse path is 'file:/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/container_1586849858644_0008_02_000001/spark-warehouse'.
20/04/14 08:20:04 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.
20/04/14 08:20:04 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@eb0d10d{/SQL,null,AVAILABLE,@Spark}
20/04/14 08:20:04 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.
20/04/14 08:20:04 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2dbd292{/SQL/json,null,AVAILABLE,@Spark}
20/04/14 08:20:04 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.
20/04/14 08:20:04 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4390678e{/SQL/execution,null,AVAILABLE,@Spark}
20/04/14 08:20:04 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.
20/04/14 08:20:04 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2c2486c9{/SQL/execution/json,null,AVAILABLE,@Spark}
20/04/14 08:20:04 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.
20/04/14 08:20:04 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70d98b9b{/static/sql,null,AVAILABLE,@Spark}
20/04/14 08:20:04 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
20/04/14 08:20:04 INFO datasources.InMemoryFileIndex: It took 101 ms to list leaf files for 1 paths.
20/04/14 08:20:05 INFO spark.SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
20/04/14 08:20:05 INFO scheduler.DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/04/14 08:20:05 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
20/04/14 08:20:05 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/04/14 08:20:05 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/14 08:20:05 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
20/04/14 08:20:05 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 127.0 KB, free 3.0 GB)
20/04/14 08:20:05 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.2 KB, free 3.0 GB)
20/04/14 08:20:05 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 178.62.198.251:36493 (size: 33.2 KB, free: 3.0 GB)
20/04/14 08:20:05 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1163
20/04/14 08:20:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/04/14 08:20:05 INFO cluster.YarnClusterScheduler: Adding task set 0.0 with 1 tasks
20/04/14 08:20:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 178.62.198.251, executor 1, partition 0, PROCESS_LOCAL, 8097 bytes)
20/04/14 08:20:05 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 178.62.198.251:45803 (size: 33.2 KB, free: 3.0 GB)
20/04/14 08:20:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1355 ms on 178.62.198.251 (executor 1) (1/1)
20/04/14 08:20:06 INFO cluster.YarnClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/04/14 08:20:06 INFO scheduler.DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.556 s
20/04/14 08:20:06 INFO scheduler.DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.586994 s
20/04/14 08:20:07 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/04/14 08:20:07 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/04/14 08:20:07 INFO datasources.FileSourceStrategy: Output Data Schema: struct<entry: string, entry_name: string, features: vector ... 1 more fields>
20/04/14 08:20:07 INFO execution.FileSourceScanExec: Pushed Filters: 
20/04/14 08:20:07 INFO spark.ContextCleaner: Cleaned accumulator 27
20/04/14 08:20:07 INFO spark.ContextCleaner: Cleaned accumulator 26
20/04/14 08:20:08 INFO codegen.CodeGenerator: Code generated in 192.878827 ms
20/04/14 08:20:08 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 341.6 KB, free 3.0 GB)
20/04/14 08:20:08 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/14 08:20:08 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.198.251:36493 (size: 32.4 KB, free: 3.0 GB)
20/04/14 08:20:08 INFO spark.SparkContext: Created broadcast 1 from rdd at DatasetUtils.scala:68
20/04/14 08:20:08 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 9137390 bytes, open cost is considered as scanning 4194304 bytes.
20/04/14 08:20:08 INFO util.Instrumentation: [15055bfe] Stage class: KMeans
20/04/14 08:20:08 INFO util.Instrumentation: [15055bfe] Stage uid: KMeans_379fad790dce
20/04/14 08:20:08 INFO util.Instrumentation: [15055bfe] training: numPartitions=18 storageLevel=StorageLevel(1 replicas)
20/04/14 08:20:08 INFO util.Instrumentation: [15055bfe] {"seed":42,"distanceMeasure":"cosine","featuresCol":"features","predictionCol":"cluster","k":2}
20/04/14 08:20:08 WARN clustering.KMeans: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
20/04/14 08:20:08 INFO spark.SparkContext: Starting job: takeSample at KMeans.scala:386
20/04/14 08:20:08 INFO scheduler.DAGScheduler: Registering RDD 5 (rdd at DatasetUtils.scala:68) as input to shuffle 0
20/04/14 08:20:08 INFO scheduler.DAGScheduler: Got job 1 (takeSample at KMeans.scala:386) with 18 output partitions
20/04/14 08:20:08 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (takeSample at KMeans.scala:386)
20/04/14 08:20:08 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
20/04/14 08:20:08 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 1)
20/04/14 08:20:08 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at rdd at DatasetUtils.scala:68), which has no missing parents
20/04/14 08:20:08 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.1 KB, free 3.0 GB)
20/04/14 08:20:08 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KB, free 3.0 GB)
20/04/14 08:20:08 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 178.62.198.251:36493 (size: 6.5 KB, free: 3.0 GB)
20/04/14 08:20:08 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1163
20/04/14 08:20:08 INFO scheduler.DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at rdd at DatasetUtils.scala:68) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))
20/04/14 08:20:08 INFO cluster.YarnClusterScheduler: Adding task set 1.0 with 9 tasks
20/04/14 08:20:08 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 178.62.199.118, executor 3, partition 0, NODE_LOCAL, 8335 bytes)
20/04/14 08:20:08 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 178.62.198.251, executor 1, partition 1, NODE_LOCAL, 8335 bytes)
20/04/14 08:20:08 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 178.62.199.118, executor 2, partition 2, NODE_LOCAL, 8335 bytes)
20/04/14 08:20:08 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, 178.62.199.118, executor 3, partition 3, NODE_LOCAL, 8335 bytes)
20/04/14 08:20:08 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5, 178.62.198.251, executor 1, partition 4, NODE_LOCAL, 8335 bytes)
20/04/14 08:20:08 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6, 178.62.199.118, executor 2, partition 5, NODE_LOCAL, 8335 bytes)
20/04/14 08:20:08 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7, 178.62.199.118, executor 3, partition 6, NODE_LOCAL, 8335 bytes)
20/04/14 08:20:08 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8, 178.62.198.251, executor 1, partition 7, NODE_LOCAL, 8335 bytes)
20/04/14 08:20:08 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9, 178.62.199.118, executor 2, partition 8, NODE_LOCAL, 8335 bytes)
20/04/14 08:20:08 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 178.62.198.251:45803 (size: 6.5 KB, free: 3.0 GB)
20/04/14 08:20:08 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 178.62.199.118:37771 (size: 6.5 KB, free: 3.0 GB)
20/04/14 08:20:08 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 178.62.199.118:37619 (size: 6.5 KB, free: 3.0 GB)
20/04/14 08:20:08 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.198.251:45803 (size: 32.4 KB, free: 3.0 GB)
20/04/14 08:20:09 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.199.118:37619 (size: 32.4 KB, free: 3.0 GB)
20/04/14 08:20:09 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.199.118:37771 (size: 32.4 KB, free: 3.0 GB)
20/04/14 08:20:10 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 1701 ms on 178.62.198.251 (executor 1) (1/9)
20/04/14 08:20:10 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1772 ms on 178.62.198.251 (executor 1) (2/9)
20/04/14 08:20:10 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1781 ms on 178.62.198.251 (executor 1) (3/9)
20/04/14 08:20:11 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 2859 ms on 178.62.199.118 (executor 2) (4/9)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 3548 ms on 178.62.199.118 (executor 3) (5/9)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 3559 ms on 178.62.199.118 (executor 2) (6/9)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 3566 ms on 178.62.199.118 (executor 3) (7/9)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 3572 ms on 178.62.199.118 (executor 2) (8/9)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3577 ms on 178.62.199.118 (executor 3) (9/9)
20/04/14 08:20:12 INFO cluster.YarnClusterScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/04/14 08:20:12 INFO scheduler.DAGScheduler: ShuffleMapStage 1 (rdd at DatasetUtils.scala:68) finished in 3.604 s
20/04/14 08:20:12 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/04/14 08:20:12 INFO scheduler.DAGScheduler: running: Set()
20/04/14 08:20:12 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 2)
20/04/14 08:20:12 INFO scheduler.DAGScheduler: failed: Set()
20/04/14 08:20:12 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[23] at map at KMeans.scala:248), which has no missing parents
20/04/14 08:20:12 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.9 KB, free 3.0 GB)
20/04/14 08:20:12 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.0 KB, free 3.0 GB)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.198.251:36493 (size: 8.0 KB, free: 3.0 GB)
20/04/14 08:20:12 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1163
20/04/14 08:20:12 INFO scheduler.DAGScheduler: Submitting 18 missing tasks from ResultStage 2 (MapPartitionsRDD[23] at map at KMeans.scala:248) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
20/04/14 08:20:12 INFO cluster.YarnClusterScheduler: Adding task set 2.0 with 18 tasks
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, 178.62.198.251, executor 1, partition 0, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, 178.62.199.118, executor 3, partition 1, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, 178.62.199.118, executor 2, partition 2, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, 178.62.198.251, executor 1, partition 3, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, 178.62.199.118, executor 3, partition 4, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 2.0 (TID 15, 178.62.199.118, executor 2, partition 5, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 2.0 (TID 16, 178.62.198.251, executor 1, partition 6, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 2.0 (TID 17, 178.62.199.118, executor 3, partition 7, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:12 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 2.0 (TID 18, 178.62.199.118, executor 2, partition 8, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.198.251:45803 (size: 8.0 KB, free: 3.0 GB)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.199.118:37771 (size: 8.0 KB, free: 3.0 GB)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.199.118:37619 (size: 8.0 KB, free: 3.0 GB)
20/04/14 08:20:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 178.62.198.251:58374
20/04/14 08:20:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 178.62.199.118:33168
20/04/14 08:20:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 178.62.199.118:33172
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added rdd_7_3 in memory on 178.62.198.251:45803 (size: 7.2 MB, free: 3.0 GB)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on 178.62.198.251:45803 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added rdd_7_6 in memory on 178.62.198.251:45803 (size: 7.3 MB, free: 3.0 GB)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added rdd_7_4 in memory on 178.62.199.118:37619 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added rdd_7_1 in memory on 178.62.199.118:37619 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added rdd_7_7 in memory on 178.62.199.118:37619 (size: 7.3 MB, free: 3.0 GB)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added rdd_7_5 in memory on 178.62.199.118:37771 (size: 7.1 MB, free: 3.0 GB)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added rdd_7_2 in memory on 178.62.199.118:37771 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:20:12 INFO storage.BlockManagerInfo: Added rdd_7_8 in memory on 178.62.199.118:37771 (size: 7.2 MB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_0 in memory on 178.62.198.251:45803 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_6 in memory on 178.62.198.251:45803 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_3 in memory on 178.62.198.251:45803 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_5 in memory on 178.62.199.118:37771 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_8 in memory on 178.62.199.118:37771 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_2 in memory on 178.62.199.118:37771 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 2.0 (TID 19, 178.62.198.251, executor 1, partition 9, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 1495 ms on 178.62.198.251 (executor 1) (1/18)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 2.0 (TID 20, 178.62.198.251, executor 1, partition 10, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 2.0 (TID 16) in 1494 ms on 178.62.198.251 (executor 1) (2/18)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 2.0 (TID 21, 178.62.198.251, executor 1, partition 11, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 1501 ms on 178.62.198.251 (executor 1) (3/18)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 2.0 (TID 22, 178.62.199.118, executor 2, partition 12, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_4 in memory on 178.62.199.118:37619 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 2.0 (TID 23, 178.62.199.118, executor 2, partition 13, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 2.0 (TID 15) in 1533 ms on 178.62.199.118 (executor 2) (4/18)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 2.0 (TID 18) in 1533 ms on 178.62.199.118 (executor 2) (5/18)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 2.0 (TID 24, 178.62.199.118, executor 2, partition 14, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 1553 ms on 178.62.199.118 (executor 2) (6/18)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_7_9 in memory on 178.62.198.251:45803 (size: 7.5 MB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_7_11 in memory on 178.62.198.251:45803 (size: 7.3 MB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_7_10 in memory on 178.62.198.251:45803 (size: 7.2 MB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_7 in memory on 178.62.199.118:37619 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_1 in memory on 178.62.199.118:37619 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_9 in memory on 178.62.198.251:45803 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_11 in memory on 178.62.198.251:45803 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_10 in memory on 178.62.198.251:45803 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 2.0 (TID 25, 178.62.198.251, executor 1, partition 15, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 2.0 (TID 19) in 128 ms on 178.62.198.251 (executor 1) (7/18)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Starting task 16.0 in stage 2.0 (TID 26, 178.62.198.251, executor 1, partition 16, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 2.0 (TID 27, 178.62.198.251, executor 1, partition 17, NODE_LOCAL, 8067 bytes)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 2.0 (TID 21) in 141 ms on 178.62.198.251 (executor 1) (8/18)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 2.0 (TID 20) in 146 ms on 178.62.198.251 (executor 1) (9/18)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 1651 ms on 178.62.199.118 (executor 3) (10/18)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 2.0 (TID 17) in 1674 ms on 178.62.199.118 (executor 3) (11/18)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 1678 ms on 178.62.199.118 (executor 3) (12/18)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_7_12 in memory on 178.62.199.118:37771 (size: 7.3 MB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_7_15 in memory on 178.62.198.251:45803 (size: 7.2 MB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_7_16 in memory on 178.62.198.251:45803 (size: 7.2 MB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_7_17 in memory on 178.62.198.251:45803 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_15 in memory on 178.62.198.251:45803 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 2.0 (TID 25) in 139 ms on 178.62.198.251 (executor 1) (13/18)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_16 in memory on 178.62.198.251:45803 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_17 in memory on 178.62.198.251:45803 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_7_13 in memory on 178.62.199.118:37771 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 16.0 in stage 2.0 (TID 26) in 136 ms on 178.62.198.251 (executor 1) (14/18)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_7_14 in memory on 178.62.199.118:37771 (size: 7.6 MB, free: 3.0 GB)
20/04/14 08:20:13 INFO scheduler.TaskSetManager: Finished task 17.0 in stage 2.0 (TID 27) in 140 ms on 178.62.198.251 (executor 1) (15/18)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_12 in memory on 178.62.199.118:37771 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManagerInfo: Added rdd_21_13 in memory on 178.62.199.118:37771 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 2.0 (TID 22) in 290 ms on 178.62.199.118 (executor 2) (16/18)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added rdd_21_14 in memory on 178.62.199.118:37771 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 2.0 (TID 23) in 302 ms on 178.62.199.118 (executor 2) (17/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 2.0 (TID 24) in 288 ms on 178.62.199.118 (executor 2) (18/18)
20/04/14 08:20:14 INFO cluster.YarnClusterScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/04/14 08:20:14 INFO scheduler.DAGScheduler: ResultStage 2 (takeSample at KMeans.scala:386) finished in 1.882 s
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Job 1 finished: takeSample at KMeans.scala:386, took 5.513499 s
20/04/14 08:20:14 INFO spark.SparkContext: Starting job: takeSample at KMeans.scala:386
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Got job 2 (takeSample at KMeans.scala:386) with 18 output partitions
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (takeSample at KMeans.scala:386)
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (PartitionwiseSampledRDD[25] at takeSample at KMeans.scala:386), which has no missing parents
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.6 KB, free 3.0 GB)
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.198.251:36493 (size: 8.3 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1163
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Submitting 18 missing tasks from ResultStage 4 (PartitionwiseSampledRDD[25] at takeSample at KMeans.scala:386) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
20/04/14 08:20:14 INFO cluster.YarnClusterScheduler: Adding task set 4.0 with 18 tasks
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 4.0 (TID 28, 178.62.199.118, executor 2, partition 2, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 29, 178.62.199.118, executor 3, partition 1, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 30, 178.62.198.251, executor 1, partition 0, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 4.0 (TID 31, 178.62.199.118, executor 2, partition 5, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 4.0 (TID 32, 178.62.199.118, executor 3, partition 4, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 4.0 (TID 33, 178.62.198.251, executor 1, partition 3, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 4.0 (TID 34, 178.62.199.118, executor 2, partition 8, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 4.0 (TID 35, 178.62.199.118, executor 3, partition 7, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 4.0 (TID 36, 178.62.198.251, executor 1, partition 6, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.198.251:45803 (size: 8.3 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.199.118:37619 (size: 8.3 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.199.118:37771 (size: 8.3 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 4.0 (TID 37, 178.62.198.251, executor 1, partition 9, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 4.0 (TID 33) in 60 ms on 178.62.198.251 (executor 1) (1/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 4.0 (TID 38, 178.62.198.251, executor 1, partition 10, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 30) in 64 ms on 178.62.198.251 (executor 1) (2/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 4.0 (TID 39, 178.62.198.251, executor 1, partition 11, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 4.0 (TID 36) in 71 ms on 178.62.198.251 (executor 1) (3/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 4.0 (TID 40, 178.62.199.118, executor 2, partition 12, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 4.0 (TID 31) in 79 ms on 178.62.199.118 (executor 2) (4/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 4.0 (TID 41, 178.62.199.118, executor 2, partition 13, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 4.0 (TID 34) in 79 ms on 178.62.199.118 (executor 2) (5/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 4.0 (TID 42, 178.62.198.251, executor 1, partition 15, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 4.0 (TID 37) in 36 ms on 178.62.198.251 (executor 1) (6/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 16.0 in stage 4.0 (TID 43, 178.62.198.251, executor 1, partition 16, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 4.0 (TID 44, 178.62.198.251, executor 1, partition 17, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 4.0 (TID 38) in 39 ms on 178.62.198.251 (executor 1) (7/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 4.0 (TID 45, 178.62.199.118, executor 2, partition 14, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 4.0 (TID 39) in 33 ms on 178.62.198.251 (executor 1) (8/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 4.0 (TID 28) in 106 ms on 178.62.199.118 (executor 2) (9/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 4.0 (TID 42) in 32 ms on 178.62.198.251 (executor 1) (10/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 17.0 in stage 4.0 (TID 44) in 29 ms on 178.62.198.251 (executor 1) (11/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 4.0 (TID 41) in 51 ms on 178.62.199.118 (executor 2) (12/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 4.0 (TID 45) in 29 ms on 178.62.199.118 (executor 2) (13/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 4.0 (TID 40) in 55 ms on 178.62.199.118 (executor 2) (14/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 29) in 137 ms on 178.62.199.118 (executor 3) (15/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 4.0 (TID 32) in 140 ms on 178.62.199.118 (executor 3) (16/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 16.0 in stage 4.0 (TID 43) in 45 ms on 178.62.198.251 (executor 1) (17/18)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 4.0 (TID 35) in 145 ms on 178.62.199.118 (executor 3) (18/18)
20/04/14 08:20:14 INFO cluster.YarnClusterScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/04/14 08:20:14 INFO scheduler.DAGScheduler: ResultStage 4 (takeSample at KMeans.scala:386) finished in 0.154 s
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Job 2 finished: takeSample at KMeans.scala:386, took 0.158699 s
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.0 MB, free 3.0 GB)
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.6 KB, free 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.198.251:36493 (size: 10.6 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO spark.SparkContext: Created broadcast 5 from broadcast at KMeans.scala:400
20/04/14 08:20:14 INFO spark.SparkContext: Starting job: sum at KMeans.scala:406
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Got job 3 (sum at KMeans.scala:406) with 18 output partitions
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (sum at KMeans.scala:406)
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at map at KMeans.scala:403), which has no missing parents
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.5 KB, free 3.0 GB)
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.7 KB, free 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.198.251:36493 (size: 8.7 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1163
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Submitting 18 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at map at KMeans.scala:403) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
20/04/14 08:20:14 INFO cluster.YarnClusterScheduler: Adding task set 6.0 with 18 tasks
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 6.0 (TID 46, 178.62.199.118, executor 2, partition 2, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 47, 178.62.198.251, executor 1, partition 0, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 48, 178.62.199.118, executor 3, partition 1, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 6.0 (TID 49, 178.62.199.118, executor 2, partition 5, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 6.0 (TID 50, 178.62.198.251, executor 1, partition 3, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 6.0 (TID 51, 178.62.199.118, executor 3, partition 4, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 6.0 (TID 52, 178.62.199.118, executor 2, partition 8, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 6.0 (TID 53, 178.62.198.251, executor 1, partition 6, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 6.0 (TID 54, 178.62.199.118, executor 3, partition 7, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.199.118:37619 (size: 8.7 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.199.118:37771 (size: 8.7 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.198.251:45803 (size: 8.7 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.198.251:45803 (size: 10.6 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.199.118:37619 (size: 10.6 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.199.118:37771 (size: 10.6 KB, free: 3.0 GB)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 6.0 (TID 55, 178.62.198.251, executor 1, partition 9, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 6.0 (TID 56, 178.62.198.251, executor 1, partition 10, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 6.0 (TID 57, 178.62.198.251, executor 1, partition 11, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 6.0 (TID 47, 178.62.198.251, executor 1): java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 3.0 in stage 6.0 (TID 50) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 1]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 6.0 in stage 6.0 (TID 53) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 2]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 7.0 in stage 6.0 (TID 54) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 3]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 4.0 in stage 6.0 (TID 51) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 4]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 1.0 in stage 6.0 (TID 48) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 5]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 1.1 in stage 6.0 (TID 58, 178.62.199.118, executor 3, partition 1, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 4.1 in stage 6.0 (TID 59, 178.62.199.118, executor 3, partition 4, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 7.1 in stage 6.0 (TID 60, 178.62.199.118, executor 3, partition 7, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 6.1 in stage 6.0 (TID 61, 178.62.198.251, executor 1, partition 6, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 11.0 in stage 6.0 (TID 57) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 6]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 11.1 in stage 6.0 (TID 62, 178.62.198.251, executor 1, partition 11, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 10.0 in stage 6.0 (TID 56) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 7]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 1.1 in stage 6.0 (TID 58) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 8]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 1.2 in stage 6.0 (TID 63, 178.62.199.118, executor 3, partition 1, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 6.0 (TID 64, 178.62.199.118, executor 2, partition 12, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 2.0 in stage 6.0 (TID 46) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 9]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 2.1 in stage 6.0 (TID 65, 178.62.199.118, executor 2, partition 2, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 5.0 in stage 6.0 (TID 49) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 10]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 5.1 in stage 6.0 (TID 66, 178.62.199.118, executor 2, partition 5, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 8.0 in stage 6.0 (TID 52) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 11]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 10.1 in stage 6.0 (TID 67, 178.62.198.251, executor 1, partition 10, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 9.0 in stage 6.0 (TID 55) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 12]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 9.1 in stage 6.0 (TID 68, 178.62.198.251, executor 1, partition 9, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 7.1 in stage 6.0 (TID 60) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 13]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 3.1 in stage 6.0 (TID 69, 178.62.198.251, executor 1, partition 3, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 6.1 in stage 6.0 (TID 61) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 14]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 7.2 in stage 6.0 (TID 70, 178.62.199.118, executor 3, partition 7, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 11.1 in stage 6.0 (TID 62) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 15]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 4.1 in stage 6.0 (TID 59) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 16]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 4.2 in stage 6.0 (TID 71, 178.62.199.118, executor 3, partition 4, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 1.2 in stage 6.0 (TID 63) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 17]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 1.3 in stage 6.0 (TID 72, 178.62.199.118, executor 3, partition 1, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 11.2 in stage 6.0 (TID 73, 178.62.198.251, executor 1, partition 11, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 8.1 in stage 6.0 (TID 74, 178.62.199.118, executor 2, partition 8, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 5.1 in stage 6.0 (TID 66) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 18]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 10.1 in stage 6.0 (TID 67) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 19]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 5.2 in stage 6.0 (TID 75, 178.62.199.118, executor 2, partition 5, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 12.0 in stage 6.0 (TID 64) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 20]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 10.2 in stage 6.0 (TID 76, 178.62.198.251, executor 1, partition 10, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 3.1 in stage 6.0 (TID 69) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 21]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 3.2 in stage 6.0 (TID 77, 178.62.198.251, executor 1, partition 3, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 9.1 in stage 6.0 (TID 68) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 22]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 7.2 in stage 6.0 (TID 70) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 23]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 7.3 in stage 6.0 (TID 78, 178.62.199.118, executor 3, partition 7, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 9.2 in stage 6.0 (TID 79, 178.62.198.251, executor 1, partition 9, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 11.2 in stage 6.0 (TID 73) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 24]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 12.1 in stage 6.0 (TID 80, 178.62.199.118, executor 2, partition 12, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 2.1 in stage 6.0 (TID 65) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 25]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Starting task 11.3 in stage 6.0 (TID 81, 178.62.198.251, executor 1, partition 11, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 10.2 in stage 6.0 (TID 76) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 26]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 1.3 in stage 6.0 (TID 72) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 27]
20/04/14 08:20:14 ERROR scheduler.TaskSetManager: Task 1 in stage 6.0 failed 4 times; aborting job
20/04/14 08:20:14 INFO cluster.YarnClusterScheduler: Cancelling stage 6
20/04/14 08:20:14 INFO cluster.YarnClusterScheduler: Killing all running tasks in stage 6: Stage cancelled
20/04/14 08:20:14 INFO cluster.YarnClusterScheduler: Stage 6 was cancelled
20/04/14 08:20:14 INFO scheduler.DAGScheduler: ResultStage 6 (sum at KMeans.scala:406) failed in 0.325 s due to Job aborted due to stage failure: Task 1 in stage 6.0 failed 4 times, most recent failure: Lost task 1.3 in stage 6.0 (TID 72, 178.62.199.118, executor 3): java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 5.2 in stage 6.0 (TID 75) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 28]
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 12.1 in stage 6.0 (TID 80) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 29]
20/04/14 08:20:14 INFO scheduler.DAGScheduler: Job 3 failed: sum at KMeans.scala:406, took 0.333284 s
20/04/14 08:20:14 INFO scheduler.TaskSetManager: Lost task 3.2 in stage 6.0 (TID 77) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 30]
20/04/14 08:20:14 ERROR util.Instrumentation: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 6.0 failed 4 times, most recent failure: Lost task 1.3 in stage 6.0 (TID 72, 178.62.199.118, executor 3): java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1143)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.fold(RDD.scala:1137)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply$mcD$sp(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.DoubleRDDFunctions.sum(DoubleRDDFunctions.scala:34)
	at org.apache.spark.mllib.clustering.KMeans.initKMeansParallel(KMeans.scala:406)
	at org.apache.spark.mllib.clustering.KMeans.runAlgorithm(KMeans.scala:282)
	at org.apache.spark.mllib.clustering.KMeans.run(KMeans.scala:251)
	at org.apache.spark.ml.clustering.KMeans$$anonfun$fit$1.apply(KMeans.scala:362)
	at org.apache.spark.ml.clustering.KMeans$$anonfun$fit$1.apply(KMeans.scala:340)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:340)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more

20/04/14 08:20:14 WARN scheduler.TaskSetManager: Lost task 4.2 in stage 6.0 (TID 71, 178.62.199.118, executor 3): TaskKilled (Stage cancelled)
20/04/14 08:20:14 WARN scheduler.TaskSetManager: Lost task 8.1 in stage 6.0 (TID 74, 178.62.199.118, executor 2): TaskKilled (Stage cancelled)
20/04/14 08:20:14 WARN scheduler.TaskSetManager: Lost task 7.3 in stage 6.0 (TID 78, 178.62.199.118, executor 3): TaskKilled (Stage cancelled)
20/04/14 08:20:14 WARN scheduler.TaskSetManager: Lost task 9.2 in stage 6.0 (TID 79, 178.62.198.251, executor 1): TaskKilled (Stage cancelled)
20/04/14 08:20:14 WARN scheduler.TaskSetManager: Lost task 11.3 in stage 6.0 (TID 81, 178.62.198.251, executor 1): TaskKilled (Stage cancelled)
20/04/14 08:20:14 INFO cluster.YarnClusterScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/04/14 08:20:14 ERROR yarn.ApplicationMaster: User application exited with status 1
20/04/14 08:20:14 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 1, (reason: User application exited with status 1)
20/04/14 08:20:14 INFO spark.SparkContext: Invoking stop() from shutdown hook
20/04/14 08:20:14 INFO server.AbstractConnector: Stopped Spark@12b46e14{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
20/04/14 08:20:14 INFO ui.SparkUI: Stopped Spark web UI at http://178.62.198.251:32915
20/04/14 08:20:14 INFO yarn.YarnAllocator: Driver requested a total number of 0 executor(s).
20/04/14 08:20:14 INFO cluster.YarnClusterSchedulerBackend: Shutting down all executors
20/04/14 08:20:14 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/04/14 08:20:14 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
20/04/14 08:20:14 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/04/14 08:20:14 INFO memory.MemoryStore: MemoryStore cleared
20/04/14 08:20:14 INFO storage.BlockManager: BlockManager stopped
20/04/14 08:20:14 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
20/04/14 08:20:14 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/04/14 08:20:14 INFO spark.SparkContext: Successfully stopped SparkContext
20/04/14 08:20:14 INFO yarn.ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: User application exited with status 1)
20/04/14 08:20:14 INFO impl.AMRMClientImpl: Waiting for application to be successfully unregistered.
20/04/14 08:20:14 INFO yarn.ApplicationMaster: Deleting staging directory hdfs://178.62.197.79:9000/user/root/.sparkStaging/application_1586849858644_0008
20/04/14 08:20:14 INFO util.ShutdownHookManager: Shutdown hook called
20/04/14 08:20:14 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/spark-101e3880-bbcf-4ef0-8963-884ecc1aa8aa/pyspark-2f9dbf11-bba0-4819-88af-3c33851a515d
20/04/14 08:20:14 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/spark-101e3880-bbcf-4ef0-8963-884ecc1aa8aa
End of LogType:stderr

LogType:stdout
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:10071
Log Contents:
Traceback (most recent call last):
  File "clustering.py", line 312, in <module>
    result_dfs_list=result_dfs,
  File "clustering.py", line 54, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 72, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 264, in perform_experiment
    in_file=in_file, distance=distance, k=k, ModelCls=ModelCls
  File "clustering.py", line 54, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 72, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 137, in perform_clustering_kmeans
    model = fit(model_algo, df)
  File "clustering.py", line 54, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 94, in fit
    model = model_algo.fit(df)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/ml/base.py", line 132, in fit
    return self._fit(dataset)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/ml/wrapper.py", line 295, in _fit
    java_model = self._fit_java(dataset)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/ml/wrapper.py", line 292, in _fit_java
    return self._java_obj.fit(dataset._jdf)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o50.fit.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 6.0 failed 4 times, most recent failure: Lost task 1.3 in stage 6.0 (TID 72, 178.62.199.118, executor 3): java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1143)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.fold(RDD.scala:1137)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply$mcD$sp(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.DoubleRDDFunctions.sum(DoubleRDDFunctions.scala:34)
	at org.apache.spark.mllib.clustering.KMeans.initKMeansParallel(KMeans.scala:406)
	at org.apache.spark.mllib.clustering.KMeans.runAlgorithm(KMeans.scala:282)
	at org.apache.spark.mllib.clustering.KMeans.run(KMeans.scala:251)
	at org.apache.spark.ml.clustering.KMeans$$anonfun$fit$1.apply(KMeans.scala:362)
	at org.apache.spark.ml.clustering.KMeans$$anonfun$fit$1.apply(KMeans.scala:340)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:340)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more

End of LogType:stdout



Container: container_1586849858644_0008_01_000001 on 178.62.198.251_42461
===========================================================================
LogType:pyspark.log
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:1402
Log Contents:
[PYTHON] 2020-04-14 08:19:45,006.006 INFO clustering - wrapper: perform_experiment keyword arguments:
[PYTHON] 2020-04-14 08:19:45,007.007 INFO clustering - wrapper: in_files: ['/data/df_5-shingles_sparse-count-vectors.parquet']
[PYTHON] 2020-04-14 08:19:45,007.007 INFO clustering - wrapper: distances: ['cosine', 'euclidean']
[PYTHON] 2020-04-14 08:19:45,007.007 INFO clustering - wrapper: ks: [2, 4, 6]
[PYTHON] 2020-04-14 08:19:45,007.007 INFO clustering - wrapper: models: [<class 'pyspark.ml.clustering.KMeans'>, <class 'pyspark.ml.clustering.BisectingKMeans'>]
[PYTHON] 2020-04-14 08:19:45,007.007 INFO clustering - wrapper: result_dfs_list: []
[PYTHON] 2020-04-14 08:19:45,007.007 INFO clustering - wrapper: perform_clustering_kmeans keyword arguments:
[PYTHON] 2020-04-14 08:19:45,007.007 INFO clustering - wrapper: in_file: /data/df_5-shingles_sparse-count-vectors.parquet
[PYTHON] 2020-04-14 08:19:45,007.007 INFO clustering - wrapper: distance: cosine
[PYTHON] 2020-04-14 08:19:45,007.007 INFO clustering - wrapper: k: 2
[PYTHON] 2020-04-14 08:19:45,007.007 INFO clustering - wrapper: ModelCls: <class 'pyspark.ml.clustering.KMeans'>
[PYTHON] 2020-04-14 08:19:45,009.009 INFO clustering - read_and_repartition: reading /data/df_5-shingles_sparse-count-vectors.parquet into 18 partitions
[PYTHON] 2020-04-14 08:19:48,974.974 INFO clustering - wrapper: read_and_repartition finished in 3.97s
End of LogType:pyspark.log

LogType:stderr
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:80047
Log Contents:
20/04/14 08:19:36 INFO util.SignalUtils: Registered signal handler for TERM
20/04/14 08:19:36 INFO util.SignalUtils: Registered signal handler for HUP
20/04/14 08:19:36 INFO util.SignalUtils: Registered signal handler for INT
20/04/14 08:19:36 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:19:36 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:19:36 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:19:36 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:19:36 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:19:37 INFO yarn.ApplicationMaster: Preparing Local resources
20/04/14 08:19:38 INFO yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1586849858644_0008_000001
20/04/14 08:19:38 INFO yarn.ApplicationMaster: Starting the user application in a separate Thread
20/04/14 08:19:38 INFO yarn.ApplicationMaster: Waiting for spark context initialization...
20/04/14 08:19:38 INFO spark.SparkContext: Running Spark version 2.4.5
20/04/14 08:19:38 INFO spark.SparkContext: Submitted application: ClusteringExperiment
20/04/14 08:19:38 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:19:38 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:19:38 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:19:38 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:19:38 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:19:38 INFO util.Utils: Successfully started service 'sparkDriver' on port 38785.
20/04/14 08:19:38 INFO spark.SparkEnv: Registering MapOutputTracker
20/04/14 08:19:38 INFO spark.SparkEnv: Registering BlockManagerMaster
20/04/14 08:19:38 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/04/14 08:19:38 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/04/14 08:19:38 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/blockmgr-56a9a27e-a17e-4447-898d-4caca50d8563
20/04/14 08:19:38 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/14 08:19:38 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/04/14 08:19:38 INFO util.log: Logging initialized @2777ms
20/04/14 08:19:38 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/04/14 08:19:38 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
20/04/14 08:19:38 INFO server.Server: Started @2845ms
20/04/14 08:19:38 INFO server.AbstractConnector: Started ServerConnector@228b8e4d{HTTP/1.1,[http/1.1]}{0.0.0.0:38625}
20/04/14 08:19:38 INFO util.Utils: Successfully started service 'SparkUI' on port 38625.
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@32c1cb43{/jobs,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1a373652{/jobs/json,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5cbc82e4{/jobs/job,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30e32f7b{/jobs/job/json,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@13c50a93{/stages,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bd611ad{/stages/json,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c4b54c5{/stages/stage,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@55100670{/stages/stage/json,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@53fb9d6b{/stages/pool,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7723dbe4{/stages/pool/json,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@385733b3{/storage,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6da1814f{/storage/json,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@623e5955{/storage/rdd,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b2b420d{/storage/rdd/json,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@ae02270{/environment,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6b2a719a{/environment/json,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7bce795b{/executors,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2aa46705{/executors/json,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@215c3383{/executors/threadDump,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@19c23093{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@11ce9651{/static,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ec1daea{/,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e29343a{/api,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4eafc166{/jobs/job/kill,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@641a1944{/stages/stage/kill,null,AVAILABLE,@Spark}
20/04/14 08:19:38 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://178.62.198.251:38625
20/04/14 08:19:39 INFO cluster.YarnClusterScheduler: Created YarnClusterScheduler
20/04/14 08:19:39 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1586849858644_0008 and attemptId Some(appattempt_1586849858644_0008_000001)
20/04/14 08:19:39 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45915.
20/04/14 08:19:39 INFO netty.NettyBlockTransferService: Server created on 178.62.198.251:45915
20/04/14 08:19:39 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/14 08:19:39 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 178.62.198.251, 45915, None)
20/04/14 08:19:39 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.198.251:45915 with 3.0 GB RAM, BlockManagerId(driver, 178.62.198.251, 45915, None)
20/04/14 08:19:39 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 178.62.198.251, 45915, None)
20/04/14 08:19:39 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 178.62.198.251, 45915, None)
20/04/14 08:19:39 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/04/14 08:19:39 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2021d82f{/metrics/json,null,AVAILABLE,@Spark}
20/04/14 08:19:39 INFO client.RMProxy: Connecting to ResourceManager at /178.62.197.79:8030
20/04/14 08:19:39 INFO yarn.YarnRMClient: Registering the ApplicationMaster
20/04/14 08:19:39 INFO yarn.ApplicationMaster: 
===============================================================================
YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>$HADOOP_CONF_DIR<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/*<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/lib/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<CPS>/usr/src/hadoop-2.8.5/etc/hadoop:/usr/src/hadoop-2.8.5/share/hadoop/common/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/common/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/*:/usr/src/hadoop-2.8.5/contrib/capacity-scheduler/*.jar<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_DIST_CLASSPATH -> /usr/src/hadoop-2.8.5/etc/hadoop:/usr/src/hadoop-2.8.5/share/hadoop/common/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/common/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/*:/usr/src/hadoop-2.8.5/contrib/capacity-scheduler/*.jar
    SPARK_YARN_STAGING_DIR -> hdfs://178.62.197.79:9000/user/root/.sparkStaging/application_1586849858644_0008
    SPARK_USER -> root
    PYTHONPATH -> /usr/src/spark-2.4.5-bin-without-hadoop/python:/usr/src/spark-2.4.5-bin-without-hadoop/python/build:/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/pyspark.zip:/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.7-src.zip

  command:
    {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx6144m \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.ui.port=0' \ 
      '-Dspark.driver.port=38785' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.CoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@178.62.198.251:38785 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      3 \ 
      --app-id \ 
      application_1586849858644_0008 \ 
      --user-class-path \ 
      file:$PWD/__app__.jar \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    pyspark.zip -> resource { scheme: "hdfs" host: "178.62.197.79" port: 9000 file: "/user/root/.sparkStaging/application_1586849858644_0008/pyspark.zip" } size: 591945 timestamp: 1586852232230 type: FILE visibility: PRIVATE
    py4j-0.10.7-src.zip -> resource { scheme: "hdfs" host: "178.62.197.79" port: 9000 file: "/user/root/.sparkStaging/application_1586849858644_0008/py4j-0.10.7-src.zip" } size: 42437 timestamp: 1586852232254 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "178.62.197.79" port: 9000 file: "/user/root/.sparkStaging/application_1586849858644_0008/__spark_libs__7819176082137010407.zip" } size: 168822862 timestamp: 1586852232079 type: ARCHIVE visibility: PRIVATE
    __spark_conf__ -> resource { scheme: "hdfs" host: "178.62.197.79" port: 9000 file: "/user/root/.sparkStaging/application_1586849858644_0008/__spark_conf__.zip" } size: 233325 timestamp: 1586852232377 type: ARCHIVE visibility: PRIVATE

===============================================================================
20/04/14 08:19:39 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@178.62.198.251:38785)
20/04/14 08:19:39 INFO yarn.YarnAllocator: Will request 3 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/14 08:19:39 INFO yarn.YarnAllocator: Submitted 3 unlocalized container requests.
20/04/14 08:19:39 INFO yarn.ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
20/04/14 08:19:40 INFO impl.AMRMClientImpl: Received new token for : 178.62.198.251:42461
20/04/14 08:19:40 INFO impl.AMRMClientImpl: Received new token for : 178.62.199.118:35057
20/04/14 08:19:40 INFO yarn.YarnAllocator: Launching container container_1586849858644_0008_01_000002 on host 178.62.198.251 for executor with ID 1
20/04/14 08:19:40 INFO yarn.YarnAllocator: Launching container container_1586849858644_0008_01_000003 on host 178.62.199.118 for executor with ID 2
20/04/14 08:19:40 INFO yarn.YarnAllocator: Received 2 containers from YARN, launching executors on 2 of them.
20/04/14 08:19:40 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/14 08:19:40 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/14 08:19:42 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.198.251:43958) with ID 1
20/04/14 08:19:42 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.198.251:43183 with 3.0 GB RAM, BlockManagerId(1, 178.62.198.251, 43183, None)
20/04/14 08:19:42 INFO yarn.YarnAllocator: Launching container container_1586849858644_0008_01_000005 on host 178.62.199.118 for executor with ID 3
20/04/14 08:19:42 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/14 08:19:42 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/14 08:19:42 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.199.118:37560) with ID 2
20/04/14 08:19:42 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.199.118:37315 with 3.0 GB RAM, BlockManagerId(2, 178.62.199.118, 37315, None)
20/04/14 08:19:44 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.199.118:37564) with ID 3
20/04/14 08:19:44 INFO cluster.YarnClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
20/04/14 08:19:44 INFO cluster.YarnClusterScheduler: YarnClusterScheduler.postStartHook done
20/04/14 08:19:44 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.199.118:33175 with 3.0 GB RAM, BlockManagerId(3, 178.62.199.118, 33175, None)
20/04/14 08:19:44 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/container_1586849858644_0008_01_000001/spark-warehouse').
20/04/14 08:19:44 INFO internal.SharedState: Warehouse path is 'file:/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/container_1586849858644_0008_01_000001/spark-warehouse'.
20/04/14 08:19:44 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.
20/04/14 08:19:44 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@768f4f71{/SQL,null,AVAILABLE,@Spark}
20/04/14 08:19:44 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.
20/04/14 08:19:44 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2906cfab{/SQL/json,null,AVAILABLE,@Spark}
20/04/14 08:19:44 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.
20/04/14 08:19:44 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1dd4eee0{/SQL/execution,null,AVAILABLE,@Spark}
20/04/14 08:19:44 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.
20/04/14 08:19:44 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6b2d1400{/SQL/execution/json,null,AVAILABLE,@Spark}
20/04/14 08:19:44 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.
20/04/14 08:19:44 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@75c1b056{/static/sql,null,AVAILABLE,@Spark}
20/04/14 08:19:44 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
20/04/14 08:19:45 INFO datasources.InMemoryFileIndex: It took 92 ms to list leaf files for 1 paths.
20/04/14 08:19:45 INFO spark.SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
20/04/14 08:19:45 INFO scheduler.DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/04/14 08:19:45 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
20/04/14 08:19:45 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/04/14 08:19:45 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/14 08:19:45 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
20/04/14 08:19:45 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 127.0 KB, free 3.0 GB)
20/04/14 08:19:45 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.2 KB, free 3.0 GB)
20/04/14 08:19:45 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 178.62.198.251:45915 (size: 33.2 KB, free: 3.0 GB)
20/04/14 08:19:45 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1163
20/04/14 08:19:45 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/04/14 08:19:45 INFO cluster.YarnClusterScheduler: Adding task set 0.0 with 1 tasks
20/04/14 08:19:45 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 178.62.199.118, executor 3, partition 0, PROCESS_LOCAL, 8097 bytes)
20/04/14 08:19:45 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 178.62.199.118:33175 (size: 33.2 KB, free: 3.0 GB)
20/04/14 08:19:47 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2277 ms on 178.62.199.118 (executor 3) (1/1)
20/04/14 08:19:47 INFO cluster.YarnClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/04/14 08:19:47 INFO scheduler.DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 2.390 s
20/04/14 08:19:47 INFO scheduler.DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 2.420681 s
20/04/14 08:19:48 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/04/14 08:19:48 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/04/14 08:19:48 INFO datasources.FileSourceStrategy: Output Data Schema: struct<entry: string, entry_name: string, features: vector ... 1 more fields>
20/04/14 08:19:48 INFO execution.FileSourceScanExec: Pushed Filters: 
20/04/14 08:19:49 INFO spark.ContextCleaner: Cleaned accumulator 27
20/04/14 08:19:49 INFO spark.ContextCleaner: Cleaned accumulator 26
20/04/14 08:19:49 INFO codegen.CodeGenerator: Code generated in 225.978629 ms
20/04/14 08:19:49 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 341.6 KB, free 3.0 GB)
20/04/14 08:19:49 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/14 08:19:49 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.198.251:45915 (size: 32.4 KB, free: 3.0 GB)
20/04/14 08:19:49 INFO spark.SparkContext: Created broadcast 1 from rdd at DatasetUtils.scala:68
20/04/14 08:19:49 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 9137390 bytes, open cost is considered as scanning 4194304 bytes.
20/04/14 08:19:49 INFO util.Instrumentation: [93a360c9] Stage class: KMeans
20/04/14 08:19:49 INFO util.Instrumentation: [93a360c9] Stage uid: KMeans_3d28c0765a9a
20/04/14 08:19:49 INFO util.Instrumentation: [93a360c9] training: numPartitions=18 storageLevel=StorageLevel(1 replicas)
20/04/14 08:19:49 INFO util.Instrumentation: [93a360c9] {"seed":42,"distanceMeasure":"cosine","featuresCol":"features","predictionCol":"cluster","k":2}
20/04/14 08:19:49 WARN clustering.KMeans: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
20/04/14 08:19:49 INFO spark.SparkContext: Starting job: takeSample at KMeans.scala:386
20/04/14 08:19:49 INFO scheduler.DAGScheduler: Registering RDD 5 (rdd at DatasetUtils.scala:68) as input to shuffle 0
20/04/14 08:19:49 INFO scheduler.DAGScheduler: Got job 1 (takeSample at KMeans.scala:386) with 18 output partitions
20/04/14 08:19:49 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (takeSample at KMeans.scala:386)
20/04/14 08:19:49 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
20/04/14 08:19:49 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 1)
20/04/14 08:19:49 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at rdd at DatasetUtils.scala:68), which has no missing parents
20/04/14 08:19:49 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.1 KB, free 3.0 GB)
20/04/14 08:19:49 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KB, free 3.0 GB)
20/04/14 08:19:49 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 178.62.198.251:45915 (size: 6.5 KB, free: 3.0 GB)
20/04/14 08:19:49 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1163
20/04/14 08:19:49 INFO scheduler.DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at rdd at DatasetUtils.scala:68) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))
20/04/14 08:19:49 INFO cluster.YarnClusterScheduler: Adding task set 1.0 with 9 tasks
20/04/14 08:19:49 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 178.62.199.118, executor 2, partition 0, NODE_LOCAL, 8335 bytes)
20/04/14 08:19:49 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 178.62.198.251, executor 1, partition 1, NODE_LOCAL, 8335 bytes)
20/04/14 08:19:49 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 178.62.199.118, executor 3, partition 2, NODE_LOCAL, 8335 bytes)
20/04/14 08:19:49 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, 178.62.199.118, executor 2, partition 3, NODE_LOCAL, 8335 bytes)
20/04/14 08:19:49 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5, 178.62.198.251, executor 1, partition 4, NODE_LOCAL, 8335 bytes)
20/04/14 08:19:49 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6, 178.62.199.118, executor 3, partition 5, NODE_LOCAL, 8335 bytes)
20/04/14 08:19:49 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7, 178.62.199.118, executor 2, partition 6, NODE_LOCAL, 8335 bytes)
20/04/14 08:19:49 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8, 178.62.198.251, executor 1, partition 7, NODE_LOCAL, 8335 bytes)
20/04/14 08:19:49 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9, 178.62.199.118, executor 3, partition 8, NODE_LOCAL, 8335 bytes)
20/04/14 08:19:49 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 178.62.199.118:33175 (size: 6.5 KB, free: 3.0 GB)
20/04/14 08:19:49 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 178.62.198.251:43183 (size: 6.5 KB, free: 3.0 GB)
20/04/14 08:19:49 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 178.62.199.118:37315 (size: 6.5 KB, free: 3.0 GB)
20/04/14 08:19:50 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.199.118:33175 (size: 32.4 KB, free: 3.0 GB)
20/04/14 08:19:50 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.198.251:43183 (size: 32.4 KB, free: 3.0 GB)
20/04/14 08:19:50 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.199.118:37315 (size: 32.4 KB, free: 3.0 GB)
20/04/14 08:19:51 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 1321 ms on 178.62.199.118 (executor 3) (1/9)
20/04/14 08:19:51 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1867 ms on 178.62.199.118 (executor 3) (2/9)
20/04/14 08:19:51 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1889 ms on 178.62.199.118 (executor 3) (3/9)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 2980 ms on 178.62.198.251 (executor 1) (4/9)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 3020 ms on 178.62.198.251 (executor 1) (5/9)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 3054 ms on 178.62.198.251 (executor 1) (6/9)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 3076 ms on 178.62.199.118 (executor 2) (7/9)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 3077 ms on 178.62.199.118 (executor 2) (8/9)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3082 ms on 178.62.199.118 (executor 2) (9/9)
20/04/14 08:19:52 INFO cluster.YarnClusterScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/04/14 08:19:52 INFO scheduler.DAGScheduler: ShuffleMapStage 1 (rdd at DatasetUtils.scala:68) finished in 3.124 s
20/04/14 08:19:52 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/04/14 08:19:52 INFO scheduler.DAGScheduler: running: Set()
20/04/14 08:19:52 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 2)
20/04/14 08:19:52 INFO scheduler.DAGScheduler: failed: Set()
20/04/14 08:19:52 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[23] at map at KMeans.scala:248), which has no missing parents
20/04/14 08:19:52 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.9 KB, free 3.0 GB)
20/04/14 08:19:52 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.0 KB, free 3.0 GB)
20/04/14 08:19:52 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.198.251:45915 (size: 8.0 KB, free: 3.0 GB)
20/04/14 08:19:52 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1163
20/04/14 08:19:52 INFO scheduler.DAGScheduler: Submitting 18 missing tasks from ResultStage 2 (MapPartitionsRDD[23] at map at KMeans.scala:248) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
20/04/14 08:19:52 INFO cluster.YarnClusterScheduler: Adding task set 2.0 with 18 tasks
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, 178.62.199.118, executor 2, partition 0, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, 178.62.198.251, executor 1, partition 1, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, 178.62.199.118, executor 3, partition 2, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, 178.62.199.118, executor 2, partition 3, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, 178.62.198.251, executor 1, partition 4, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 2.0 (TID 15, 178.62.199.118, executor 3, partition 5, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 2.0 (TID 16, 178.62.199.118, executor 2, partition 6, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 2.0 (TID 17, 178.62.198.251, executor 1, partition 7, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:52 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 2.0 (TID 18, 178.62.199.118, executor 3, partition 8, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:52 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.199.118:33175 (size: 8.0 KB, free: 3.0 GB)
20/04/14 08:19:52 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.198.251:43183 (size: 8.0 KB, free: 3.0 GB)
20/04/14 08:19:52 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.199.118:37315 (size: 8.0 KB, free: 3.0 GB)
20/04/14 08:19:52 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 178.62.199.118:37564
20/04/14 08:19:52 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 178.62.198.251:43958
20/04/14 08:19:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 178.62.199.118:37560
20/04/14 08:19:53 INFO storage.BlockManagerInfo: Added rdd_7_4 in memory on 178.62.198.251:43183 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:19:53 INFO storage.BlockManagerInfo: Added rdd_7_7 in memory on 178.62.198.251:43183 (size: 7.3 MB, free: 3.0 GB)
20/04/14 08:19:53 INFO storage.BlockManagerInfo: Added rdd_7_1 in memory on 178.62.198.251:43183 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:19:53 INFO storage.BlockManagerInfo: Added rdd_7_5 in memory on 178.62.199.118:33175 (size: 7.1 MB, free: 3.0 GB)
20/04/14 08:19:53 INFO storage.BlockManagerInfo: Added rdd_7_2 in memory on 178.62.199.118:33175 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:19:53 INFO storage.BlockManagerInfo: Added rdd_7_8 in memory on 178.62.199.118:33175 (size: 7.2 MB, free: 3.0 GB)
20/04/14 08:19:53 INFO storage.BlockManagerInfo: Added rdd_7_3 in memory on 178.62.199.118:37315 (size: 7.2 MB, free: 3.0 GB)
20/04/14 08:19:53 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on 178.62.199.118:37315 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:19:53 INFO storage.BlockManagerInfo: Added rdd_7_6 in memory on 178.62.199.118:37315 (size: 7.3 MB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_4 in memory on 178.62.198.251:43183 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_1 in memory on 178.62.198.251:43183 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_7 in memory on 178.62.198.251:43183 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_8 in memory on 178.62.199.118:33175 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_5 in memory on 178.62.199.118:33175 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_2 in memory on 178.62.199.118:33175 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 2.0 (TID 19, 178.62.198.251, executor 1, partition 9, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 2.0 (TID 17) in 1429 ms on 178.62.198.251 (executor 1) (1/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 2.0 (TID 20, 178.62.199.118, executor 3, partition 10, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 2.0 (TID 18) in 1434 ms on 178.62.199.118 (executor 3) (2/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 2.0 (TID 21, 178.62.199.118, executor 3, partition 11, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 2.0 (TID 15) in 1436 ms on 178.62.199.118 (executor 3) (3/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 2.0 (TID 22, 178.62.199.118, executor 3, partition 12, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 1439 ms on 178.62.199.118 (executor 3) (4/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 2.0 (TID 23, 178.62.198.251, executor 1, partition 13, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 1442 ms on 178.62.198.251 (executor 1) (5/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 2.0 (TID 24, 178.62.198.251, executor 1, partition 14, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 1444 ms on 178.62.198.251 (executor 1) (6/18)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_7_9 in memory on 178.62.198.251:43183 (size: 7.5 MB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_7_14 in memory on 178.62.198.251:43183 (size: 7.6 MB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_7_13 in memory on 178.62.198.251:43183 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_9 in memory on 178.62.198.251:43183 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_14 in memory on 178.62.198.251:43183 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_13 in memory on 178.62.198.251:43183 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 2.0 (TID 25, 178.62.198.251, executor 1, partition 15, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 2.0 (TID 19) in 151 ms on 178.62.198.251 (executor 1) (7/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 16.0 in stage 2.0 (TID 26, 178.62.198.251, executor 1, partition 16, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 2.0 (TID 24) in 143 ms on 178.62.198.251 (executor 1) (8/18)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_7_12 in memory on 178.62.199.118:33175 (size: 7.3 MB, free: 3.0 GB)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 2.0 (TID 27, 178.62.198.251, executor 1, partition 17, NODE_LOCAL, 8067 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 2.0 (TID 23) in 162 ms on 178.62.198.251 (executor 1) (9/18)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_7_11 in memory on 178.62.199.118:33175 (size: 7.3 MB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_7_10 in memory on 178.62.199.118:33175 (size: 7.2 MB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_7_16 in memory on 178.62.198.251:43183 (size: 7.2 MB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_7_15 in memory on 178.62.198.251:43183 (size: 7.2 MB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_7_17 in memory on 178.62.198.251:43183 (size: 7.4 MB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_12 in memory on 178.62.199.118:33175 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_11 in memory on 178.62.199.118:33175 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_0 in memory on 178.62.199.118:37315 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_3 in memory on 178.62.199.118:37315 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_6 in memory on 178.62.199.118:37315 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_10 in memory on 178.62.199.118:33175 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_15 in memory on 178.62.198.251:43183 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_16 in memory on 178.62.198.251:43183 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added rdd_21_17 in memory on 178.62.198.251:43183 (size: 32.5 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 2.0 (TID 22) in 301 ms on 178.62.199.118 (executor 3) (10/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 2.0 (TID 21) in 313 ms on 178.62.199.118 (executor 3) (11/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 16.0 in stage 2.0 (TID 26) in 168 ms on 178.62.198.251 (executor 1) (12/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 17.0 in stage 2.0 (TID 27) in 151 ms on 178.62.198.251 (executor 1) (13/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 2.0 (TID 25) in 178 ms on 178.62.198.251 (executor 1) (14/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 2.0 (TID 20) in 374 ms on 178.62.199.118 (executor 3) (15/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 2.0 (TID 16) in 1837 ms on 178.62.199.118 (executor 2) (16/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 1838 ms on 178.62.199.118 (executor 2) (17/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 1841 ms on 178.62.199.118 (executor 2) (18/18)
20/04/14 08:19:54 INFO cluster.YarnClusterScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/04/14 08:19:54 INFO scheduler.DAGScheduler: ResultStage 2 (takeSample at KMeans.scala:386) finished in 1.884 s
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Job 1 finished: takeSample at KMeans.scala:386, took 5.037780 s
20/04/14 08:19:54 INFO spark.SparkContext: Starting job: takeSample at KMeans.scala:386
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Got job 2 (takeSample at KMeans.scala:386) with 18 output partitions
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (takeSample at KMeans.scala:386)
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (PartitionwiseSampledRDD[25] at takeSample at KMeans.scala:386), which has no missing parents
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.6 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.198.251:45915 (size: 8.3 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1163
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Submitting 18 missing tasks from ResultStage 4 (PartitionwiseSampledRDD[25] at takeSample at KMeans.scala:386) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
20/04/14 08:19:54 INFO cluster.YarnClusterScheduler: Adding task set 4.0 with 18 tasks
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 28, 178.62.198.251, executor 1, partition 1, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 4.0 (TID 29, 178.62.199.118, executor 3, partition 2, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 30, 178.62.199.118, executor 2, partition 0, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 4.0 (TID 31, 178.62.198.251, executor 1, partition 4, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 4.0 (TID 32, 178.62.199.118, executor 3, partition 5, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 4.0 (TID 33, 178.62.199.118, executor 2, partition 3, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 4.0 (TID 34, 178.62.198.251, executor 1, partition 7, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 4.0 (TID 35, 178.62.199.118, executor 3, partition 8, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 4.0 (TID 36, 178.62.199.118, executor 2, partition 6, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.199.118:33175 (size: 8.3 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.198.251:43183 (size: 8.3 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 4.0 (TID 37, 178.62.198.251, executor 1, partition 9, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 28) in 64 ms on 178.62.198.251 (executor 1) (1/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 4.0 (TID 38, 178.62.198.251, executor 1, partition 13, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 4.0 (TID 39, 178.62.198.251, executor 1, partition 14, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 4.0 (TID 34) in 65 ms on 178.62.198.251 (executor 1) (2/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 4.0 (TID 31) in 66 ms on 178.62.198.251 (executor 1) (3/18)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.199.118:37315 (size: 8.3 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 4.0 (TID 40, 178.62.199.118, executor 3, partition 10, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 4.0 (TID 32) in 75 ms on 178.62.199.118 (executor 3) (4/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 4.0 (TID 41, 178.62.199.118, executor 3, partition 11, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 4.0 (TID 35) in 86 ms on 178.62.199.118 (executor 3) (5/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 4.0 (TID 42, 178.62.199.118, executor 3, partition 12, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 4.0 (TID 29) in 93 ms on 178.62.199.118 (executor 3) (6/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 4.0 (TID 43, 178.62.198.251, executor 1, partition 15, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 4.0 (TID 38) in 47 ms on 178.62.198.251 (executor 1) (7/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 16.0 in stage 4.0 (TID 44, 178.62.198.251, executor 1, partition 16, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 4.0 (TID 37) in 50 ms on 178.62.198.251 (executor 1) (8/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 4.0 (TID 45, 178.62.198.251, executor 1, partition 17, PROCESS_LOCAL, 8176 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 4.0 (TID 39) in 49 ms on 178.62.198.251 (executor 1) (9/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 4.0 (TID 40) in 42 ms on 178.62.199.118 (executor 3) (10/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 4.0 (TID 41) in 53 ms on 178.62.199.118 (executor 3) (11/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 4.0 (TID 42) in 48 ms on 178.62.199.118 (executor 3) (12/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 30) in 143 ms on 178.62.199.118 (executor 2) (13/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 4.0 (TID 33) in 143 ms on 178.62.199.118 (executor 2) (14/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 4.0 (TID 36) in 142 ms on 178.62.199.118 (executor 2) (15/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 16.0 in stage 4.0 (TID 44) in 34 ms on 178.62.198.251 (executor 1) (16/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 4.0 (TID 43) in 46 ms on 178.62.198.251 (executor 1) (17/18)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Finished task 17.0 in stage 4.0 (TID 45) in 48 ms on 178.62.198.251 (executor 1) (18/18)
20/04/14 08:19:54 INFO cluster.YarnClusterScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/04/14 08:19:54 INFO scheduler.DAGScheduler: ResultStage 4 (takeSample at KMeans.scala:386) finished in 0.169 s
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Job 2 finished: takeSample at KMeans.scala:386, took 0.175118 s
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.0 MB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.9 KB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.198.251:45915 (size: 10.9 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO spark.SparkContext: Created broadcast 5 from broadcast at KMeans.scala:400
20/04/14 08:19:54 INFO spark.SparkContext: Starting job: sum at KMeans.scala:406
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Got job 3 (sum at KMeans.scala:406) with 18 output partitions
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (sum at KMeans.scala:406)
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at map at KMeans.scala:403), which has no missing parents
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.7 KB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.198.251:45915 (size: 8.7 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1163
20/04/14 08:19:54 INFO scheduler.DAGScheduler: Submitting 18 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at map at KMeans.scala:403) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
20/04/14 08:19:54 INFO cluster.YarnClusterScheduler: Adding task set 6.0 with 18 tasks
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 6.0 (TID 46, 178.62.199.118, executor 3, partition 2, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 47, 178.62.199.118, executor 2, partition 0, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 48, 178.62.198.251, executor 1, partition 1, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 6.0 (TID 49, 178.62.199.118, executor 3, partition 5, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 6.0 (TID 50, 178.62.199.118, executor 2, partition 3, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 6.0 (TID 51, 178.62.198.251, executor 1, partition 4, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 6.0 (TID 52, 178.62.199.118, executor 3, partition 8, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 6.0 (TID 53, 178.62.199.118, executor 2, partition 6, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:54 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 6.0 (TID 54, 178.62.198.251, executor 1, partition 7, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.198.251:43183 (size: 8.7 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.199.118:33175 (size: 8.7 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.199.118:37315 (size: 8.7 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.198.251:43183 (size: 10.9 KB, free: 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.199.118:33175 (size: 10.9 KB, free: 3.0 GB)
20/04/14 08:19:55 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.199.118:37315 (size: 10.9 KB, free: 3.0 GB)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 6.0 (TID 55, 178.62.198.251, executor 1, partition 9, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 6.0 (TID 56, 178.62.198.251, executor 1, partition 13, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 6.0 (TID 57, 178.62.198.251, executor 1, partition 14, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 6.0 (TID 51, 178.62.198.251, executor 1): java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 7.0 in stage 6.0 (TID 54) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 1]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 1.0 in stage 6.0 (TID 48) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 2]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 6.0 (TID 58, 178.62.199.118, executor 3, partition 10, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 5.0 in stage 6.0 (TID 49) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 3]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 5.1 in stage 6.0 (TID 59, 178.62.199.118, executor 3, partition 5, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 2.0 in stage 6.0 (TID 46) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 4]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 2.1 in stage 6.0 (TID 60, 178.62.199.118, executor 3, partition 2, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 1.1 in stage 6.0 (TID 61, 178.62.198.251, executor 1, partition 1, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 6.0 in stage 6.0 (TID 53) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 5]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 6.1 in stage 6.0 (TID 62, 178.62.199.118, executor 2, partition 6, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 8.0 in stage 6.0 (TID 52) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 6]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 3.0 in stage 6.0 (TID 50) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 7]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 13.0 in stage 6.0 (TID 56) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 8]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 3.1 in stage 6.0 (TID 63, 178.62.199.118, executor 2, partition 3, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 0.0 in stage 6.0 (TID 47) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 9]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 6.0 (TID 64, 178.62.199.118, executor 2, partition 0, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 13.1 in stage 6.0 (TID 65, 178.62.198.251, executor 1, partition 13, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 7.1 in stage 6.0 (TID 66, 178.62.198.251, executor 1, partition 7, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 9.0 in stage 6.0 (TID 55) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 10]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 14.0 in stage 6.0 (TID 57) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 11]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 8.1 in stage 6.0 (TID 67, 178.62.199.118, executor 3, partition 8, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 10.0 in stage 6.0 (TID 58) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 12]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 10.1 in stage 6.0 (TID 68, 178.62.199.118, executor 3, partition 10, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 5.1 in stage 6.0 (TID 59) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 13]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 14.1 in stage 6.0 (TID 69, 178.62.198.251, executor 1, partition 14, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 1.1 in stage 6.0 (TID 61) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 14]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 6.1 in stage 6.0 (TID 62) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 15]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 6.2 in stage 6.0 (TID 70, 178.62.199.118, executor 2, partition 6, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 5.2 in stage 6.0 (TID 71, 178.62.199.118, executor 3, partition 5, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 2.1 in stage 6.0 (TID 60) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 16]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 1.2 in stage 6.0 (TID 72, 178.62.198.251, executor 1, partition 1, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 9.1 in stage 6.0 (TID 73, 178.62.198.251, executor 1, partition 9, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 13.1 in stage 6.0 (TID 65) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 17]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 7.1 in stage 6.0 (TID 66) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 18]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 0.1 in stage 6.0 (TID 64) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 19]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 0.2 in stage 6.0 (TID 74, 178.62.199.118, executor 2, partition 0, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 2.2 in stage 6.0 (TID 75, 178.62.199.118, executor 3, partition 2, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 10.1 in stage 6.0 (TID 68) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 20]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 7.2 in stage 6.0 (TID 76, 178.62.198.251, executor 1, partition 7, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 14.1 in stage 6.0 (TID 69) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 21]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 14.2 in stage 6.0 (TID 77, 178.62.198.251, executor 1, partition 14, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 1.2 in stage 6.0 (TID 72) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 22]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 6.2 in stage 6.0 (TID 70) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 23]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 6.3 in stage 6.0 (TID 78, 178.62.199.118, executor 2, partition 6, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 1.3 in stage 6.0 (TID 79, 178.62.198.251, executor 1, partition 1, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 9.1 in stage 6.0 (TID 73) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 24]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 3.1 in stage 6.0 (TID 63) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 25]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 3.2 in stage 6.0 (TID 80, 178.62.199.118, executor 2, partition 3, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 10.2 in stage 6.0 (TID 81, 178.62.199.118, executor 3, partition 10, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 5.2 in stage 6.0 (TID 71) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 26]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 0.2 in stage 6.0 (TID 74) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 27]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 6.0 (TID 82, 178.62.199.118, executor 2, partition 0, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 9.2 in stage 6.0 (TID 83, 178.62.198.251, executor 1, partition 9, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 7.2 in stage 6.0 (TID 76) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 28]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Starting task 5.3 in stage 6.0 (TID 84, 178.62.199.118, executor 3, partition 5, PROCESS_LOCAL, 8099 bytes)
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 8.1 in stage 6.0 (TID 67) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 29]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 6.3 in stage 6.0 (TID 78) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 30]
20/04/14 08:19:55 ERROR scheduler.TaskSetManager: Task 6 in stage 6.0 failed 4 times; aborting job
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 2.2 in stage 6.0 (TID 75) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 31]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 14.2 in stage 6.0 (TID 77) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 32]
20/04/14 08:19:55 INFO cluster.YarnClusterScheduler: Cancelling stage 6
20/04/14 08:19:55 INFO cluster.YarnClusterScheduler: Killing all running tasks in stage 6: Stage cancelled
20/04/14 08:19:55 INFO cluster.YarnClusterScheduler: Stage 6 was cancelled
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 1.3 in stage 6.0 (TID 79) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 33]
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 0.3 in stage 6.0 (TID 82) on 178.62.199.118, executor 2: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 34]
20/04/14 08:19:55 INFO scheduler.DAGScheduler: ResultStage 6 (sum at KMeans.scala:406) failed in 0.314 s due to Job aborted due to stage failure: Task 6 in stage 6.0 failed 4 times, most recent failure: Lost task 6.3 in stage 6.0 (TID 78, 178.62.199.118, executor 2): java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 10.2 in stage 6.0 (TID 81) on 178.62.199.118, executor 3: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 35]
20/04/14 08:19:55 INFO scheduler.DAGScheduler: Job 3 failed: sum at KMeans.scala:406, took 0.323716 s
20/04/14 08:19:55 ERROR util.Instrumentation: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 6.0 failed 4 times, most recent failure: Lost task 6.3 in stage 6.0 (TID 78, 178.62.199.118, executor 2): java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1143)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.fold(RDD.scala:1137)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply$mcD$sp(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.DoubleRDDFunctions.sum(DoubleRDDFunctions.scala:34)
	at org.apache.spark.mllib.clustering.KMeans.initKMeansParallel(KMeans.scala:406)
	at org.apache.spark.mllib.clustering.KMeans.runAlgorithm(KMeans.scala:282)
	at org.apache.spark.mllib.clustering.KMeans.run(KMeans.scala:251)
	at org.apache.spark.ml.clustering.KMeans$$anonfun$fit$1.apply(KMeans.scala:362)
	at org.apache.spark.ml.clustering.KMeans$$anonfun$fit$1.apply(KMeans.scala:340)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:340)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more

20/04/14 08:19:55 INFO scheduler.TaskSetManager: Lost task 9.2 in stage 6.0 (TID 83) on 178.62.198.251, executor 1: java.lang.AssertionError (assertion failed: Cosine distance is not defined for zero-length vectors.) [duplicate 36]
20/04/14 08:19:55 WARN scheduler.TaskSetManager: Lost task 5.3 in stage 6.0 (TID 84, 178.62.199.118, executor 3): TaskKilled (Stage cancelled)
20/04/14 08:19:55 WARN scheduler.TaskSetManager: Lost task 3.2 in stage 6.0 (TID 80, 178.62.199.118, executor 2): TaskKilled (Stage cancelled)
20/04/14 08:19:55 INFO cluster.YarnClusterScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/04/14 08:19:55 ERROR yarn.ApplicationMaster: User application exited with status 1
20/04/14 08:19:55 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 1, (reason: User application exited with status 1)
20/04/14 08:19:55 INFO spark.SparkContext: Invoking stop() from shutdown hook
20/04/14 08:19:55 INFO server.AbstractConnector: Stopped Spark@228b8e4d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
20/04/14 08:19:55 INFO ui.SparkUI: Stopped Spark web UI at http://178.62.198.251:38625
20/04/14 08:19:55 INFO yarn.YarnAllocator: Driver requested a total number of 0 executor(s).
20/04/14 08:19:55 INFO cluster.YarnClusterSchedulerBackend: Shutting down all executors
20/04/14 08:19:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/04/14 08:19:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
20/04/14 08:19:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/04/14 08:19:55 INFO memory.MemoryStore: MemoryStore cleared
20/04/14 08:19:55 INFO storage.BlockManager: BlockManager stopped
20/04/14 08:19:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
20/04/14 08:19:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/04/14 08:19:55 INFO spark.SparkContext: Successfully stopped SparkContext
20/04/14 08:19:55 INFO util.ShutdownHookManager: Shutdown hook called
20/04/14 08:19:55 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/spark-ee29f08e-3394-4277-8ee7-75e3c89ca447/pyspark-01ce792d-0f01-4ef3-a661-d2f59343d58a
20/04/14 08:19:55 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/spark-ee29f08e-3394-4277-8ee7-75e3c89ca447
End of LogType:stderr

LogType:stdout
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:10071
Log Contents:
Traceback (most recent call last):
  File "clustering.py", line 312, in <module>
    result_dfs_list=result_dfs,
  File "clustering.py", line 54, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 72, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 264, in perform_experiment
    in_file=in_file, distance=distance, k=k, ModelCls=ModelCls
  File "clustering.py", line 54, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 72, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 137, in perform_clustering_kmeans
    model = fit(model_algo, df)
  File "clustering.py", line 54, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 94, in fit
    model = model_algo.fit(df)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/ml/base.py", line 132, in fit
    return self._fit(dataset)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/ml/wrapper.py", line 295, in _fit
    java_model = self._fit_java(dataset)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/ml/wrapper.py", line 292, in _fit_java
    return self._java_obj.fit(dataset._jdf)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o50.fit.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 6.0 failed 4 times, most recent failure: Lost task 6.3 in stage 6.0 (TID 78, 178.62.199.118, executor 2): java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1143)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.fold(RDD.scala:1137)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply$mcD$sp(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.DoubleRDDFunctions.sum(DoubleRDDFunctions.scala:34)
	at org.apache.spark.mllib.clustering.KMeans.initKMeansParallel(KMeans.scala:406)
	at org.apache.spark.mllib.clustering.KMeans.runAlgorithm(KMeans.scala:282)
	at org.apache.spark.mllib.clustering.KMeans.run(KMeans.scala:251)
	at org.apache.spark.ml.clustering.KMeans$$anonfun$fit$1.apply(KMeans.scala:362)
	at org.apache.spark.ml.clustering.KMeans$$anonfun$fit$1.apply(KMeans.scala:340)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:340)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more

End of LogType:stdout



Container: container_1586849858644_0008_02_000002 on 178.62.198.251_42461
===========================================================================
LogType:stderr
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:69405
Log Contents:
20/04/14 08:20:00 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22511@178.62.198.251
20/04/14 08:20:00 INFO util.SignalUtils: Registered signal handler for TERM
20/04/14 08:20:00 INFO util.SignalUtils: Registered signal handler for HUP
20/04/14 08:20:00 INFO util.SignalUtils: Registered signal handler for INT
20/04/14 08:20:01 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:20:01 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:20:01 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:20:01 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:20:01 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:20:01 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:42739 after 48 ms (0 ms spent in bootstraps)
20/04/14 08:20:01 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:20:01 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:20:01 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:20:01 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:20:01 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:20:01 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:42739 after 3 ms (0 ms spent in bootstraps)
20/04/14 08:20:01 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/blockmgr-1d5712c5-5e8b-405d-9c7c-6969b5286913
20/04/14 08:20:01 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/14 08:20:01 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.198.251:42739
20/04/14 08:20:01 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/14 08:20:01 INFO executor.Executor: Starting executor ID 1 on host 178.62.198.251
20/04/14 08:20:01 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45803.
20/04/14 08:20:01 INFO netty.NettyBlockTransferService: Server created on 178.62.198.251:45803
20/04/14 08:20:01 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/14 08:20:01 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(1, 178.62.198.251, 45803, None)
20/04/14 08:20:01 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(1, 178.62.198.251, 45803, None)
20/04/14 08:20:01 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(1, 178.62.198.251, 45803, None)
20/04/14 08:20:05 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 0
20/04/14 08:20:05 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
20/04/14 08:20:05 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
20/04/14 08:20:05 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:36493 after 2 ms (0 ms spent in bootstraps)
20/04/14 08:20:05 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.2 KB, free 3.0 GB)
20/04/14 08:20:05 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 109 ms
20/04/14 08:20:05 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 127.0 KB, free 3.0 GB)
20/04/14 08:20:06 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2496 bytes result sent to driver
20/04/14 08:20:08 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2
20/04/14 08:20:08 INFO executor.Executor: Running task 1.0 in stage 1.0 (TID 2)
20/04/14 08:20:08 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 5
20/04/14 08:20:08 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 8
20/04/14 08:20:08 INFO executor.Executor: Running task 7.0 in stage 1.0 (TID 8)
20/04/14 08:20:08 INFO executor.Executor: Running task 4.0 in stage 1.0 (TID 5)
20/04/14 08:20:08 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
20/04/14 08:20:08 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KB, free 3.0 GB)
20/04/14 08:20:08 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 11 ms
20/04/14 08:20:08 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.1 KB, free 3.0 GB)
20/04/14 08:20:08 INFO codegen.CodeGenerator: Code generated in 194.426102 ms
20/04/14 08:20:08 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00003-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5604846, partition values: [empty row]
20/04/14 08:20:08 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00004-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5732549, partition values: [empty row]
20/04/14 08:20:08 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00000-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5209247, partition values: [empty row]
20/04/14 08:20:08 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/14 08:20:08 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/14 08:20:08 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 11 ms
20/04/14 08:20:09 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/14 08:20:09 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:20:09 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:20:09 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:20:09 INFO codegen.CodeGenerator: Code generated in 60.363026 ms
20/04/14 08:20:09 INFO codegen.CodeGenerator: Code generated in 12.47766 ms
20/04/14 08:20:09 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5980 records.
20/04/14 08:20:09 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 9550 records.
20/04/14 08:20:09 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11557 records.
20/04/14 08:20:09 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:20:09 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:20:09 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:20:09 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:20:09 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:20:09 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:20:09 INFO hadoop.InternalParquetRecordReader: block read in memory in 35 ms. row count = 5980
20/04/14 08:20:09 INFO hadoop.InternalParquetRecordReader: block read in memory in 34 ms. row count = 9550
20/04/14 08:20:09 INFO hadoop.InternalParquetRecordReader: block read in memory in 34 ms. row count = 11557
20/04/14 08:20:10 INFO executor.Executor: Finished task 7.0 in stage 1.0 (TID 8). 1530 bytes result sent to driver
20/04/14 08:20:10 INFO executor.Executor: Finished task 4.0 in stage 1.0 (TID 5). 1530 bytes result sent to driver
20/04/14 08:20:10 INFO executor.Executor: Finished task 1.0 in stage 1.0 (TID 2). 1487 bytes result sent to driver
20/04/14 08:20:12 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 10
20/04/14 08:20:12 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 10)
20/04/14 08:20:12 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 13
20/04/14 08:20:12 INFO executor.Executor: Running task 3.0 in stage 2.0 (TID 13)
20/04/14 08:20:12 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 16
20/04/14 08:20:12 INFO executor.Executor: Running task 6.0 in stage 2.0 (TID 16)
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
20/04/14 08:20:12 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/14 08:20:12 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.0 KB, free 3.0 GB)
20/04/14 08:20:12 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 10 ms
20/04/14 08:20:12 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.9 KB, free 3.0 GB)
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@178.62.198.251:42739)
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Got the output locations
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:12 INFO client.TransportClientFactory: Successfully created connection to /178.62.199.118:37771 after 1 ms (0 ms spent in bootstraps)
20/04/14 08:20:12 INFO client.TransportClientFactory: Successfully created connection to /178.62.199.118:37619 after 9 ms (0 ms spent in bootstraps)
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 21 ms
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 21 ms
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 22 ms
20/04/14 08:20:12 INFO memory.MemoryStore: Block rdd_7_3 stored as values in memory (estimated size 7.2 MB, free 3.0 GB)
20/04/14 08:20:12 INFO memory.MemoryStore: Block rdd_7_0 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:20:12 INFO memory.MemoryStore: Block rdd_7_6 stored as values in memory (estimated size 7.3 MB, free 3.0 GB)
20/04/14 08:20:12 INFO codegen.CodeGenerator: Code generated in 6.084905 ms
20/04/14 08:20:12 INFO codegen.CodeGenerator: Code generated in 33.378184 ms
20/04/14 08:20:13 INFO codegen.CodeGenerator: Code generated in 14.349558 ms
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_0 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_6 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_3 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 10). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO executor.Executor: Finished task 6.0 in stage 2.0 (TID 16). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 19
20/04/14 08:20:13 INFO executor.Executor: Running task 9.0 in stage 2.0 (TID 19)
20/04/14 08:20:13 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 20
20/04/14 08:20:13 INFO executor.Executor: Running task 10.0 in stage 2.0 (TID 20)
20/04/14 08:20:13 INFO executor.Executor: Finished task 3.0 in stage 2.0 (TID 13). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 21
20/04/14 08:20:13 INFO executor.Executor: Running task 11.0 in stage 2.0 (TID 21)
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 1 ms
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 2 ms
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 1 ms
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_7_9 stored as values in memory (estimated size 7.5 MB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_7_11 stored as values in memory (estimated size 7.3 MB, free 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_7_10 stored as values in memory (estimated size 7.2 MB, free 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_11 locally
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_9 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_11 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_10 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO executor.Executor: Finished task 9.0 in stage 2.0 (TID 19). 1626 bytes result sent to driver
20/04/14 08:20:13 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 25
20/04/14 08:20:13 INFO executor.Executor: Running task 15.0 in stage 2.0 (TID 25)
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 1 ms
20/04/14 08:20:13 INFO executor.Executor: Finished task 11.0 in stage 2.0 (TID 21). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO executor.Executor: Finished task 10.0 in stage 2.0 (TID 20). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 26
20/04/14 08:20:13 INFO executor.Executor: Running task 16.0 in stage 2.0 (TID 26)
20/04/14 08:20:13 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 27
20/04/14 08:20:13 INFO executor.Executor: Running task 17.0 in stage 2.0 (TID 27)
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 1 ms
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 1 ms
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_7_15 stored as values in memory (estimated size 7.2 MB, free 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_15 locally
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_7_16 stored as values in memory (estimated size 7.2 MB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_7_17 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_16 locally
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_15 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_17 locally
20/04/14 08:20:13 INFO executor.Executor: Finished task 15.0 in stage 2.0 (TID 25). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_16 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_17 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO executor.Executor: Finished task 16.0 in stage 2.0 (TID 26). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO executor.Executor: Finished task 17.0 in stage 2.0 (TID 27). 1669 bytes result sent to driver
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 30
20/04/14 08:20:14 INFO executor.Executor: Running task 0.0 in stage 4.0 (TID 30)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 33
20/04/14 08:20:14 INFO executor.Executor: Running task 3.0 in stage 4.0 (TID 33)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 36
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/14 08:20:14 INFO executor.Executor: Running task 6.0 in stage 4.0 (TID 36)
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.0 GB)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 8 ms
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.6 KB, free 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:20:14 INFO executor.Executor: Finished task 3.0 in stage 4.0 (TID 33). 4362 bytes result sent to driver
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 37
20/04/14 08:20:14 INFO executor.Executor: Running task 9.0 in stage 4.0 (TID 37)
20/04/14 08:20:14 INFO executor.Executor: Finished task 0.0 in stage 4.0 (TID 30). 10453 bytes result sent to driver
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 38
20/04/14 08:20:14 INFO executor.Executor: Running task 10.0 in stage 4.0 (TID 38)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:20:14 INFO executor.Executor: Finished task 6.0 in stage 4.0 (TID 36). 6407 bytes result sent to driver
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 39
20/04/14 08:20:14 INFO executor.Executor: Running task 11.0 in stage 4.0 (TID 39)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_11 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_11 locally
20/04/14 08:20:14 INFO executor.Executor: Finished task 9.0 in stage 4.0 (TID 37). 2085 bytes result sent to driver
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 42
20/04/14 08:20:14 INFO executor.Executor: Running task 15.0 in stage 4.0 (TID 42)
20/04/14 08:20:14 INFO executor.Executor: Finished task 10.0 in stage 4.0 (TID 38). 2706 bytes result sent to driver
20/04/14 08:20:14 INFO executor.Executor: Finished task 11.0 in stage 4.0 (TID 39). 1736 bytes result sent to driver
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_15 locally
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 43
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 44
20/04/14 08:20:14 INFO executor.Executor: Running task 17.0 in stage 4.0 (TID 44)
20/04/14 08:20:14 INFO executor.Executor: Running task 16.0 in stage 4.0 (TID 43)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_15 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_17 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_17 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_16 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_16 locally
20/04/14 08:20:14 INFO executor.Executor: Finished task 15.0 in stage 4.0 (TID 42). 5857 bytes result sent to driver
20/04/14 08:20:14 INFO executor.Executor: Finished task 17.0 in stage 4.0 (TID 44). 3122 bytes result sent to driver
20/04/14 08:20:14 INFO executor.Executor: Finished task 16.0 in stage 4.0 (TID 43). 1765 bytes result sent to driver
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 47
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 50
20/04/14 08:20:14 INFO executor.Executor: Running task 3.0 in stage 6.0 (TID 50)
20/04/14 08:20:14 INFO executor.Executor: Running task 0.0 in stage 6.0 (TID 47)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 53
20/04/14 08:20:14 INFO executor.Executor: Running task 6.0 in stage 6.0 (TID 53)
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.7 KB, free 3.0 GB)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 14 ms
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.5 KB, free 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.6 KB, free 3.0 GB)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 7 ms
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.0 MB, free 3.0 GB)
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_6 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_6 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_3 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_3 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_0 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_0 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 6.0 in stage 6.0 (TID 53)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 0.0 in stage 6.0 (TID 47)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 3.0 in stage 6.0 (TID 50)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 55
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 56
20/04/14 08:20:14 INFO executor.Executor: Running task 10.0 in stage 6.0 (TID 56)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 57
20/04/14 08:20:14 INFO executor.Executor: Running task 11.0 in stage 6.0 (TID 57)
20/04/14 08:20:14 INFO executor.Executor: Running task 9.0 in stage 6.0 (TID 55)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_11 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_11 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_11 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_11 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_11 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_11 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 11.0 in stage 6.0 (TID 57)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_10 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_10 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 10.0 in stage 6.0 (TID 56)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 61
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 62
20/04/14 08:20:14 INFO executor.Executor: Running task 6.1 in stage 6.0 (TID 61)
20/04/14 08:20:14 INFO executor.Executor: Running task 11.1 in stage 6.0 (TID 62)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_11 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_11 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_11 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_11 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_11 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_11 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_9 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_9 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_6 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_6 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 9.0 in stage 6.0 (TID 55)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 11.1 in stage 6.0 (TID 62)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 6.1 in stage 6.0 (TID 61)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 67
20/04/14 08:20:14 INFO executor.Executor: Running task 10.1 in stage 6.0 (TID 67)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 68
20/04/14 08:20:14 INFO executor.Executor: Running task 9.1 in stage 6.0 (TID 68)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 69
20/04/14 08:20:14 INFO executor.Executor: Running task 3.1 in stage 6.0 (TID 69)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_10 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_10 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_3 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_3 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 10.1 in stage 6.0 (TID 67)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 3.1 in stage 6.0 (TID 69)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 73
20/04/14 08:20:14 INFO executor.Executor: Running task 11.2 in stage 6.0 (TID 73)
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_9 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_9 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 76
20/04/14 08:20:14 INFO executor.Executor: Running task 10.2 in stage 6.0 (TID 76)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_11 locally
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 9.1 in stage 6.0 (TID 68)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_11 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_11 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_11 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_11 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_11 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 77
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:20:14 INFO executor.Executor: Running task 3.2 in stage 6.0 (TID 77)
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 11.2 in stage 6.0 (TID 73)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 79
20/04/14 08:20:14 INFO executor.Executor: Running task 9.2 in stage 6.0 (TID 79)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_10 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_10 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 10.2 in stage 6.0 (TID 76)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 81
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_3 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_3 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 3.2 in stage 6.0 (TID 77)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.Executor: Executor is trying to kill task 11.3 in stage 6.0 (TID 81), reason: Stage cancelled
20/04/14 08:20:14 INFO executor.Executor: Executor is trying to kill task 9.2 in stage 6.0 (TID 79), reason: Stage cancelled
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_9 failed due to exception org.apache.spark.TaskKilledException.
20/04/14 08:20:14 INFO executor.Executor: Running task 11.3 in stage 6.0 (TID 81)
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_9 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 INFO executor.Executor: Executor killed task 9.2 in stage 6.0 (TID 79), reason: Stage cancelled
20/04/14 08:20:14 INFO executor.Executor: Executor killed task 11.3 in stage 6.0 (TID 81), reason: Stage cancelled
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/04/14 08:20:14 INFO memory.MemoryStore: MemoryStore cleared
20/04/14 08:20:14 INFO storage.BlockManager: BlockManager stopped
20/04/14 08:20:14 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1586849858644_0008_01_000002 on 178.62.198.251_42461
===========================================================================
LogType:stderr
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:73538
Log Contents:
20/04/14 08:19:40 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22290@178.62.198.251
20/04/14 08:19:40 INFO util.SignalUtils: Registered signal handler for TERM
20/04/14 08:19:40 INFO util.SignalUtils: Registered signal handler for HUP
20/04/14 08:19:40 INFO util.SignalUtils: Registered signal handler for INT
20/04/14 08:19:41 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:19:41 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:19:41 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:19:41 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:19:41 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:19:41 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:38785 after 50 ms (0 ms spent in bootstraps)
20/04/14 08:19:41 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:19:41 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:19:41 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:19:41 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:19:41 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:19:41 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:38785 after 4 ms (0 ms spent in bootstraps)
20/04/14 08:19:42 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/blockmgr-df47e15e-a5bd-401b-b9af-ef3df4bedab2
20/04/14 08:19:42 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/14 08:19:42 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.198.251:38785
20/04/14 08:19:42 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/14 08:19:42 INFO executor.Executor: Starting executor ID 1 on host 178.62.198.251
20/04/14 08:19:42 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43183.
20/04/14 08:19:42 INFO netty.NettyBlockTransferService: Server created on 178.62.198.251:43183
20/04/14 08:19:42 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/14 08:19:42 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(1, 178.62.198.251, 43183, None)
20/04/14 08:19:42 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(1, 178.62.198.251, 43183, None)
20/04/14 08:19:42 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(1, 178.62.198.251, 43183, None)
20/04/14 08:19:49 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2
20/04/14 08:19:49 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 5
20/04/14 08:19:49 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 8
20/04/14 08:19:49 INFO executor.Executor: Running task 7.0 in stage 1.0 (TID 8)
20/04/14 08:19:49 INFO executor.Executor: Running task 4.0 in stage 1.0 (TID 5)
20/04/14 08:19:49 INFO executor.Executor: Running task 1.0 in stage 1.0 (TID 2)
20/04/14 08:19:49 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
20/04/14 08:19:49 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:45915 after 2 ms (0 ms spent in bootstraps)
20/04/14 08:19:49 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KB, free 3.0 GB)
20/04/14 08:19:49 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 82 ms
20/04/14 08:19:49 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.1 KB, free 3.0 GB)
20/04/14 08:19:50 INFO codegen.CodeGenerator: Code generated in 222.986802 ms
20/04/14 08:19:50 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00003-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5604846, partition values: [empty row]
20/04/14 08:19:50 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00004-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5732549, partition values: [empty row]
20/04/14 08:19:50 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00000-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5209247, partition values: [empty row]
20/04/14 08:19:50 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/14 08:19:50 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/14 08:19:50 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 9 ms
20/04/14 08:19:50 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/14 08:19:51 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:19:51 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:19:51 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:19:51 INFO codegen.CodeGenerator: Code generated in 37.682277 ms
20/04/14 08:19:51 INFO codegen.CodeGenerator: Code generated in 19.228977 ms
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5980 records.
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11557 records.
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 9550 records.
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:19:51 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:19:51 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:19:51 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: block read in memory in 38 ms. row count = 5980
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: block read in memory in 38 ms. row count = 11557
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: block read in memory in 38 ms. row count = 9550
20/04/14 08:19:52 INFO executor.Executor: Finished task 7.0 in stage 1.0 (TID 8). 1530 bytes result sent to driver
20/04/14 08:19:52 INFO executor.Executor: Finished task 4.0 in stage 1.0 (TID 5). 1487 bytes result sent to driver
20/04/14 08:19:52 INFO executor.Executor: Finished task 1.0 in stage 1.0 (TID 2). 1487 bytes result sent to driver
20/04/14 08:19:52 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 11
20/04/14 08:19:52 INFO executor.Executor: Running task 1.0 in stage 2.0 (TID 11)
20/04/14 08:19:52 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 14
20/04/14 08:19:52 INFO executor.Executor: Running task 4.0 in stage 2.0 (TID 14)
20/04/14 08:19:52 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 17
20/04/14 08:19:52 INFO executor.Executor: Running task 7.0 in stage 2.0 (TID 17)
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
20/04/14 08:19:52 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/14 08:19:52 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.0 KB, free 3.0 GB)
20/04/14 08:19:52 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 9 ms
20/04/14 08:19:52 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.9 KB, free 3.0 GB)
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@178.62.198.251:38785)
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Got the output locations
20/04/14 08:19:52 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:52 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:52 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:52 INFO client.TransportClientFactory: Successfully created connection to /178.62.199.118:37315 after 5 ms (0 ms spent in bootstraps)
20/04/14 08:19:52 INFO client.TransportClientFactory: Successfully created connection to /178.62.199.118:33175 after 6 ms (0 ms spent in bootstraps)
20/04/14 08:19:53 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 22 ms
20/04/14 08:19:53 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 22 ms
20/04/14 08:19:53 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 20 ms
20/04/14 08:19:53 INFO memory.MemoryStore: Block rdd_7_4 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:19:53 INFO memory.MemoryStore: Block rdd_7_7 stored as values in memory (estimated size 7.3 MB, free 3.0 GB)
20/04/14 08:19:53 INFO memory.MemoryStore: Block rdd_7_1 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:19:53 INFO codegen.CodeGenerator: Code generated in 7.483318 ms
20/04/14 08:19:53 INFO codegen.CodeGenerator: Code generated in 18.326864 ms
20/04/14 08:19:54 INFO codegen.CodeGenerator: Code generated in 15.424459 ms
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_4 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_1 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_7 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO executor.Executor: Finished task 7.0 in stage 2.0 (TID 17). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 4.0 in stage 2.0 (TID 14). 1712 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 19
20/04/14 08:19:54 INFO executor.Executor: Finished task 1.0 in stage 2.0 (TID 11). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Running task 9.0 in stage 2.0 (TID 19)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 23
20/04/14 08:19:54 INFO executor.Executor: Running task 13.0 in stage 2.0 (TID 23)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 24
20/04/14 08:19:54 INFO executor.Executor: Running task 14.0 in stage 2.0 (TID 24)
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 1 ms
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 0 ms
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 6 ms
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_7_9 stored as values in memory (estimated size 7.5 MB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_7_13 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_7_14 stored as values in memory (estimated size 7.6 MB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_14 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_13 locally
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_9 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_14 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_13 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO executor.Executor: Finished task 9.0 in stage 2.0 (TID 19). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 25
20/04/14 08:19:54 INFO executor.Executor: Running task 15.0 in stage 2.0 (TID 25)
20/04/14 08:19:54 INFO executor.Executor: Finished task 14.0 in stage 2.0 (TID 24). 1626 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 26
20/04/14 08:19:54 INFO executor.Executor: Running task 16.0 in stage 2.0 (TID 26)
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 3 ms
20/04/14 08:19:54 INFO executor.Executor: Finished task 13.0 in stage 2.0 (TID 23). 1626 bytes result sent to driver
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 2 ms
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 27
20/04/14 08:19:54 INFO executor.Executor: Running task 17.0 in stage 2.0 (TID 27)
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 1 ms
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_7_16 stored as values in memory (estimated size 7.2 MB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_7_15 stored as values in memory (estimated size 7.2 MB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_7_17 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_15 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_16 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_17 locally
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_15 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_16 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_17 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO executor.Executor: Finished task 16.0 in stage 2.0 (TID 26). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 17.0 in stage 2.0 (TID 27). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 15.0 in stage 2.0 (TID 25). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 28
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 31
20/04/14 08:19:54 INFO executor.Executor: Running task 1.0 in stage 4.0 (TID 28)
20/04/14 08:19:54 INFO executor.Executor: Running task 4.0 in stage 4.0 (TID 31)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 34
20/04/14 08:19:54 INFO executor.Executor: Running task 7.0 in stage 4.0 (TID 34)
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.0 GB)
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 8 ms
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.6 KB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_4 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:19:54 INFO executor.Executor: Finished task 1.0 in stage 4.0 (TID 28). 1319 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 7.0 in stage 4.0 (TID 34). 3479 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 4.0 in stage 4.0 (TID 31). 12761 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 37
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 38
20/04/14 08:19:54 INFO executor.Executor: Running task 13.0 in stage 4.0 (TID 38)
20/04/14 08:19:54 INFO executor.Executor: Running task 9.0 in stage 4.0 (TID 37)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 39
20/04/14 08:19:54 INFO executor.Executor: Running task 14.0 in stage 4.0 (TID 39)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_13 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_13 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_14 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_14 locally
20/04/14 08:19:54 INFO executor.Executor: Finished task 13.0 in stage 4.0 (TID 38). 7412 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 9.0 in stage 4.0 (TID 37). 2738 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 43
20/04/14 08:19:54 INFO executor.Executor: Running task 15.0 in stage 4.0 (TID 43)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 44
20/04/14 08:19:54 INFO executor.Executor: Finished task 14.0 in stage 4.0 (TID 39). 7636 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Running task 16.0 in stage 4.0 (TID 44)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 45
20/04/14 08:19:54 INFO executor.Executor: Running task 17.0 in stage 4.0 (TID 45)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_15 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_16 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_15 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_16 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_17 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_17 locally
20/04/14 08:19:54 INFO executor.Executor: Finished task 16.0 in stage 4.0 (TID 44). 1808 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 15.0 in stage 4.0 (TID 43). 5900 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 17.0 in stage 4.0 (TID 45). 3955 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 48
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 51
20/04/14 08:19:54 INFO executor.Executor: Running task 1.0 in stage 6.0 (TID 48)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 54
20/04/14 08:19:54 INFO executor.Executor: Running task 4.0 in stage 6.0 (TID 51)
20/04/14 08:19:54 INFO executor.Executor: Running task 7.0 in stage 6.0 (TID 54)
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.7 KB, free 3.0 GB)
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 11 ms
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_4 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_4 locally
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.9 KB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 11 ms
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.0 MB, free 3.0 GB)
20/04/14 08:19:54 WARN storage.BlockManager: Putting block rdd_27_1 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:54 WARN storage.BlockManager: Block rdd_27_1 could not be removed as it was not found on disk or in memory
20/04/14 08:19:54 WARN storage.BlockManager: Putting block rdd_27_7 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:54 WARN storage.BlockManager: Block rdd_27_7 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_4 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_4 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 7.0 in stage 6.0 (TID 54)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 1.0 in stage 6.0 (TID 48)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 4.0 in stage 6.0 (TID 51)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 55
20/04/14 08:19:55 INFO executor.Executor: Running task 9.0 in stage 6.0 (TID 55)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 56
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 57
20/04/14 08:19:55 INFO executor.Executor: Running task 14.0 in stage 6.0 (TID 57)
20/04/14 08:19:55 INFO executor.Executor: Running task 13.0 in stage 6.0 (TID 56)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_14 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_13 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_13 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_13 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_14 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_14 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_13 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_14 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_13 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_13 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 13.0 in stage 6.0 (TID 56)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 61
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_9 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_9 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_14 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_14 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO executor.Executor: Running task 1.1 in stage 6.0 (TID 61)
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 9.0 in stage 6.0 (TID 55)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 14.0 in stage 6.0 (TID 57)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 65
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 66
20/04/14 08:19:55 INFO executor.Executor: Running task 13.1 in stage 6.0 (TID 65)
20/04/14 08:19:55 INFO executor.Executor: Running task 7.1 in stage 6.0 (TID 66)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_13 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_1 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_1 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_13 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_13 locally
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 1.1 in stage 6.0 (TID 61)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_13 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 69
20/04/14 08:19:55 INFO executor.Executor: Running task 14.1 in stage 6.0 (TID 69)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_7 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_7 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_14 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_13 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_13 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_14 locally
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 7.1 in stage 6.0 (TID 66)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 13.1 in stage 6.0 (TID 65)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_14 locally
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 72
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 73
20/04/14 08:19:55 INFO executor.Executor: Running task 9.1 in stage 6.0 (TID 73)
20/04/14 08:19:55 INFO executor.Executor: Running task 1.2 in stage 6.0 (TID 72)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_14 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_1 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_1 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_14 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_14 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 14.1 in stage 6.0 (TID 69)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 76
20/04/14 08:19:55 INFO executor.Executor: Running task 7.2 in stage 6.0 (TID 76)
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 1.2 in stage 6.0 (TID 72)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_9 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_9 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 77
20/04/14 08:19:55 INFO executor.Executor: Running task 14.2 in stage 6.0 (TID 77)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 9.1 in stage 6.0 (TID 73)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_14 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_14 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_14 locally
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 79
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_14 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_7 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_7 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO executor.Executor: Running task 1.3 in stage 6.0 (TID 79)
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 7.2 in stage 6.0 (TID 76)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 83
20/04/14 08:19:55 INFO executor.Executor: Running task 9.2 in stage 6.0 (TID 83)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_14 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_14 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 14.2 in stage 6.0 (TID 77)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_9 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_9 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_1 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_1 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 1.3 in stage 6.0 (TID 79)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_9 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_9 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 9.2 in stage 6.0 (TID 83)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/04/14 08:19:55 INFO memory.MemoryStore: MemoryStore cleared
20/04/14 08:19:55 INFO storage.BlockManager: BlockManager stopped
20/04/14 08:19:55 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1586849858644_0008_01_000003 on 178.62.199.118_35057
===========================================================================
LogType:stderr
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:48278
Log Contents:
20/04/14 08:19:41 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22064@178.62.199.118
20/04/14 08:19:41 INFO util.SignalUtils: Registered signal handler for TERM
20/04/14 08:19:41 INFO util.SignalUtils: Registered signal handler for HUP
20/04/14 08:19:41 INFO util.SignalUtils: Registered signal handler for INT
20/04/14 08:19:42 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:19:42 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:19:42 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:19:42 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:19:42 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:19:42 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:38785 after 45 ms (0 ms spent in bootstraps)
20/04/14 08:19:42 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:19:42 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:19:42 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:19:42 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:19:42 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:19:42 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:38785 after 2 ms (0 ms spent in bootstraps)
20/04/14 08:19:42 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/blockmgr-73d11127-368c-4924-9032-c68e0a83e0df
20/04/14 08:19:42 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/14 08:19:42 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.198.251:38785
20/04/14 08:19:42 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/14 08:19:42 INFO executor.Executor: Starting executor ID 2 on host 178.62.199.118
20/04/14 08:19:42 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37315.
20/04/14 08:19:42 INFO netty.NettyBlockTransferService: Server created on 178.62.199.118:37315
20/04/14 08:19:42 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/14 08:19:42 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(2, 178.62.199.118, 37315, None)
20/04/14 08:19:42 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(2, 178.62.199.118, 37315, None)
20/04/14 08:19:42 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(2, 178.62.199.118, 37315, None)
20/04/14 08:19:49 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1
20/04/14 08:19:49 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 4
20/04/14 08:19:49 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 7
20/04/14 08:19:49 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)
20/04/14 08:19:49 INFO executor.Executor: Running task 6.0 in stage 1.0 (TID 7)
20/04/14 08:19:49 INFO executor.Executor: Running task 3.0 in stage 1.0 (TID 4)
20/04/14 08:19:49 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
20/04/14 08:19:49 INFO client.TransportClientFactory: Successfully created connection to /178.62.199.118:33175 after 1 ms (0 ms spent in bootstraps)
20/04/14 08:19:49 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KB, free 3.0 GB)
20/04/14 08:19:49 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 111 ms
20/04/14 08:19:50 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.1 KB, free 3.0 GB)
20/04/14 08:19:50 INFO codegen.CodeGenerator: Code generated in 200.305664 ms
20/04/14 08:19:50 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00005-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5742209, partition values: [empty row]
20/04/14 08:19:50 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00002-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5232773, partition values: [empty row]
20/04/14 08:19:50 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00006-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5714629, partition values: [empty row]
20/04/14 08:19:50 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/14 08:19:50 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/14 08:19:50 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 14 ms
20/04/14 08:19:50 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/14 08:19:51 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:19:51 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:19:51 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:19:51 INFO codegen.CodeGenerator: Code generated in 17.70189 ms
20/04/14 08:19:51 INFO codegen.CodeGenerator: Code generated in 17.872449 ms
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11734 records.
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11838 records.
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 6080 records.
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:19:51 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:19:51 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:19:51 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: block read in memory in 36 ms. row count = 6080
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: block read in memory in 35 ms. row count = 11838
20/04/14 08:19:51 INFO hadoop.InternalParquetRecordReader: block read in memory in 44 ms. row count = 11734
20/04/14 08:19:52 INFO executor.Executor: Finished task 3.0 in stage 1.0 (TID 4). 1530 bytes result sent to driver
20/04/14 08:19:52 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 1487 bytes result sent to driver
20/04/14 08:19:52 INFO executor.Executor: Finished task 6.0 in stage 1.0 (TID 7). 1487 bytes result sent to driver
20/04/14 08:19:52 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 10
20/04/14 08:19:52 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 10)
20/04/14 08:19:52 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 13
20/04/14 08:19:52 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 16
20/04/14 08:19:52 INFO executor.Executor: Running task 3.0 in stage 2.0 (TID 13)
20/04/14 08:19:52 INFO executor.Executor: Running task 6.0 in stage 2.0 (TID 16)
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
20/04/14 08:19:52 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/14 08:19:52 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.0 KB, free 3.0 GB)
20/04/14 08:19:52 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 18 ms
20/04/14 08:19:52 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.9 KB, free 3.0 GB)
20/04/14 08:19:53 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:19:53 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:19:53 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@178.62.198.251:38785)
20/04/14 08:19:53 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:19:53 INFO spark.MapOutputTrackerWorker: Got the output locations
20/04/14 08:19:53 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:53 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:53 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:53 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:43183 after 10 ms (0 ms spent in bootstraps)
20/04/14 08:19:53 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 29 ms
20/04/14 08:19:53 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 46 ms
20/04/14 08:19:53 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 46 ms
20/04/14 08:19:53 INFO memory.MemoryStore: Block rdd_7_3 stored as values in memory (estimated size 7.2 MB, free 3.0 GB)
20/04/14 08:19:53 INFO memory.MemoryStore: Block rdd_7_0 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:19:53 INFO memory.MemoryStore: Block rdd_7_6 stored as values in memory (estimated size 7.3 MB, free 3.0 GB)
20/04/14 08:19:53 INFO codegen.CodeGenerator: Code generated in 28.858583 ms
20/04/14 08:19:53 INFO codegen.CodeGenerator: Code generated in 32.700486 ms
20/04/14 08:19:54 INFO codegen.CodeGenerator: Code generated in 18.67103 ms
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_0 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_3 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_6 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO executor.Executor: Finished task 6.0 in stage 2.0 (TID 16). 1712 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 10). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 3.0 in stage 2.0 (TID 13). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 30
20/04/14 08:19:54 INFO executor.Executor: Running task 0.0 in stage 4.0 (TID 30)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 33
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 36
20/04/14 08:19:54 INFO executor.Executor: Running task 3.0 in stage 4.0 (TID 33)
20/04/14 08:19:54 INFO executor.Executor: Running task 6.0 in stage 4.0 (TID 36)
20/04/14 08:19:54 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:45915 after 4 ms (0 ms spent in bootstraps)
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.0 GB)
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 61 ms
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.6 KB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:19:54 INFO executor.Executor: Finished task 0.0 in stage 4.0 (TID 30). 12824 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 6.0 in stage 4.0 (TID 36). 2670 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 3.0 in stage 4.0 (TID 33). 2934 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 47
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 50
20/04/14 08:19:54 INFO executor.Executor: Running task 0.0 in stage 6.0 (TID 47)
20/04/14 08:19:54 INFO executor.Executor: Running task 3.0 in stage 6.0 (TID 50)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 53
20/04/14 08:19:54 INFO executor.Executor: Running task 6.0 in stage 6.0 (TID 53)
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.7 KB, free 3.0 GB)
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 11 ms
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:19:55 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:19:55 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.9 KB, free 3.0 GB)
20/04/14 08:19:55 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 15 ms
20/04/14 08:19:55 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.0 MB, free 3.0 GB)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_6 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_0 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_0 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_6 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 0.0 in stage 6.0 (TID 47)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 6.0 in stage 6.0 (TID 53)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_3 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_3 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 3.0 in stage 6.0 (TID 50)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 62
20/04/14 08:19:55 INFO executor.Executor: Running task 6.1 in stage 6.0 (TID 62)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 63
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 64
20/04/14 08:19:55 INFO executor.Executor: Running task 0.1 in stage 6.0 (TID 64)
20/04/14 08:19:55 INFO executor.Executor: Running task 3.1 in stage 6.0 (TID 63)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_6 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_6 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 6.1 in stage 6.0 (TID 62)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 70
20/04/14 08:19:55 INFO executor.Executor: Running task 6.2 in stage 6.0 (TID 70)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_0 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_0 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 0.1 in stage 6.0 (TID 64)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 74
20/04/14 08:19:55 INFO executor.Executor: Running task 0.2 in stage 6.0 (TID 74)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_6 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_6 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 6.2 in stage 6.0 (TID 70)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_3 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_3 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 3.1 in stage 6.0 (TID 63)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 78
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_0 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_0 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO executor.Executor: Running task 6.3 in stage 6.0 (TID 78)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 80
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 0.2 in stage 6.0 (TID 74)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.Executor: Running task 3.2 in stage 6.0 (TID 80)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 82
20/04/14 08:19:55 INFO executor.Executor: Running task 0.3 in stage 6.0 (TID 82)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_6 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_6 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_3 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_0 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_6 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_6 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 6.3 in stage 6.0 (TID 78)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_0 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_3 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_0 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_0 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 0.3 in stage 6.0 (TID 82)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.Executor: Executor is trying to kill task 3.2 in stage 6.0 (TID 80), reason: Stage cancelled
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_3 failed due to exception org.apache.spark.TaskKilledException.
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_3 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO executor.Executor: Executor killed task 3.2 in stage 6.0 (TID 80), reason: Stage cancelled
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/04/14 08:19:55 INFO memory.MemoryStore: MemoryStore cleared
20/04/14 08:19:55 INFO storage.BlockManager: BlockManager stopped
20/04/14 08:19:55 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1586849858644_0008_02_000005 on 178.62.199.118_35057
===========================================================================
LogType:stderr
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:46118
Log Contents:
20/04/14 08:20:02 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22311@178.62.199.118
20/04/14 08:20:02 INFO util.SignalUtils: Registered signal handler for TERM
20/04/14 08:20:02 INFO util.SignalUtils: Registered signal handler for HUP
20/04/14 08:20:02 INFO util.SignalUtils: Registered signal handler for INT
20/04/14 08:20:03 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:20:03 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:20:03 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:20:03 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:20:03 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:20:03 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:42739 after 47 ms (0 ms spent in bootstraps)
20/04/14 08:20:03 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:20:03 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:20:03 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:20:03 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:20:03 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:20:03 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:42739 after 2 ms (0 ms spent in bootstraps)
20/04/14 08:20:03 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/blockmgr-df64c42a-eb9e-4367-b9ec-7252e4089c45
20/04/14 08:20:03 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/14 08:20:04 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.198.251:42739
20/04/14 08:20:04 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/14 08:20:04 INFO executor.Executor: Starting executor ID 3 on host 178.62.199.118
20/04/14 08:20:04 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37619.
20/04/14 08:20:04 INFO netty.NettyBlockTransferService: Server created on 178.62.199.118:37619
20/04/14 08:20:04 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/14 08:20:04 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(3, 178.62.199.118, 37619, None)
20/04/14 08:20:04 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(3, 178.62.199.118, 37619, None)
20/04/14 08:20:04 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(3, 178.62.199.118, 37619, None)
20/04/14 08:20:08 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1
20/04/14 08:20:08 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 4
20/04/14 08:20:08 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 7
20/04/14 08:20:08 INFO executor.Executor: Running task 3.0 in stage 1.0 (TID 4)
20/04/14 08:20:08 INFO executor.Executor: Running task 6.0 in stage 1.0 (TID 7)
20/04/14 08:20:08 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)
20/04/14 08:20:08 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
20/04/14 08:20:08 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:45803 after 2 ms (0 ms spent in bootstraps)
20/04/14 08:20:08 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KB, free 3.0 GB)
20/04/14 08:20:08 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 92 ms
20/04/14 08:20:08 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.1 KB, free 3.0 GB)
20/04/14 08:20:09 INFO codegen.CodeGenerator: Code generated in 218.141611 ms
20/04/14 08:20:09 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00002-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5232773, partition values: [empty row]
20/04/14 08:20:09 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00005-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5742209, partition values: [empty row]
20/04/14 08:20:09 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00006-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5714629, partition values: [empty row]
20/04/14 08:20:09 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/14 08:20:09 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/14 08:20:09 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 15 ms
20/04/14 08:20:09 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/14 08:20:10 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:20:10 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:20:10 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:20:10 INFO codegen.CodeGenerator: Code generated in 60.967969 ms
20/04/14 08:20:10 INFO codegen.CodeGenerator: Code generated in 18.344158 ms
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11734 records.
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11838 records.
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 6080 records.
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:20:10 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:20:10 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:20:10 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: block read in memory in 42 ms. row count = 11838
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: block read in memory in 46 ms. row count = 11734
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: block read in memory in 52 ms. row count = 6080
20/04/14 08:20:12 INFO executor.Executor: Finished task 6.0 in stage 1.0 (TID 7). 1530 bytes result sent to driver
20/04/14 08:20:12 INFO executor.Executor: Finished task 3.0 in stage 1.0 (TID 4). 1530 bytes result sent to driver
20/04/14 08:20:12 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 1487 bytes result sent to driver
20/04/14 08:20:12 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 11
20/04/14 08:20:12 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 14
20/04/14 08:20:12 INFO executor.Executor: Running task 1.0 in stage 2.0 (TID 11)
20/04/14 08:20:12 INFO executor.Executor: Running task 4.0 in stage 2.0 (TID 14)
20/04/14 08:20:12 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 17
20/04/14 08:20:12 INFO executor.Executor: Running task 7.0 in stage 2.0 (TID 17)
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
20/04/14 08:20:12 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/14 08:20:12 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:36493 after 3 ms (0 ms spent in bootstraps)
20/04/14 08:20:12 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.0 KB, free 3.0 GB)
20/04/14 08:20:12 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 27 ms
20/04/14 08:20:12 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.9 KB, free 3.0 GB)
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@178.62.198.251:42739)
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Got the output locations
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:12 INFO client.TransportClientFactory: Successfully created connection to /178.62.199.118:37771 after 8 ms (0 ms spent in bootstraps)
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 23 ms
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 24 ms
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 30 ms
20/04/14 08:20:12 INFO memory.MemoryStore: Block rdd_7_4 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:20:12 INFO memory.MemoryStore: Block rdd_7_1 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:20:12 INFO memory.MemoryStore: Block rdd_7_7 stored as values in memory (estimated size 7.3 MB, free 3.0 GB)
20/04/14 08:20:12 INFO codegen.CodeGenerator: Code generated in 5.931253 ms
20/04/14 08:20:12 INFO codegen.CodeGenerator: Code generated in 40.509942 ms
20/04/14 08:20:13 INFO codegen.CodeGenerator: Code generated in 13.019003 ms
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_4 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_7 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_1 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO executor.Executor: Finished task 4.0 in stage 2.0 (TID 14). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO executor.Executor: Finished task 7.0 in stage 2.0 (TID 17). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO executor.Executor: Finished task 1.0 in stage 2.0 (TID 11). 1712 bytes result sent to driver
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 29
20/04/14 08:20:14 INFO executor.Executor: Running task 1.0 in stage 4.0 (TID 29)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 32
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 35
20/04/14 08:20:14 INFO executor.Executor: Running task 4.0 in stage 4.0 (TID 32)
20/04/14 08:20:14 INFO executor.Executor: Running task 7.0 in stage 4.0 (TID 35)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.0 GB)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 9 ms
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.6 KB, free 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_4 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:20:14 INFO executor.Executor: Finished task 1.0 in stage 4.0 (TID 29). 1362 bytes result sent to driver
20/04/14 08:20:14 INFO executor.Executor: Finished task 4.0 in stage 4.0 (TID 32). 1755 bytes result sent to driver
20/04/14 08:20:14 INFO executor.Executor: Finished task 7.0 in stage 4.0 (TID 35). 4017 bytes result sent to driver
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 48
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 51
20/04/14 08:20:14 INFO executor.Executor: Running task 1.0 in stage 6.0 (TID 48)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 54
20/04/14 08:20:14 INFO executor.Executor: Running task 4.0 in stage 6.0 (TID 51)
20/04/14 08:20:14 INFO executor.Executor: Running task 7.0 in stage 6.0 (TID 54)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.7 KB, free 3.0 GB)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 10 ms
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.5 KB, free 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_4 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_4 locally
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.6 KB, free 3.0 GB)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 14 ms
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.0 MB, free 3.0 GB)
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_1 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_1 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 1.0 in stage 6.0 (TID 48)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_4 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_4 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_7 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_7 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 4.0 in stage 6.0 (TID 51)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 7.0 in stage 6.0 (TID 54)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 58
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 59
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 60
20/04/14 08:20:14 INFO executor.Executor: Running task 7.1 in stage 6.0 (TID 60)
20/04/14 08:20:14 INFO executor.Executor: Running task 4.1 in stage 6.0 (TID 59)
20/04/14 08:20:14 INFO executor.Executor: Running task 1.1 in stage 6.0 (TID 58)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_4 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_4 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_1 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_1 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 1.1 in stage 6.0 (TID 58)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 63
20/04/14 08:20:14 INFO executor.Executor: Running task 1.2 in stage 6.0 (TID 63)
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_7 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_7 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 7.1 in stage 6.0 (TID 60)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 70
20/04/14 08:20:14 INFO executor.Executor: Running task 7.2 in stage 6.0 (TID 70)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_1 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_1 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_4 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_4 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 4.1 in stage 6.0 (TID 59)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 71
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 1.2 in stage 6.0 (TID 63)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.Executor: Running task 4.2 in stage 6.0 (TID 71)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 72
20/04/14 08:20:14 INFO executor.Executor: Running task 1.3 in stage 6.0 (TID 72)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_7 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_7 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_4 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_4 locally
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 7.2 in stage 6.0 (TID 70)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_1 locally
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 78
20/04/14 08:20:14 INFO executor.Executor: Running task 7.3 in stage 6.0 (TID 78)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_4 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_7 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_1 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_1 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_1 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 1.3 in stage 6.0 (TID 72)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_7 locally
20/04/14 08:20:14 INFO executor.Executor: Executor is trying to kill task 7.3 in stage 6.0 (TID 78), reason: Stage cancelled
20/04/14 08:20:14 INFO executor.Executor: Executor is trying to kill task 4.2 in stage 6.0 (TID 71), reason: Stage cancelled
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_7 failed due to exception org.apache.spark.TaskKilledException.
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_4 failed due to exception org.apache.spark.TaskKilledException.
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_7 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_4 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 INFO executor.Executor: Executor killed task 7.3 in stage 6.0 (TID 78), reason: Stage cancelled
20/04/14 08:20:14 INFO executor.Executor: Executor killed task 4.2 in stage 6.0 (TID 71), reason: Stage cancelled
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/04/14 08:20:14 INFO memory.MemoryStore: MemoryStore cleared
20/04/14 08:20:14 INFO storage.BlockManager: BlockManager stopped
20/04/14 08:20:14 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1586849858644_0008_02_000003 on 178.62.199.118_35057
===========================================================================
LogType:stderr
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:45850
Log Contents:
20/04/14 08:20:00 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22253@178.62.199.118
20/04/14 08:20:00 INFO util.SignalUtils: Registered signal handler for TERM
20/04/14 08:20:00 INFO util.SignalUtils: Registered signal handler for HUP
20/04/14 08:20:00 INFO util.SignalUtils: Registered signal handler for INT
20/04/14 08:20:01 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:20:01 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:20:01 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:20:01 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:20:01 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:20:01 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:42739 after 46 ms (0 ms spent in bootstraps)
20/04/14 08:20:01 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:20:01 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:20:01 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:20:01 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:20:01 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:20:01 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:42739 after 2 ms (0 ms spent in bootstraps)
20/04/14 08:20:01 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/blockmgr-9844d7db-501b-46d0-b7bf-8eb2e88775d7
20/04/14 08:20:01 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/14 08:20:01 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.198.251:42739
20/04/14 08:20:01 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/14 08:20:01 INFO executor.Executor: Starting executor ID 2 on host 178.62.199.118
20/04/14 08:20:01 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37771.
20/04/14 08:20:01 INFO netty.NettyBlockTransferService: Server created on 178.62.199.118:37771
20/04/14 08:20:01 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/14 08:20:01 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(2, 178.62.199.118, 37771, None)
20/04/14 08:20:01 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(2, 178.62.199.118, 37771, None)
20/04/14 08:20:01 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(2, 178.62.199.118, 37771, None)
20/04/14 08:20:08 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3
20/04/14 08:20:08 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 6
20/04/14 08:20:08 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 9
20/04/14 08:20:08 INFO executor.Executor: Running task 2.0 in stage 1.0 (TID 3)
20/04/14 08:20:08 INFO executor.Executor: Running task 8.0 in stage 1.0 (TID 9)
20/04/14 08:20:08 INFO executor.Executor: Running task 5.0 in stage 1.0 (TID 6)
20/04/14 08:20:08 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
20/04/14 08:20:08 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:45803 after 2 ms (0 ms spent in bootstraps)
20/04/14 08:20:08 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KB, free 3.0 GB)
20/04/14 08:20:08 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 110 ms
20/04/14 08:20:08 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.1 KB, free 3.0 GB)
20/04/14 08:20:09 INFO codegen.CodeGenerator: Code generated in 206.3935 ms
20/04/14 08:20:09 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00007-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5727714, partition values: [empty row]
20/04/14 08:20:09 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00001-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5299881, partition values: [empty row]
20/04/14 08:20:09 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/14 08:20:09 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00008-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-223928, partition values: [empty row]
20/04/14 08:20:09 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/14 08:20:09 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 13 ms
20/04/14 08:20:09 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/14 08:20:10 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:20:10 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:20:10 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:20:10 INFO codegen.CodeGenerator: Code generated in 48.402549 ms
20/04/14 08:20:10 INFO codegen.CodeGenerator: Code generated in 24.746316 ms
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5926 records.
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 472 records.
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11674 records.
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:20:10 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:20:11 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:20:11 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:20:11 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:20:11 INFO hadoop.InternalParquetRecordReader: block read in memory in 43 ms. row count = 472
20/04/14 08:20:11 INFO hadoop.InternalParquetRecordReader: block read in memory in 48 ms. row count = 11674
20/04/14 08:20:11 INFO hadoop.InternalParquetRecordReader: block read in memory in 47 ms. row count = 5926
20/04/14 08:20:11 INFO executor.Executor: Finished task 8.0 in stage 1.0 (TID 9). 1530 bytes result sent to driver
20/04/14 08:20:12 INFO executor.Executor: Finished task 5.0 in stage 1.0 (TID 6). 1487 bytes result sent to driver
20/04/14 08:20:12 INFO executor.Executor: Finished task 2.0 in stage 1.0 (TID 3). 1487 bytes result sent to driver
20/04/14 08:20:12 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 12
20/04/14 08:20:12 INFO executor.Executor: Running task 2.0 in stage 2.0 (TID 12)
20/04/14 08:20:12 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 15
20/04/14 08:20:12 INFO executor.Executor: Running task 5.0 in stage 2.0 (TID 15)
20/04/14 08:20:12 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 18
20/04/14 08:20:12 INFO executor.Executor: Running task 8.0 in stage 2.0 (TID 18)
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
20/04/14 08:20:12 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/14 08:20:12 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:36493 after 2 ms (0 ms spent in bootstraps)
20/04/14 08:20:12 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.0 KB, free 3.0 GB)
20/04/14 08:20:12 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 21 ms
20/04/14 08:20:12 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.9 KB, free 3.0 GB)
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@178.62.198.251:42739)
20/04/14 08:20:12 INFO spark.MapOutputTrackerWorker: Got the output locations
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:12 INFO client.TransportClientFactory: Successfully created connection to /178.62.199.118:37619 after 3 ms (0 ms spent in bootstraps)
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 19 ms
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 19 ms
20/04/14 08:20:12 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 34 ms
20/04/14 08:20:12 INFO memory.MemoryStore: Block rdd_7_5 stored as values in memory (estimated size 7.1 MB, free 3.0 GB)
20/04/14 08:20:12 INFO memory.MemoryStore: Block rdd_7_2 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:20:12 INFO memory.MemoryStore: Block rdd_7_8 stored as values in memory (estimated size 7.2 MB, free 3.0 GB)
20/04/14 08:20:12 INFO codegen.CodeGenerator: Code generated in 5.876779 ms
20/04/14 08:20:12 INFO codegen.CodeGenerator: Code generated in 32.755141 ms
20/04/14 08:20:13 INFO codegen.CodeGenerator: Code generated in 12.213903 ms
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_5 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_8 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_2 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:13 INFO executor.Executor: Finished task 5.0 in stage 2.0 (TID 15). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO executor.Executor: Finished task 8.0 in stage 2.0 (TID 18). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 22
20/04/14 08:20:13 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 23
20/04/14 08:20:13 INFO executor.Executor: Running task 13.0 in stage 2.0 (TID 23)
20/04/14 08:20:13 INFO executor.Executor: Running task 12.0 in stage 2.0 (TID 22)
20/04/14 08:20:13 INFO executor.Executor: Finished task 2.0 in stage 2.0 (TID 12). 1669 bytes result sent to driver
20/04/14 08:20:13 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 24
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 6 ms
20/04/14 08:20:13 INFO executor.Executor: Running task 14.0 in stage 2.0 (TID 24)
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 20 ms
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:20:13 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 19 ms
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_7_12 stored as values in memory (estimated size 7.3 MB, free 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_12 locally
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_7_13 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_7_14 stored as values in memory (estimated size 7.6 MB, free 3.0 GB)
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_13 locally
20/04/14 08:20:13 INFO storage.BlockManager: Found block rdd_7_14 locally
20/04/14 08:20:13 INFO memory.MemoryStore: Block rdd_21_12 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:14 INFO memory.MemoryStore: Block rdd_21_13 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:14 INFO executor.Executor: Finished task 12.0 in stage 2.0 (TID 22). 1669 bytes result sent to driver
20/04/14 08:20:14 INFO memory.MemoryStore: Block rdd_21_14 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:20:14 INFO executor.Executor: Finished task 13.0 in stage 2.0 (TID 23). 1669 bytes result sent to driver
20/04/14 08:20:14 INFO executor.Executor: Finished task 14.0 in stage 2.0 (TID 24). 1669 bytes result sent to driver
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 28
20/04/14 08:20:14 INFO executor.Executor: Running task 2.0 in stage 4.0 (TID 28)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 31
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 34
20/04/14 08:20:14 INFO executor.Executor: Running task 5.0 in stage 4.0 (TID 31)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/14 08:20:14 INFO executor.Executor: Running task 8.0 in stage 4.0 (TID 34)
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.0 GB)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 10 ms
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.6 KB, free 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_8 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:20:14 INFO executor.Executor: Finished task 5.0 in stage 4.0 (TID 31). 1319 bytes result sent to driver
20/04/14 08:20:14 INFO executor.Executor: Finished task 8.0 in stage 4.0 (TID 34). 1772 bytes result sent to driver
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 40
20/04/14 08:20:14 INFO executor.Executor: Running task 12.0 in stage 4.0 (TID 40)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 41
20/04/14 08:20:14 INFO executor.Executor: Running task 13.0 in stage 4.0 (TID 41)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_13 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_13 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_12 locally
20/04/14 08:20:14 INFO executor.Executor: Finished task 2.0 in stage 4.0 (TID 28). 2065 bytes result sent to driver
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_12 locally
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 45
20/04/14 08:20:14 INFO executor.Executor: Running task 14.0 in stage 4.0 (TID 45)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_14 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_14 locally
20/04/14 08:20:14 INFO executor.Executor: Finished task 13.0 in stage 4.0 (TID 41). 3627 bytes result sent to driver
20/04/14 08:20:14 INFO executor.Executor: Finished task 12.0 in stage 4.0 (TID 40). 4345 bytes result sent to driver
20/04/14 08:20:14 INFO executor.Executor: Finished task 14.0 in stage 4.0 (TID 45). 15450 bytes result sent to driver
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 46
20/04/14 08:20:14 INFO executor.Executor: Running task 2.0 in stage 6.0 (TID 46)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 49
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 52
20/04/14 08:20:14 INFO executor.Executor: Running task 8.0 in stage 6.0 (TID 52)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/14 08:20:14 INFO executor.Executor: Running task 5.0 in stage 6.0 (TID 49)
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.7 KB, free 3.0 GB)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 12 ms
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.5 KB, free 3.0 GB)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_8 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_8 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.6 KB, free 3.0 GB)
20/04/14 08:20:14 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 9 ms
20/04/14 08:20:14 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.0 MB, free 3.0 GB)
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_2 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_2 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_5 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_5 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_8 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_8 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 2.0 in stage 6.0 (TID 46)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 8.0 in stage 6.0 (TID 52)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 5.0 in stage 6.0 (TID 49)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 64
20/04/14 08:20:14 INFO executor.Executor: Running task 12.0 in stage 6.0 (TID 64)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 65
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 66
20/04/14 08:20:14 INFO executor.Executor: Running task 2.1 in stage 6.0 (TID 65)
20/04/14 08:20:14 INFO executor.Executor: Running task 5.1 in stage 6.0 (TID 66)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_12 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_12 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_12 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_12 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_12 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_12 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_5 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_5 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 5.1 in stage 6.0 (TID 66)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 12.0 in stage 6.0 (TID 64)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 74
20/04/14 08:20:14 INFO executor.Executor: Running task 8.1 in stage 6.0 (TID 74)
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 75
20/04/14 08:20:14 INFO executor.Executor: Running task 5.2 in stage 6.0 (TID 75)
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_2 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_2 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 2.1 in stage 6.0 (TID 65)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_8 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_8 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 80
20/04/14 08:20:14 INFO executor.Executor: Running task 12.1 in stage 6.0 (TID 80)
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_12 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_12 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_7_12 locally
20/04/14 08:20:14 INFO storage.BlockManager: Found block rdd_21_12 locally
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_5 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_5 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_12 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_12 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 5.2 in stage 6.0 (TID 75)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 ERROR executor.Executor: Exception in task 12.1 in stage 6.0 (TID 80)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:20:14 INFO executor.Executor: Executor is trying to kill task 8.1 in stage 6.0 (TID 74), reason: Stage cancelled
20/04/14 08:20:14 WARN storage.BlockManager: Putting block rdd_27_8 failed due to exception org.apache.spark.TaskKilledException.
20/04/14 08:20:14 WARN storage.BlockManager: Block rdd_27_8 could not be removed as it was not found on disk or in memory
20/04/14 08:20:14 INFO executor.Executor: Executor killed task 8.1 in stage 6.0 (TID 74), reason: Stage cancelled
20/04/14 08:20:14 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/04/14 08:20:14 INFO memory.MemoryStore: MemoryStore cleared
20/04/14 08:20:14 INFO storage.BlockManager: BlockManager stopped
20/04/14 08:20:14 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1586849858644_0008_01_000005 on 178.62.199.118_35057
===========================================================================
LogType:stderr
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:55970
Log Contents:
20/04/14 08:19:43 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22123@178.62.199.118
20/04/14 08:19:43 INFO util.SignalUtils: Registered signal handler for TERM
20/04/14 08:19:43 INFO util.SignalUtils: Registered signal handler for HUP
20/04/14 08:19:43 INFO util.SignalUtils: Registered signal handler for INT
20/04/14 08:19:43 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:19:43 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:19:43 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:19:43 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:19:43 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:19:43 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:38785 after 48 ms (0 ms spent in bootstraps)
20/04/14 08:19:44 INFO spark.SecurityManager: Changing view acls to: root
20/04/14 08:19:44 INFO spark.SecurityManager: Changing modify acls to: root
20/04/14 08:19:44 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/14 08:19:44 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/14 08:19:44 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/14 08:19:44 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:38785 after 4 ms (0 ms spent in bootstraps)
20/04/14 08:19:44 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586849858644_0008/blockmgr-55f00df4-9b94-4559-b2c7-1aed4dfade38
20/04/14 08:19:44 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/14 08:19:44 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.198.251:38785
20/04/14 08:19:44 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/14 08:19:44 INFO executor.Executor: Starting executor ID 3 on host 178.62.199.118
20/04/14 08:19:44 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33175.
20/04/14 08:19:44 INFO netty.NettyBlockTransferService: Server created on 178.62.199.118:33175
20/04/14 08:19:44 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/14 08:19:44 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(3, 178.62.199.118, 33175, None)
20/04/14 08:19:44 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(3, 178.62.199.118, 33175, None)
20/04/14 08:19:44 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(3, 178.62.199.118, 33175, None)
20/04/14 08:19:45 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 0
20/04/14 08:19:45 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
20/04/14 08:19:45 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
20/04/14 08:19:45 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:45915 after 1 ms (0 ms spent in bootstraps)
20/04/14 08:19:45 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.2 KB, free 3.0 GB)
20/04/14 08:19:45 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 220 ms
20/04/14 08:19:45 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 127.0 KB, free 3.0 GB)
20/04/14 08:19:47 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2496 bytes result sent to driver
20/04/14 08:19:49 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3
20/04/14 08:19:49 INFO executor.Executor: Running task 2.0 in stage 1.0 (TID 3)
20/04/14 08:19:49 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 6
20/04/14 08:19:49 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 9
20/04/14 08:19:49 INFO executor.Executor: Running task 5.0 in stage 1.0 (TID 6)
20/04/14 08:19:49 INFO executor.Executor: Running task 8.0 in stage 1.0 (TID 9)
20/04/14 08:19:49 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
20/04/14 08:19:49 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KB, free 3.0 GB)
20/04/14 08:19:49 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 14 ms
20/04/14 08:19:49 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.1 KB, free 3.0 GB)
20/04/14 08:19:50 INFO codegen.CodeGenerator: Code generated in 231.577048 ms
20/04/14 08:19:50 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00007-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5727714, partition values: [empty row]
20/04/14 08:19:50 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00008-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-223928, partition values: [empty row]
20/04/14 08:19:50 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.79:9000/data/df_5-shingles_sparse-count-vectors.parquet/part-00001-bc444799-4664-485e-a7b0-8e2525cc9395-c000.snappy.parquet, range: 0-5299881, partition values: [empty row]
20/04/14 08:19:50 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/14 08:19:50 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/14 08:19:50 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 10 ms
20/04/14 08:19:50 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/14 08:19:50 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:19:50 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:19:50 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/14 08:19:50 INFO codegen.CodeGenerator: Code generated in 20.616862 ms
20/04/14 08:19:50 INFO codegen.CodeGenerator: Code generated in 30.192801 ms
20/04/14 08:19:50 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11674 records.
20/04/14 08:19:50 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5926 records.
20/04/14 08:19:50 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 472 records.
20/04/14 08:19:50 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:19:50 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:19:50 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/14 08:19:50 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:19:50 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:19:50 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/14 08:19:50 INFO hadoop.InternalParquetRecordReader: block read in memory in 94 ms. row count = 472
20/04/14 08:19:50 INFO hadoop.InternalParquetRecordReader: block read in memory in 98 ms. row count = 11674
20/04/14 08:19:50 INFO hadoop.InternalParquetRecordReader: block read in memory in 84 ms. row count = 5926
20/04/14 08:19:51 INFO executor.Executor: Finished task 8.0 in stage 1.0 (TID 9). 1530 bytes result sent to driver
20/04/14 08:19:51 INFO executor.Executor: Finished task 5.0 in stage 1.0 (TID 6). 1530 bytes result sent to driver
20/04/14 08:19:51 INFO executor.Executor: Finished task 2.0 in stage 1.0 (TID 3). 1530 bytes result sent to driver
20/04/14 08:19:52 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 12
20/04/14 08:19:52 INFO executor.Executor: Running task 2.0 in stage 2.0 (TID 12)
20/04/14 08:19:52 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 15
20/04/14 08:19:52 INFO executor.Executor: Running task 5.0 in stage 2.0 (TID 15)
20/04/14 08:19:52 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 18
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
20/04/14 08:19:52 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/14 08:19:52 INFO executor.Executor: Running task 8.0 in stage 2.0 (TID 18)
20/04/14 08:19:52 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.0 KB, free 3.0 GB)
20/04/14 08:19:52 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 13 ms
20/04/14 08:19:52 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.9 KB, free 3.0 GB)
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@178.62.198.251:38785)
20/04/14 08:19:52 INFO spark.MapOutputTrackerWorker: Got the output locations
20/04/14 08:19:52 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:52 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:52 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:52 INFO client.TransportClientFactory: Successfully created connection to /178.62.199.118:37315 after 2 ms (0 ms spent in bootstraps)
20/04/14 08:19:52 INFO client.TransportClientFactory: Successfully created connection to /178.62.198.251:43183 after 4 ms (0 ms spent in bootstraps)
20/04/14 08:19:52 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 17 ms
20/04/14 08:19:52 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 22 ms
20/04/14 08:19:52 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 17 ms
20/04/14 08:19:53 INFO memory.MemoryStore: Block rdd_7_5 stored as values in memory (estimated size 7.1 MB, free 3.0 GB)
20/04/14 08:19:53 INFO memory.MemoryStore: Block rdd_7_2 stored as values in memory (estimated size 7.4 MB, free 3.0 GB)
20/04/14 08:19:53 INFO memory.MemoryStore: Block rdd_7_8 stored as values in memory (estimated size 7.2 MB, free 3.0 GB)
20/04/14 08:19:53 INFO codegen.CodeGenerator: Code generated in 28.310922 ms
20/04/14 08:19:53 INFO codegen.CodeGenerator: Code generated in 24.020139 ms
20/04/14 08:19:54 INFO codegen.CodeGenerator: Code generated in 9.615563 ms
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_8 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_5 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_2 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO executor.Executor: Finished task 8.0 in stage 2.0 (TID 18). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 5.0 in stage 2.0 (TID 15). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 2.0 in stage 2.0 (TID 12). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 20
20/04/14 08:19:54 INFO executor.Executor: Running task 10.0 in stage 2.0 (TID 20)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 21
20/04/14 08:19:54 INFO executor.Executor: Running task 11.0 in stage 2.0 (TID 21)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 22
20/04/14 08:19:54 INFO executor.Executor: Running task 12.0 in stage 2.0 (TID 22)
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 16 ms
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 2 ms
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Getting 9 non-empty blocks including 3 local blocks and 6 remote blocks
20/04/14 08:19:54 INFO storage.ShuffleBlockFetcherIterator: Started 2 remote fetches in 1 ms
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_7_12 stored as values in memory (estimated size 7.3 MB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_7_10 stored as values in memory (estimated size 7.2 MB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_7_11 stored as values in memory (estimated size 7.3 MB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_12 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_11 locally
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_12 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_11 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO memory.MemoryStore: Block rdd_21_10 stored as values in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO executor.Executor: Finished task 12.0 in stage 2.0 (TID 22). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 11.0 in stage 2.0 (TID 21). 1626 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 10.0 in stage 2.0 (TID 20). 1669 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 29
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 32
20/04/14 08:19:54 INFO executor.Executor: Running task 2.0 in stage 4.0 (TID 29)
20/04/14 08:19:54 INFO executor.Executor: Running task 5.0 in stage 4.0 (TID 32)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 35
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/14 08:19:54 INFO executor.Executor: Running task 8.0 in stage 4.0 (TID 35)
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.0 GB)
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 7 ms
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.6 KB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_8 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:19:54 INFO executor.Executor: Finished task 5.0 in stage 4.0 (TID 32). 1319 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 40
20/04/14 08:19:54 INFO executor.Executor: Running task 10.0 in stage 4.0 (TID 40)
20/04/14 08:19:54 INFO executor.Executor: Finished task 8.0 in stage 4.0 (TID 35). 1772 bytes result sent to driver
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:19:54 INFO executor.Executor: Finished task 2.0 in stage 4.0 (TID 29). 2610 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 41
20/04/14 08:19:54 INFO executor.Executor: Running task 11.0 in stage 4.0 (TID 41)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 42
20/04/14 08:19:54 INFO executor.Executor: Running task 12.0 in stage 4.0 (TID 42)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_11 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_12 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_11 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_12 locally
20/04/14 08:19:54 INFO executor.Executor: Finished task 10.0 in stage 4.0 (TID 40). 1933 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 11.0 in stage 4.0 (TID 41). 3642 bytes result sent to driver
20/04/14 08:19:54 INFO executor.Executor: Finished task 12.0 in stage 4.0 (TID 42). 4345 bytes result sent to driver
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 46
20/04/14 08:19:54 INFO executor.Executor: Running task 2.0 in stage 6.0 (TID 46)
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 49
20/04/14 08:19:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 52
20/04/14 08:19:54 INFO executor.Executor: Running task 5.0 in stage 6.0 (TID 49)
20/04/14 08:19:54 INFO executor.Executor: Running task 8.0 in stage 6.0 (TID 52)
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.7 KB, free 3.0 GB)
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 12 ms
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.5 KB, free 3.0 GB)
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_8 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_8 locally
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:19:54 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.9 KB, free 3.0 GB)
20/04/14 08:19:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 14 ms
20/04/14 08:19:54 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.0 MB, free 3.0 GB)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_5 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_5 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_2 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_2 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 5.0 in stage 6.0 (TID 49)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_8 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_8 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 2.0 in stage 6.0 (TID 46)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 8.0 in stage 6.0 (TID 52)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 58
20/04/14 08:19:55 INFO executor.Executor: Running task 10.0 in stage 6.0 (TID 58)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 59
20/04/14 08:19:55 INFO executor.Executor: Running task 5.1 in stage 6.0 (TID 59)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 60
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:19:55 INFO executor.Executor: Running task 2.1 in stage 6.0 (TID 60)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_10 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_10 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_5 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_5 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 10.0 in stage 6.0 (TID 58)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 5.1 in stage 6.0 (TID 59)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 67
20/04/14 08:19:55 INFO executor.Executor: Running task 8.1 in stage 6.0 (TID 67)
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 68
20/04/14 08:19:55 INFO executor.Executor: Running task 10.1 in stage 6.0 (TID 68)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_2 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_2 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 2.1 in stage 6.0 (TID 60)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 71
20/04/14 08:19:55 INFO executor.Executor: Running task 5.2 in stage 6.0 (TID 71)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_8 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_8 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_8 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_10 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_10 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 10.1 in stage 6.0 (TID 68)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 75
20/04/14 08:19:55 INFO executor.Executor: Running task 2.2 in stage 6.0 (TID 75)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_5 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_5 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 5.2 in stage 6.0 (TID 71)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_8 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_8 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_2 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_2 locally
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 81
20/04/14 08:19:55 INFO executor.Executor: Running task 10.2 in stage 6.0 (TID 81)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_10 locally
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 8.1 in stage 6.0 (TID 67)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_2 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_2 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_10 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_10 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_10 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 84
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 2.2 in stage 6.0 (TID 75)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO executor.Executor: Running task 5.3 in stage 6.0 (TID 84)
20/04/14 08:19:55 ERROR executor.Executor: Exception in task 10.2 in stage 6.0 (TID 81)
java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors.
	at scala.Predef$.assert(Predef.scala:170)
	at org.apache.spark.mllib.clustering.CosineDistanceMeasure.distance(DistanceMeasure.scala:243)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:37)
	at org.apache.spark.mllib.clustering.DistanceMeasure$$anonfun$findClosest$1.apply(DistanceMeasure.scala:36)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:36)
	at org.apache.spark.mllib.clustering.DistanceMeasure.pointCost(DistanceMeasure.scala:53)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:404)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$initKMeansParallel$2.apply(KMeans.scala:403)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_7_5 locally
20/04/14 08:19:55 INFO storage.BlockManager: Found block rdd_21_5 locally
20/04/14 08:19:55 WARN storage.BlockManager: Putting block rdd_27_5 failed due to exception java.lang.AssertionError: assertion failed: Cosine distance is not defined for zero-length vectors..
20/04/14 08:19:55 WARN storage.BlockManager: Block rdd_27_5 could not be removed as it was not found on disk or in memory
20/04/14 08:19:55 INFO executor.Executor: Executor is trying to kill task 5.3 in stage 6.0 (TID 84), reason: Stage cancelled
20/04/14 08:19:55 INFO executor.Executor: Executor interrupted and killed task 5.3 in stage 6.0 (TID 84), reason: Stage cancelled
20/04/14 08:19:55 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/04/14 08:19:55 INFO memory.MemoryStore: MemoryStore cleared
20/04/14 08:19:55 INFO storage.BlockManager: BlockManager stopped
20/04/14 08:19:55 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Tue Apr 14 08:20:16 +0000 2020
LogLength:0
Log Contents:
End of LogType:stdout

