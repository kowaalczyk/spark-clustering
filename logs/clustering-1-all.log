

Container: container_1586815278733_0007_01_000010 on 178.62.197.156_36923
===========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:5789
Log Contents:
20/04/13 22:26:45 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22809@178.62.197.156
20/04/13 22:26:45 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:45 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:45 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:46 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:46 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:46 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:46 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:46 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:46 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 52 ms (0 ms spent in bootstraps)
20/04/13 22:26:46 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:46 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:46 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:46 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:46 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:46 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 4 ms (0 ms spent in bootstraps)
20/04/13 22:26:46 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-7d4f9ff6-c302-474a-b2ab-07955f64177b
20/04/13 22:26:46 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:47 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.197.156:39167
20/04/13 22:26:47 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:26:47 INFO executor.Executor: Starting executor ID 8 on host 178.62.197.156
20/04/13 22:26:47 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44543.
20/04/13 22:26:47 INFO netty.NettyBlockTransferService: Server created on 178.62.197.156:44543
20/04/13 22:26:47 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:47 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(8, 178.62.197.156, 44543, None)
20/04/13 22:26:47 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(8, 178.62.197.156, 44543, None)
20/04/13 22:26:47 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(8, 178.62.197.156, 44543, None)
20/04/13 22:26:47 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 41
20/04/13 22:26:47 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 42
20/04/13 22:26:47 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 43
20/04/13 22:26:47 INFO executor.Executor: Running task 2.2 in stage 4.0 (TID 41)
20/04/13 22:26:47 INFO executor.Executor: Running task 5.2 in stage 4.0 (TID 43)
20/04/13 22:26:47 INFO executor.Executor: Running task 7.2 in stage 4.0 (TID 42)
20/04/13 22:26:47 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:26:47 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:45529 after 1 ms (0 ms spent in bootstraps)
20/04/13 22:26:47 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 3.0 GB)
20/04/13 22:26:47 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 69 ms
20/04/13 22:26:47 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 3.0 GB)
20/04/13 22:26:47 INFO codegen.CodeGenerator: Code generated in 227.238257 ms
20/04/13 22:26:47 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00000-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4791031, partition values: [empty row]
20/04/13 22:26:47 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00007-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4944913, partition values: [empty row]
20/04/13 22:26:47 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00002-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4735846, partition values: [empty row]
20/04/13 22:26:47 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:26:47 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/13 22:26:47 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 7 ms
20/04/13 22:26:47 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:26:48 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/04/13 22:26:48 INFO memory.MemoryStore: MemoryStore cleared
20/04/13 22:26:48 INFO storage.BlockManager: BlockManager stopped
20/04/13 22:26:48 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1586815278733_0007_02_000008 on 178.62.197.156_36923
===========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:5785
Log Contents:
20/04/13 22:27:35 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 23306@178.62.197.156
20/04/13 22:27:35 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:27:35 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:27:35 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:27:36 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:27:36 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:27:36 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:27:36 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:27:36 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:27:36 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 45 ms (0 ms spent in bootstraps)
20/04/13 22:27:36 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:27:36 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:27:36 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:27:36 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:27:36 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:27:36 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 3 ms (0 ms spent in bootstraps)
20/04/13 22:27:36 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-053ce37f-9ca2-4f02-a0d0-5b11f5310dba
20/04/13 22:27:36 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:27:36 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@64.227.70.177:45487
20/04/13 22:27:36 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:27:36 INFO executor.Executor: Starting executor ID 7 on host 178.62.197.156
20/04/13 22:27:37 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40191.
20/04/13 22:27:37 INFO netty.NettyBlockTransferService: Server created on 178.62.197.156:40191
20/04/13 22:27:37 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:27:37 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(7, 178.62.197.156, 40191, None)
20/04/13 22:27:37 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(7, 178.62.197.156, 40191, None)
20/04/13 22:27:37 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(7, 178.62.197.156, 40191, None)
20/04/13 22:27:37 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 38
20/04/13 22:27:37 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 39
20/04/13 22:27:37 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 40
20/04/13 22:27:37 INFO executor.Executor: Running task 3.2 in stage 4.0 (TID 40)
20/04/13 22:27:37 INFO executor.Executor: Running task 8.2 in stage 4.0 (TID 38)
20/04/13 22:27:37 INFO executor.Executor: Running task 6.2 in stage 4.0 (TID 39)
20/04/13 22:27:37 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:27:37 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:38753 after 1 ms (0 ms spent in bootstraps)
20/04/13 22:27:37 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 3.0 GB)
20/04/13 22:27:37 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 70 ms
20/04/13 22:27:37 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 3.0 GB)
20/04/13 22:27:37 INFO codegen.CodeGenerator: Code generated in 287.174367 ms
20/04/13 22:27:37 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00004-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4935172, partition values: [empty row]
20/04/13 22:27:37 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00001-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4785170, partition values: [empty row]
20/04/13 22:27:37 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00008-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-213844, partition values: [empty row]
20/04/13 22:27:37 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:27:37 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/13 22:27:37 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 10 ms
20/04/13 22:27:37 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:27:38 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/04/13 22:27:38 INFO memory.MemoryStore: MemoryStore cleared
20/04/13 22:27:38 INFO storage.BlockManager: BlockManager stopped
20/04/13 22:27:38 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1586815278733_0007_01_000008 on 178.62.197.156_36923
===========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:16265
Log Contents:
20/04/13 22:26:32 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22710@178.62.197.156
20/04/13 22:26:32 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:32 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:32 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:33 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:33 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:33 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:33 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:33 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 50 ms (0 ms spent in bootstraps)
20/04/13 22:26:33 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:33 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:33 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:33 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:33 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 4 ms (0 ms spent in bootstraps)
20/04/13 22:26:33 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-d0e475bb-47ce-4cfb-9272-fdf6fff9f7ac
20/04/13 22:26:33 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:33 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.197.156:39167
20/04/13 22:26:33 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:26:33 INFO executor.Executor: Starting executor ID 6 on host 178.62.197.156
20/04/13 22:26:34 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41639.
20/04/13 22:26:34 INFO netty.NettyBlockTransferService: Server created on 178.62.197.156:41639
20/04/13 22:26:34 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:34 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(6, 178.62.197.156, 41639, None)
20/04/13 22:26:34 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(6, 178.62.197.156, 41639, None)
20/04/13 22:26:34 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(6, 178.62.197.156, 41639, None)
20/04/13 22:26:34 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 35
20/04/13 22:26:34 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 36
20/04/13 22:26:34 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 37
20/04/13 22:26:34 INFO executor.Executor: Running task 2.1 in stage 4.0 (TID 36)
20/04/13 22:26:34 INFO executor.Executor: Running task 7.1 in stage 4.0 (TID 37)
20/04/13 22:26:34 INFO executor.Executor: Running task 5.1 in stage 4.0 (TID 35)
20/04/13 22:26:34 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:26:34 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:45529 after 1 ms (0 ms spent in bootstraps)
20/04/13 22:26:34 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 3.0 GB)
20/04/13 22:26:34 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 83 ms
20/04/13 22:26:34 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 3.0 GB)
20/04/13 22:26:34 INFO codegen.CodeGenerator: Code generated in 257.804026 ms
20/04/13 22:26:34 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00007-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4944913, partition values: [empty row]
20/04/13 22:26:34 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00000-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4791031, partition values: [empty row]
20/04/13 22:26:34 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00002-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4735846, partition values: [empty row]
20/04/13 22:26:34 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:26:34 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/13 22:26:34 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 9 ms
20/04/13 22:26:34 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:26:35 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:35 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:35 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:35 INFO codegen.CodeGenerator: Code generated in 16.054321 ms
20/04/13 22:26:35 INFO codegen.CodeGenerator: Code generated in 12.253466 ms
20/04/13 22:26:35 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5980 records.
20/04/13 22:26:35 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11674 records.
20/04/13 22:26:35 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 6080 records.
20/04/13 22:26:35 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:35 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:35 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:36 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:36 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:36 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:36 INFO hadoop.InternalParquetRecordReader: block read in memory in 34 ms. row count = 5980
20/04/13 22:26:36 INFO hadoop.InternalParquetRecordReader: block read in memory in 34 ms. row count = 11674
20/04/13 22:26:36 INFO hadoop.InternalParquetRecordReader: block read in memory in 34 ms. row count = 6080
20/04/13 22:26:36 INFO memory.MemoryStore: Block rdd_4_2 stored as values in memory (estimated size 32.6 MB, free 3.0 GB)
20/04/13 22:26:36 INFO codegen.CodeGenerator: Code generated in 4.946292 ms
20/04/13 22:26:36 INFO codegen.CodeGenerator: Code generated in 17.75965 ms
20/04/13 22:26:37 INFO memory.MemoryStore: Block rdd_4_7 stored as values in memory (estimated size 33.4 MB, free 3.0 GB)
20/04/13 22:26:37 INFO memory.MemoryStore: Block rdd_4_5 stored as values in memory (estimated size 33.8 MB, free 2.9 GB)
20/04/13 22:26:37 INFO codegen.CodeGenerator: Code generated in 19.013922 ms
20/04/13 22:26:37 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:26:37 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 2.9 GB)
20/04/13 22:26:37 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 10 ms
20/04/13 22:26:37 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 2.9 GB)
20/04/13 22:26:37 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:26:37 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 2.9 GB)
20/04/13 22:26:37 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 16 ms
20/04/13 22:26:38 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:26:43 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:26:43 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:26:43 INFO util.ShutdownHookManager: Shutdown hook called
20/04/13 22:26:43 ERROR executor.Executor: Exception in task 5.1 in stage 4.0 (TID 35)
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:26:43 INFO executor.Executor: Not reporting error to driver during JVM shutdown.
20/04/13 22:26:43 ERROR util.SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 35,5,main]
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 22710"...
End of LogType:stdout



Container: container_1586815278733_0007_02_000006 on 178.62.197.156_36923
===========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:16265
Log Contents:
20/04/13 22:27:20 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 23162@178.62.197.156
20/04/13 22:27:20 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:27:20 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:27:20 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:27:20 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:27:20 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:27:20 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:27:20 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:27:20 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:27:21 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 55 ms (0 ms spent in bootstraps)
20/04/13 22:27:21 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:27:21 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:27:21 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:27:21 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:27:21 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:27:21 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 3 ms (0 ms spent in bootstraps)
20/04/13 22:27:21 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-72d69de0-8feb-44f3-aacd-5f7b115e39d0
20/04/13 22:27:21 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:27:21 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@64.227.70.177:45487
20/04/13 22:27:21 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:27:21 INFO executor.Executor: Starting executor ID 5 on host 178.62.197.156
20/04/13 22:27:21 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39129.
20/04/13 22:27:21 INFO netty.NettyBlockTransferService: Server created on 178.62.197.156:39129
20/04/13 22:27:21 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:27:21 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(5, 178.62.197.156, 39129, None)
20/04/13 22:27:21 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(5, 178.62.197.156, 39129, None)
20/04/13 22:27:21 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(5, 178.62.197.156, 39129, None)
20/04/13 22:27:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 32
20/04/13 22:27:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 33
20/04/13 22:27:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 34
20/04/13 22:27:21 INFO executor.Executor: Running task 6.1 in stage 4.0 (TID 34)
20/04/13 22:27:21 INFO executor.Executor: Running task 3.1 in stage 4.0 (TID 32)
20/04/13 22:27:21 INFO executor.Executor: Running task 8.1 in stage 4.0 (TID 33)
20/04/13 22:27:22 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:27:22 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:43885 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:27:22 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 3.0 GB)
20/04/13 22:27:22 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 122 ms
20/04/13 22:27:22 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 3.0 GB)
20/04/13 22:27:22 INFO codegen.CodeGenerator: Code generated in 375.592514 ms
20/04/13 22:27:22 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00008-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-213844, partition values: [empty row]
20/04/13 22:27:22 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00004-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4935172, partition values: [empty row]
20/04/13 22:27:22 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:27:22 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00001-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4785170, partition values: [empty row]
20/04/13 22:27:22 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/13 22:27:22 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 17 ms
20/04/13 22:27:23 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:27:24 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:24 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:24 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:24 INFO codegen.CodeGenerator: Code generated in 25.752651 ms
20/04/13 22:27:24 INFO codegen.CodeGenerator: Code generated in 19.495588 ms
20/04/13 22:27:24 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5926 records.
20/04/13 22:27:24 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11557 records.
20/04/13 22:27:24 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 472 records.
20/04/13 22:27:24 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:24 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:24 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:24 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:24 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:24 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:24 INFO hadoop.InternalParquetRecordReader: block read in memory in 32 ms. row count = 472
20/04/13 22:27:24 INFO hadoop.InternalParquetRecordReader: block read in memory in 35 ms. row count = 5926
20/04/13 22:27:24 INFO hadoop.InternalParquetRecordReader: block read in memory in 37 ms. row count = 11557
20/04/13 22:27:24 INFO memory.MemoryStore: Block rdd_4_8 stored as values in memory (estimated size 1296.6 KB, free 3.0 GB)
20/04/13 22:27:24 INFO codegen.CodeGenerator: Code generated in 12.370415 ms
20/04/13 22:27:24 INFO codegen.CodeGenerator: Code generated in 23.856814 ms
20/04/13 22:27:25 INFO memory.MemoryStore: Block rdd_4_6 stored as values in memory (estimated size 33.8 MB, free 3.0 GB)
20/04/13 22:27:25 INFO memory.MemoryStore: Block rdd_4_3 stored as values in memory (estimated size 32.5 MB, free 3.0 GB)
20/04/13 22:27:26 INFO codegen.CodeGenerator: Code generated in 12.112873 ms
20/04/13 22:27:26 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:27:26 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 3.0 GB)
20/04/13 22:27:26 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 10 ms
20/04/13 22:27:26 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 3.0 GB)
20/04/13 22:27:26 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:27:26 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 3.0 GB)
20/04/13 22:27:26 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 20 ms
20/04/13 22:27:27 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:27:34 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:27:34 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:27:34 ERROR executor.Executor: Exception in task 6.1 in stage 4.0 (TID 34)
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:27:34 INFO executor.Executor: Not reporting error to driver during JVM shutdown.
20/04/13 22:27:34 ERROR util.SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 34,5,main]
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:27:34 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 23162"...
End of LogType:stdout



Container: container_1586815278733_0007_02_000004 on 178.62.197.156_36923
===========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:13803
Log Contents:
20/04/13 22:26:55 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22970@178.62.197.156
20/04/13 22:26:55 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:55 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:55 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:56 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:56 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:56 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:56 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:56 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:56 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 48 ms (0 ms spent in bootstraps)
20/04/13 22:26:56 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:56 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:56 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:56 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:56 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:56 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:26:56 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-332ddf96-f013-45ef-a0e8-c2de9b2bbbec
20/04/13 22:26:56 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:56 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@64.227.70.177:45487
20/04/13 22:26:56 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:26:56 INFO executor.Executor: Starting executor ID 3 on host 178.62.197.156
20/04/13 22:26:57 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44225.
20/04/13 22:26:57 INFO netty.NettyBlockTransferService: Server created on 178.62.197.156:44225
20/04/13 22:26:57 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:57 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(3, 178.62.197.156, 44225, None)
20/04/13 22:26:57 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(3, 178.62.197.156, 44225, None)
20/04/13 22:26:57 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(3, 178.62.197.156, 44225, None)
20/04/13 22:27:04 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 5
20/04/13 22:27:04 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 8
20/04/13 22:27:04 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 10
20/04/13 22:27:04 INFO executor.Executor: Running task 3.0 in stage 2.0 (TID 5)
20/04/13 22:27:04 INFO executor.Executor: Running task 8.0 in stage 2.0 (TID 10)
20/04/13 22:27:04 INFO executor.Executor: Running task 6.0 in stage 2.0 (TID 8)
20/04/13 22:27:04 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/13 22:27:04 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:42931 after 3 ms (0 ms spent in bootstraps)
20/04/13 22:27:04 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:27:04 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 123 ms
20/04/13 22:27:04 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 21.3 KB, free 3.0 GB)
20/04/13 22:27:05 INFO codegen.CodeGenerator: Code generated in 216.752107 ms
20/04/13 22:27:05 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00004-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4935172, partition values: [empty row]
20/04/13 22:27:05 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00008-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-213844, partition values: [empty row]
20/04/13 22:27:05 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00001-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4785170, partition values: [empty row]
20/04/13 22:27:05 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:27:05 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/13 22:27:05 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 17 ms
20/04/13 22:27:05 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:27:06 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:06 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:06 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:06 INFO codegen.CodeGenerator: Code generated in 26.231031 ms
20/04/13 22:27:06 INFO codegen.CodeGenerator: Code generated in 18.893959 ms
20/04/13 22:27:06 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11557 records.
20/04/13 22:27:06 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5926 records.
20/04/13 22:27:06 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 472 records.
20/04/13 22:27:06 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:06 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:06 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:07 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:07 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:07 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:07 INFO hadoop.InternalParquetRecordReader: block read in memory in 38 ms. row count = 472
20/04/13 22:27:07 INFO hadoop.InternalParquetRecordReader: block read in memory in 39 ms. row count = 5926
20/04/13 22:27:07 INFO hadoop.InternalParquetRecordReader: block read in memory in 39 ms. row count = 11557
20/04/13 22:27:07 INFO memory.MemoryStore: Block rdd_4_8 stored as values in memory (estimated size 1296.6 KB, free 3.0 GB)
20/04/13 22:27:07 INFO codegen.CodeGenerator: Code generated in 12.994713 ms
20/04/13 22:27:07 INFO codegen.CodeGenerator: Code generated in 53.66796 ms
20/04/13 22:27:08 INFO memory.MemoryStore: Block rdd_4_6 stored as values in memory (estimated size 33.8 MB, free 3.0 GB)
20/04/13 22:27:08 INFO memory.MemoryStore: Block rdd_4_3 stored as values in memory (estimated size 32.5 MB, free 3.0 GB)
20/04/13 22:27:08 INFO codegen.CodeGenerator: Code generated in 15.863105 ms
20/04/13 22:27:08 INFO executor.Executor: Finished task 8.0 in stage 2.0 (TID 10). 1427 bytes result sent to driver
20/04/13 22:27:09 INFO executor.Executor: Finished task 6.0 in stage 2.0 (TID 8). 1427 bytes result sent to driver
20/04/13 22:27:09 INFO executor.Executor: Finished task 3.0 in stage 2.0 (TID 5). 1470 bytes result sent to driver
20/04/13 22:27:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 12
20/04/13 22:27:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 15
20/04/13 22:27:09 INFO executor.Executor: Running task 6.0 in stage 3.0 (TID 15)
20/04/13 22:27:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 18
20/04/13 22:27:09 INFO executor.Executor: Running task 3.0 in stage 3.0 (TID 12)
20/04/13 22:27:09 INFO executor.Executor: Running task 8.0 in stage 3.0 (TID 18)
20/04/13 22:27:09 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/13 22:27:09 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.5 KB, free 3.0 GB)
20/04/13 22:27:09 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 10 ms
20/04/13 22:27:09 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 38.4 KB, free 3.0 GB)
20/04/13 22:27:09 INFO storage.BlockManager: Found block rdd_4_8 locally
20/04/13 22:27:09 INFO storage.BlockManager: Found block rdd_4_3 locally
20/04/13 22:27:09 INFO storage.BlockManager: Found block rdd_4_6 locally
20/04/13 22:27:09 INFO executor.Executor: Finished task 8.0 in stage 3.0 (TID 18). 1363 bytes result sent to driver
20/04/13 22:27:09 INFO executor.Executor: Finished task 6.0 in stage 3.0 (TID 15). 8331 bytes result sent to driver
20/04/13 22:27:09 INFO executor.Executor: Finished task 3.0 in stage 3.0 (TID 12). 20594 bytes result sent to driver
20/04/13 22:27:11 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 20
20/04/13 22:27:11 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 23
20/04/13 22:27:11 INFO executor.Executor: Running task 3.0 in stage 4.0 (TID 20)
20/04/13 22:27:11 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 26
20/04/13 22:27:11 INFO executor.Executor: Running task 6.0 in stage 4.0 (TID 23)
20/04/13 22:27:11 INFO executor.Executor: Running task 8.0 in stage 4.0 (TID 26)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:27:11 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:38753 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 3.0 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 26 ms
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 3.0 GB)
20/04/13 22:27:11 INFO storage.BlockManager: Found block rdd_4_8 locally
20/04/13 22:27:11 INFO storage.BlockManager: Found block rdd_4_6 locally
20/04/13 22:27:11 INFO storage.BlockManager: Found block rdd_4_3 locally
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 3.0 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 9 ms
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 3.0 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 3.0 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 23 ms
20/04/13 22:27:12 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:27:17 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:27:17 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:27:17 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 22970"...
End of LogType:stdout



Container: container_1586815278733_0007_02_000005 on 178.62.197.156_36923
===========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:16261
Log Contents:
20/04/13 22:27:19 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 23123@178.62.197.156
20/04/13 22:27:19 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:27:19 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:27:19 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:27:19 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:27:19 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:27:19 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:27:19 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:27:19 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:27:19 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 54 ms (0 ms spent in bootstraps)
20/04/13 22:27:20 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:27:20 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:27:20 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:27:20 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:27:20 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:27:20 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 6 ms (0 ms spent in bootstraps)
20/04/13 22:27:20 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-523df0e6-2d31-4c59-a359-3e643a05f69c
20/04/13 22:27:20 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:27:20 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@64.227.70.177:45487
20/04/13 22:27:20 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:27:20 INFO executor.Executor: Starting executor ID 4 on host 178.62.197.156
20/04/13 22:27:20 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43885.
20/04/13 22:27:20 INFO netty.NettyBlockTransferService: Server created on 178.62.197.156:43885
20/04/13 22:27:20 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:27:20 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(4, 178.62.197.156, 43885, None)
20/04/13 22:27:20 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(4, 178.62.197.156, 43885, None)
20/04/13 22:27:20 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(4, 178.62.197.156, 43885, None)
20/04/13 22:27:20 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 29
20/04/13 22:27:20 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 30
20/04/13 22:27:20 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 31
20/04/13 22:27:20 INFO executor.Executor: Running task 4.1 in stage 4.0 (TID 29)
20/04/13 22:27:20 INFO executor.Executor: Running task 1.1 in stage 4.0 (TID 30)
20/04/13 22:27:20 INFO executor.Executor: Running task 7.1 in stage 4.0 (TID 31)
20/04/13 22:27:20 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:27:20 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:38753 after 13 ms (0 ms spent in bootstraps)
20/04/13 22:27:20 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 3.0 GB)
20/04/13 22:27:20 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 99 ms
20/04/13 22:27:20 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 3.0 GB)
20/04/13 22:27:21 INFO codegen.CodeGenerator: Code generated in 315.8342 ms
20/04/13 22:27:21 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00002-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4735846, partition values: [empty row]
20/04/13 22:27:21 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00003-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4855590, partition values: [empty row]
20/04/13 22:27:21 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00005-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4950456, partition values: [empty row]
20/04/13 22:27:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:27:21 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/13 22:27:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 10 ms
20/04/13 22:27:21 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:27:22 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:22 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:22 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:22 INFO codegen.CodeGenerator: Code generated in 34.906333 ms
20/04/13 22:27:22 INFO codegen.CodeGenerator: Code generated in 28.940955 ms
20/04/13 22:27:22 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11838 records.
20/04/13 22:27:22 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 6080 records.
20/04/13 22:27:22 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 9550 records.
20/04/13 22:27:22 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:22 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:22 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:22 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:22 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:22 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:22 INFO hadoop.InternalParquetRecordReader: block read in memory in 44 ms. row count = 9550
20/04/13 22:27:22 INFO hadoop.InternalParquetRecordReader: block read in memory in 44 ms. row count = 6080
20/04/13 22:27:22 INFO hadoop.InternalParquetRecordReader: block read in memory in 46 ms. row count = 11838
20/04/13 22:27:24 INFO memory.MemoryStore: Block rdd_4_1 stored as values in memory (estimated size 32.6 MB, free 3.0 GB)
20/04/13 22:27:24 INFO memory.MemoryStore: Block rdd_4_4 stored as values in memory (estimated size 33.1 MB, free 3.0 GB)
20/04/13 22:27:24 INFO memory.MemoryStore: Block rdd_4_7 stored as values in memory (estimated size 33.4 MB, free 2.9 GB)
20/04/13 22:27:24 INFO codegen.CodeGenerator: Code generated in 6.74954 ms
20/04/13 22:27:24 INFO codegen.CodeGenerator: Code generated in 48.014256 ms
20/04/13 22:27:25 INFO codegen.CodeGenerator: Code generated in 17.695322 ms
20/04/13 22:27:25 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:27:25 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 2.9 GB)
20/04/13 22:27:25 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 20 ms
20/04/13 22:27:25 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 2.9 GB)
20/04/13 22:27:25 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:27:25 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 2.9 GB)
20/04/13 22:27:25 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 34 ms
20/04/13 22:27:26 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:27:31 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:27:31 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:27:31 ERROR executor.Executor: Exception in task 1.1 in stage 4.0 (TID 30)
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:27:31 INFO executor.Executor: Not reporting error to driver during JVM shutdown.
20/04/13 22:27:31 INFO util.ShutdownHookManager: Shutdown hook called
20/04/13 22:27:31 ERROR util.SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 30,5,main]
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 23123"...
End of LogType:stdout



Container: container_1586815278733_0007_01_000001 on 178.62.197.156_36923
===========================================================================
LogType:pyspark.log
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:23295
Log Contents:
[PYTHON] 2020-04-13 22:26:08,239.239 INFO clustering - wrapper: perform_experiment keyword arguments:
[PYTHON] 2020-04-13 22:26:08,241.241 INFO clustering - wrapper: in_files: ['/data/df_3-shingles_sparse-binary-vectors.parquet']
[PYTHON] 2020-04-13 22:26:08,241.241 INFO clustering - wrapper: distances: ['euclidean', 'cosine']
[PYTHON] 2020-04-13 22:26:08,241.241 INFO clustering - wrapper: ks: [2, 4]
[PYTHON] 2020-04-13 22:26:08,241.241 INFO clustering - wrapper: models: [<class 'pyspark.ml.clustering.GaussianMixture'>]
[PYTHON] 2020-04-13 22:26:08,241.241 INFO clustering - wrapper: result_dfs_list: []
[PYTHON] 2020-04-13 22:26:48,339.339 INFO java_gateway - send_command: Error while receiving.
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1159, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
[PYTHON] 2020-04-13 22:26:48,340.340 ERROR java_gateway - send_command: Exception while sending command.
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1159, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 985, in send_command
    response = connection.send_command(command)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1164, in send_command
    "Error while receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while receiving
[PYTHON] 2020-04-13 22:26:48,342.342 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,343.343 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,343.343 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,343.343 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,344.344 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,344.344 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,345.345 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,345.345 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,347.347 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,347.347 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,349.349 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,349.349 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,350.350 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,351.351 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,351.351 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,351.351 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,352.352 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,352.352 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,352.352 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,352.352 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,353.353 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,353.353 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,353.353 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,354.354 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,354.354 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,354.354 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,355.355 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,355.355 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,433.433 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:26:48,439.439 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:46257)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
End of LogType:pyspark.log

LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:88159
Log Contents:
20/04/13 22:25:59 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:25:59 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:25:59 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:25:59 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:25:59 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:25:59 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:25:59 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:25:59 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:00 INFO yarn.ApplicationMaster: Preparing Local resources
20/04/13 22:26:01 INFO yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1586815278733_0007_000001
20/04/13 22:26:01 INFO yarn.ApplicationMaster: Starting the user application in a separate Thread
20/04/13 22:26:01 INFO yarn.ApplicationMaster: Waiting for spark context initialization...
20/04/13 22:26:01 INFO spark.SparkContext: Running Spark version 2.4.5
20/04/13 22:26:01 INFO spark.SparkContext: Submitted application: ClusteringExperiment
20/04/13 22:26:01 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:01 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:01 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:01 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:01 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:01 INFO util.Utils: Successfully started service 'sparkDriver' on port 39167.
20/04/13 22:26:01 INFO spark.SparkEnv: Registering MapOutputTracker
20/04/13 22:26:01 INFO spark.SparkEnv: Registering BlockManagerMaster
20/04/13 22:26:01 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/04/13 22:26:01 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/04/13 22:26:01 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-1a619158-cb43-4a1d-967f-ffa9c105d546
20/04/13 22:26:01 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:02 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/04/13 22:26:02 INFO util.log: Logging initialized @2740ms
20/04/13 22:26:02 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/04/13 22:26:02 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
20/04/13 22:26:02 INFO server.Server: Started @2810ms
20/04/13 22:26:02 INFO server.AbstractConnector: Started ServerConnector@87b98ec{HTTP/1.1,[http/1.1]}{0.0.0.0:35903}
20/04/13 22:26:02 INFO util.Utils: Successfully started service 'SparkUI' on port 35903.
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7686c9a5{/jobs,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f810d64{/jobs/json,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7c0acb48{/jobs/job,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5773cc74{/jobs/job/json,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@400e01d3{/stages,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6a74c211{/stages/json,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a0c789a{/stages/stage,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@f4db2c4{/stages/stage/json,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@565cc31f{/stages/pool,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@dcc891c{/stages/pool/json,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6261c64a{/storage,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@588350{/storage/json,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30acec7f{/storage/rdd,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59c1071f{/storage/rdd/json,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35fed9fb{/environment,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@71f88e17{/environment/json,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26604b43{/executors,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7748596f{/executors/json,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@343a677c{/executors/threadDump,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@187dfda{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2519b6fa{/static,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9b28038{/,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f578d46{/api,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68ecc2{/jobs/job/kill,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c862ede{/stages/stage/kill,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://178.62.197.156:35903
20/04/13 22:26:02 INFO cluster.YarnClusterScheduler: Created YarnClusterScheduler
20/04/13 22:26:02 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1586815278733_0007 and attemptId Some(appattempt_1586815278733_0007_000001)
20/04/13 22:26:02 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45529.
20/04/13 22:26:02 INFO netty.NettyBlockTransferService: Server created on 178.62.197.156:45529
20/04/13 22:26:02 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:02 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 178.62.197.156, 45529, None)
20/04/13 22:26:02 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.197.156:45529 with 3.0 GB RAM, BlockManagerId(driver, 178.62.197.156, 45529, None)
20/04/13 22:26:02 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 178.62.197.156, 45529, None)
20/04/13 22:26:02 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 178.62.197.156, 45529, None)
20/04/13 22:26:02 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/04/13 22:26:02 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d9fa649{/metrics/json,null,AVAILABLE,@Spark}
20/04/13 22:26:02 INFO client.RMProxy: Connecting to ResourceManager at /178.62.197.108:8030
20/04/13 22:26:02 INFO yarn.YarnRMClient: Registering the ApplicationMaster
20/04/13 22:26:02 INFO yarn.ApplicationMaster: 
===============================================================================
YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>$HADOOP_CONF_DIR<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/*<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/lib/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<CPS>/usr/src/hadoop-2.8.5/etc/hadoop:/usr/src/hadoop-2.8.5/share/hadoop/common/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/common/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/*:/usr/src/hadoop-2.8.5/contrib/capacity-scheduler/*.jar<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_DIST_CLASSPATH -> /usr/src/hadoop-2.8.5/etc/hadoop:/usr/src/hadoop-2.8.5/share/hadoop/common/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/common/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/*:/usr/src/hadoop-2.8.5/contrib/capacity-scheduler/*.jar
    SPARK_YARN_STAGING_DIR -> hdfs://178.62.197.108:9000/user/root/.sparkStaging/application_1586815278733_0007
    SPARK_USER -> root
    PYTHONPATH -> /usr/src/spark-2.4.5-bin-without-hadoop/python:/usr/src/spark-2.4.5-bin-without-hadoop/python/build:/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/pyspark.zip:/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.7-src.zip

  command:
    {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx6144m \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.ui.port=0' \ 
      '-Dspark.driver.port=39167' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.CoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@178.62.197.156:39167 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      3 \ 
      --app-id \ 
      application_1586815278733_0007 \ 
      --user-class-path \ 
      file:$PWD/__app__.jar \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    pyspark.zip -> resource { scheme: "hdfs" host: "178.62.197.108" port: 9000 file: "/user/root/.sparkStaging/application_1586815278733_0007/pyspark.zip" } size: 591945 timestamp: 1586816756842 type: FILE visibility: PRIVATE
    py4j-0.10.7-src.zip -> resource { scheme: "hdfs" host: "178.62.197.108" port: 9000 file: "/user/root/.sparkStaging/application_1586815278733_0007/py4j-0.10.7-src.zip" } size: 42437 timestamp: 1586816756866 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "178.62.197.108" port: 9000 file: "/user/root/.sparkStaging/application_1586815278733_0007/__spark_libs__4999350945858927134.zip" } size: 168822862 timestamp: 1586816756677 type: ARCHIVE visibility: PRIVATE
    __spark_conf__ -> resource { scheme: "hdfs" host: "178.62.197.108" port: 9000 file: "/user/root/.sparkStaging/application_1586815278733_0007/__spark_conf__.zip" } size: 233332 timestamp: 1586816756990 type: ARCHIVE visibility: PRIVATE

===============================================================================
20/04/13 22:26:02 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@178.62.197.156:39167)
20/04/13 22:26:02 INFO yarn.YarnAllocator: Will request 3 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/13 22:26:02 INFO yarn.YarnAllocator: Submitted 3 unlocalized container requests.
20/04/13 22:26:02 INFO yarn.ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
20/04/13 22:26:04 INFO impl.AMRMClientImpl: Received new token for : 178.62.197.156:36923
20/04/13 22:26:04 INFO impl.AMRMClientImpl: Received new token for : 64.227.70.177:41217
20/04/13 22:26:04 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_01_000002 on host 178.62.197.156 for executor with ID 1
20/04/13 22:26:04 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_01_000003 on host 64.227.70.177 for executor with ID 2
20/04/13 22:26:04 INFO yarn.YarnAllocator: Received 2 containers from YARN, launching executors on 2 of them.
20/04/13 22:26:04 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:26:04 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:26:05 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_01_000005 on host 64.227.70.177 for executor with ID 3
20/04/13 22:26:05 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/13 22:26:05 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:26:06 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.197.156:49726) with ID 1
20/04/13 22:26:06 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.197.156:35373 with 3.0 GB RAM, BlockManagerId(1, 178.62.197.156, 35373, None)
20/04/13 22:26:06 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (64.227.70.177:37534) with ID 2
20/04/13 22:26:06 INFO storage.BlockManagerMasterEndpoint: Registering block manager 64.227.70.177:33507 with 3.0 GB RAM, BlockManagerId(2, 64.227.70.177, 33507, None)
20/04/13 22:26:07 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (64.227.70.177:37538) with ID 3
20/04/13 22:26:07 INFO cluster.YarnClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
20/04/13 22:26:07 INFO cluster.YarnClusterScheduler: YarnClusterScheduler.postStartHook done
20/04/13 22:26:07 INFO storage.BlockManagerMasterEndpoint: Registering block manager 64.227.70.177:43849 with 3.0 GB RAM, BlockManagerId(3, 64.227.70.177, 43849, None)
20/04/13 22:26:07 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/container_1586815278733_0007_01_000001/spark-warehouse').
20/04/13 22:26:07 INFO internal.SharedState: Warehouse path is 'file:/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/container_1586815278733_0007_01_000001/spark-warehouse'.
20/04/13 22:26:07 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.
20/04/13 22:26:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@53246edc{/SQL,null,AVAILABLE,@Spark}
20/04/13 22:26:07 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.
20/04/13 22:26:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@34489238{/SQL/json,null,AVAILABLE,@Spark}
20/04/13 22:26:07 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.
20/04/13 22:26:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@410d2bf3{/SQL/execution,null,AVAILABLE,@Spark}
20/04/13 22:26:07 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.
20/04/13 22:26:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@106a7e7a{/SQL/execution/json,null,AVAILABLE,@Spark}
20/04/13 22:26:07 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.
20/04/13 22:26:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@790982e8{/static/sql,null,AVAILABLE,@Spark}
20/04/13 22:26:08 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
20/04/13 22:26:08 INFO datasources.InMemoryFileIndex: It took 102 ms to list leaf files for 1 paths.
20/04/13 22:26:08 INFO spark.SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
20/04/13 22:26:08 INFO scheduler.DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/04/13 22:26:08 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
20/04/13 22:26:08 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/04/13 22:26:08 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/13 22:26:08 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
20/04/13 22:26:08 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 127.0 KB, free 3.0 GB)
20/04/13 22:26:08 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.1 KB, free 3.0 GB)
20/04/13 22:26:08 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 178.62.197.156:45529 (size: 33.1 KB, free: 3.0 GB)
20/04/13 22:26:08 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1163
20/04/13 22:26:08 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/04/13 22:26:08 INFO cluster.YarnClusterScheduler: Adding task set 0.0 with 1 tasks
20/04/13 22:26:08 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 178.62.197.156, executor 1, partition 0, PROCESS_LOCAL, 8099 bytes)
20/04/13 22:26:09 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 178.62.197.156:35373 (size: 33.1 KB, free: 3.0 GB)
20/04/13 22:26:10 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1452 ms on 178.62.197.156 (executor 1) (1/1)
20/04/13 22:26:10 INFO cluster.YarnClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/04/13 22:26:10 INFO scheduler.DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.562 s
20/04/13 22:26:10 INFO scheduler.DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.601698 s
20/04/13 22:26:11 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/04/13 22:26:11 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/04/13 22:26:11 INFO datasources.FileSourceStrategy: Output Data Schema: struct<entry: string, entry_name: string, features: vector ... 1 more fields>
20/04/13 22:26:11 INFO execution.FileSourceScanExec: Pushed Filters: 
20/04/13 22:26:11 INFO codegen.CodeGenerator: Code generated in 214.761485 ms
20/04/13 22:26:11 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 341.6 KB, free 3.0 GB)
20/04/13 22:26:11 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/13 22:26:11 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.197.156:45529 (size: 32.4 KB, free: 3.0 GB)
20/04/13 22:26:11 INFO spark.SparkContext: Created broadcast 1 from rdd at GaussianMixture.scala:348
20/04/13 22:26:11 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 8546355 bytes, open cost is considered as scanning 4194304 bytes.
20/04/13 22:26:12 INFO spark.SparkContext: Starting job: first at GaussianMixture.scala:357
20/04/13 22:26:12 INFO scheduler.DAGScheduler: Got job 1 (first at GaussianMixture.scala:357) with 1 output partitions
20/04/13 22:26:12 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (first at GaussianMixture.scala:357)
20/04/13 22:26:12 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/04/13 22:26:12 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/13 22:26:12 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at map at GaussianMixture.scala:348), which has no missing parents
20/04/13 22:26:12 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 21.5 KB, free 3.0 GB)
20/04/13 22:26:12 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:26:12 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 178.62.197.156:45529 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:26:12 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1163
20/04/13 22:26:12 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at map at GaussianMixture.scala:348) (first 15 tasks are for partitions Vector(0))
20/04/13 22:26:12 INFO cluster.YarnClusterScheduler: Adding task set 1.0 with 1 tasks
20/04/13 22:26:12 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 64.227.70.177, executor 2, partition 0, NODE_LOCAL, 8348 bytes)
20/04/13 22:26:12 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 64.227.70.177:33507 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:26:12 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 64.227.70.177:33507 (size: 32.4 KB, free: 3.0 GB)
20/04/13 22:26:14 INFO storage.BlockManagerInfo: Added rdd_4_0 in memory on 64.227.70.177:33507 (size: 32.6 MB, free: 3.0 GB)
20/04/13 22:26:15 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3146 ms on 64.227.70.177 (executor 2) (1/1)
20/04/13 22:26:15 INFO cluster.YarnClusterScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/04/13 22:26:15 INFO scheduler.DAGScheduler: ResultStage 1 (first at GaussianMixture.scala:357) finished in 3.156 s
20/04/13 22:26:15 INFO scheduler.DAGScheduler: Job 1 finished: first at GaussianMixture.scala:357, took 3.164829 s
20/04/13 22:26:15 INFO util.Instrumentation: [43faf88a] Stage class: GaussianMixture
20/04/13 22:26:15 INFO util.Instrumentation: [43faf88a] Stage uid: GaussianMixture_24e3d15500c7
20/04/13 22:26:15 INFO util.Instrumentation: [43faf88a] training: numPartitions=9 storageLevel=StorageLevel(1 replicas)
20/04/13 22:26:15 INFO util.Instrumentation: [43faf88a] {"featuresCol":"features","predictionCol":"cluster","k":2,"seed":42}
20/04/13 22:26:15 INFO util.Instrumentation: [43faf88a] {"numFeatures":8502}
20/04/13 22:26:15 INFO spark.SparkContext: Starting job: takeSample at GaussianMixture.scala:470
20/04/13 22:26:15 INFO scheduler.DAGScheduler: Got job 2 (takeSample at GaussianMixture.scala:470) with 9 output partitions
20/04/13 22:26:15 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (takeSample at GaussianMixture.scala:470)
20/04/13 22:26:15 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/04/13 22:26:15 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/13 22:26:15 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at map at GaussianMixture.scala:348), which has no missing parents
20/04/13 22:26:15 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 21.3 KB, free 3.0 GB)
20/04/13 22:26:15 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:26:15 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.197.156:45529 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:26:15 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1163
20/04/13 22:26:15 INFO scheduler.DAGScheduler: Submitting 9 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at map at GaussianMixture.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))
20/04/13 22:26:15 INFO cluster.YarnClusterScheduler: Adding task set 2.0 with 9 tasks
20/04/13 22:26:15 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 64.227.70.177, executor 2, partition 0, PROCESS_LOCAL, 8348 bytes)
20/04/13 22:26:15 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, 64.227.70.177, executor 2, partition 1, NODE_LOCAL, 8348 bytes)
20/04/13 22:26:15 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4, 178.62.197.156, executor 1, partition 2, NODE_LOCAL, 8348 bytes)
20/04/13 22:26:15 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5, 64.227.70.177, executor 3, partition 3, NODE_LOCAL, 8348 bytes)
20/04/13 22:26:15 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 2.0 (TID 6, 64.227.70.177, executor 2, partition 4, NODE_LOCAL, 8348 bytes)
20/04/13 22:26:15 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 2.0 (TID 7, 178.62.197.156, executor 1, partition 5, NODE_LOCAL, 8348 bytes)
20/04/13 22:26:15 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 2.0 (TID 8, 64.227.70.177, executor 3, partition 6, NODE_LOCAL, 8348 bytes)
20/04/13 22:26:15 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 2.0 (TID 9, 178.62.197.156, executor 1, partition 7, NODE_LOCAL, 8348 bytes)
20/04/13 22:26:15 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 2.0 (TID 10, 64.227.70.177, executor 3, partition 8, NODE_LOCAL, 8348 bytes)
20/04/13 22:26:15 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 64.227.70.177:33507 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:26:15 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.197.156:35373 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:26:15 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 64.227.70.177:43849 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:26:15 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 471 ms on 64.227.70.177 (executor 2) (1/9)
20/04/13 22:26:15 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.197.156:35373 (size: 32.4 KB, free: 3.0 GB)
20/04/13 22:26:16 INFO storage.BlockManagerInfo: Added rdd_4_4 in memory on 64.227.70.177:33507 (size: 33.1 MB, free: 3.0 GB)
20/04/13 22:26:16 INFO storage.BlockManagerInfo: Added rdd_4_1 in memory on 64.227.70.177:33507 (size: 32.6 MB, free: 2.9 GB)
20/04/13 22:26:16 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 2.0 (TID 6) in 913 ms on 64.227.70.177 (executor 2) (2/9)
20/04/13 22:26:16 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 917 ms on 64.227.70.177 (executor 2) (3/9)
20/04/13 22:26:16 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 64.227.70.177:43849 (size: 32.4 KB, free: 3.0 GB)
20/04/13 22:26:17 INFO storage.BlockManagerInfo: Added rdd_4_7 in memory on 178.62.197.156:35373 (size: 33.4 MB, free: 3.0 GB)
20/04/13 22:26:17 INFO storage.BlockManagerInfo: Added rdd_4_2 in memory on 178.62.197.156:35373 (size: 32.6 MB, free: 3.0 GB)
20/04/13 22:26:17 INFO storage.BlockManagerInfo: Added rdd_4_5 in memory on 178.62.197.156:35373 (size: 33.8 MB, free: 2.9 GB)
20/04/13 22:26:17 INFO storage.BlockManagerInfo: Added rdd_4_8 in memory on 64.227.70.177:43849 (size: 1296.6 KB, free: 3.0 GB)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 2.0 (TID 9) in 3010 ms on 178.62.197.156 (executor 1) (4/9)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 2.0 (TID 7) in 3013 ms on 178.62.197.156 (executor 1) (5/9)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 3021 ms on 178.62.197.156 (executor 1) (6/9)
20/04/13 22:26:18 INFO storage.BlockManagerInfo: Added rdd_4_3 in memory on 64.227.70.177:43849 (size: 32.5 MB, free: 3.0 GB)
20/04/13 22:26:18 INFO storage.BlockManagerInfo: Added rdd_4_6 in memory on 64.227.70.177:43849 (size: 33.8 MB, free: 3.0 GB)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 2.0 (TID 10) in 3535 ms on 64.227.70.177 (executor 3) (7/9)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 2.0 (TID 8) in 3632 ms on 64.227.70.177 (executor 3) (8/9)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 3647 ms on 64.227.70.177 (executor 3) (9/9)
20/04/13 22:26:18 INFO cluster.YarnClusterScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/04/13 22:26:18 INFO scheduler.DAGScheduler: ResultStage 2 (takeSample at GaussianMixture.scala:470) finished in 3.656 s
20/04/13 22:26:18 INFO scheduler.DAGScheduler: Job 2 finished: takeSample at GaussianMixture.scala:470, took 3.660643 s
20/04/13 22:26:18 INFO spark.SparkContext: Starting job: takeSample at GaussianMixture.scala:470
20/04/13 22:26:18 INFO scheduler.DAGScheduler: Got job 3 (takeSample at GaussianMixture.scala:470) with 9 output partitions
20/04/13 22:26:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (takeSample at GaussianMixture.scala:470)
20/04/13 22:26:18 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/04/13 22:26:18 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/13 22:26:18 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (PartitionwiseSampledRDD[18] at takeSample at GaussianMixture.scala:470), which has no missing parents
20/04/13 22:26:18 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 38.4 KB, free 3.0 GB)
20/04/13 22:26:18 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.5 KB, free 3.0 GB)
20/04/13 22:26:18 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.197.156:45529 (size: 18.5 KB, free: 3.0 GB)
20/04/13 22:26:18 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1163
20/04/13 22:26:18 INFO scheduler.DAGScheduler: Submitting 9 missing tasks from ResultStage 3 (PartitionwiseSampledRDD[18] at takeSample at GaussianMixture.scala:470) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))
20/04/13 22:26:18 INFO cluster.YarnClusterScheduler: Adding task set 3.0 with 9 tasks
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 11, 64.227.70.177, executor 2, partition 0, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 3.0 (TID 12, 64.227.70.177, executor 3, partition 3, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 3.0 (TID 13, 178.62.197.156, executor 1, partition 2, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 14, 64.227.70.177, executor 2, partition 1, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 3.0 (TID 15, 64.227.70.177, executor 3, partition 6, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 3.0 (TID 16, 178.62.197.156, executor 1, partition 5, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 3.0 (TID 17, 64.227.70.177, executor 2, partition 4, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 3.0 (TID 18, 64.227.70.177, executor 3, partition 8, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:26:18 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 3.0 (TID 19, 178.62.197.156, executor 1, partition 7, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:26:18 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 64.227.70.177:33507 (size: 18.5 KB, free: 2.9 GB)
20/04/13 22:26:18 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.197.156:35373 (size: 18.5 KB, free: 2.9 GB)
20/04/13 22:26:18 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 64.227.70.177:43849 (size: 18.5 KB, free: 3.0 GB)
20/04/13 22:26:19 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 3.0 (TID 18) in 110 ms on 64.227.70.177 (executor 3) (1/9)
20/04/13 22:26:19 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 3.0 (TID 16) in 126 ms on 178.62.197.156 (executor 1) (2/9)
20/04/13 22:26:19 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 3.0 (TID 19) in 143 ms on 178.62.197.156 (executor 1) (3/9)
20/04/13 22:26:19 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 3.0 (TID 13) in 150 ms on 178.62.197.156 (executor 1) (4/9)
20/04/13 22:26:19 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 14) in 210 ms on 64.227.70.177 (executor 2) (5/9)
20/04/13 22:26:19 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 3.0 (TID 12) in 227 ms on 64.227.70.177 (executor 3) (6/9)
20/04/13 22:26:19 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 3.0 (TID 17) in 231 ms on 64.227.70.177 (executor 2) (7/9)
20/04/13 22:26:19 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 11) in 236 ms on 64.227.70.177 (executor 2) (8/9)
20/04/13 22:26:19 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 3.0 (TID 15) in 238 ms on 64.227.70.177 (executor 3) (9/9)
20/04/13 22:26:19 INFO cluster.YarnClusterScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/04/13 22:26:19 INFO scheduler.DAGScheduler: ResultStage 3 (takeSample at GaussianMixture.scala:470) finished in 0.246 s
20/04/13 22:26:19 INFO scheduler.DAGScheduler: Job 3 finished: takeSample at GaussianMixture.scala:470, took 0.251106 s
20/04/13 22:26:19 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
20/04/13 22:26:19 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 45
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 40
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 65
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 89
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 54
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 70
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 43
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 49
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 75
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 96
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 69
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 34
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 107
20/04/13 22:26:20 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 178.62.197.156:45529 in memory (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:26:20 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 64.227.70.177:33507 in memory (size: 9.7 KB, free: 2.9 GB)
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 94
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 48
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 73
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 92
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 38
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 88
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 44
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 91
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 93
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 61
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 66
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 74
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 81
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 55
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 98
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 58
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 50
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 68
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 36
20/04/13 22:26:20 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 178.62.197.156:45529 in memory (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:26:20 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 64.227.70.177:33507 in memory (size: 9.7 KB, free: 2.9 GB)
20/04/13 22:26:20 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 64.227.70.177:43849 in memory (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:26:20 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 178.62.197.156:35373 in memory (size: 9.7 KB, free: 2.9 GB)
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 95
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 83
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 37
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 99
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 67
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 35
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 78
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 108
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 106
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 51
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 77
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 71
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 79
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 85
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 86
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 104
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 56
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 46
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 101
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 102
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 52
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 97
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 62
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 39
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 110
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 72
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 64
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 87
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 105
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 57
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 109
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 84
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 41
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 90
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 42
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 63
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 80
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 53
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 82
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 76
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 100
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 103
20/04/13 22:26:20 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 178.62.197.156:45529 in memory (size: 18.5 KB, free: 3.0 GB)
20/04/13 22:26:20 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 64.227.70.177:43849 in memory (size: 18.5 KB, free: 3.0 GB)
20/04/13 22:26:20 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 64.227.70.177:33507 in memory (size: 18.5 KB, free: 2.9 GB)
20/04/13 22:26:20 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 178.62.197.156:35373 in memory (size: 18.5 KB, free: 2.9 GB)
20/04/13 22:26:20 INFO spark.ContextCleaner: Cleaned accumulator 47
20/04/13 22:26:20 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 3.0 GB)
20/04/13 22:26:20 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 3.0 GB)
20/04/13 22:26:20 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.197.156:45529 (size: 85.0 B, free: 3.0 GB)
20/04/13 22:26:20 INFO spark.SparkContext: Created broadcast 5 from broadcast at GaussianMixture.scala:379
20/04/13 22:26:20 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.5 GB)
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 2.5 GB)
20/04/13 22:26:21 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.197.156:45529 (size: 2.7 MB, free: 3.0 GB)
20/04/13 22:26:21 INFO spark.SparkContext: Created broadcast 6 from broadcast at GaussianMixture.scala:380
20/04/13 22:26:21 INFO spark.SparkContext: Starting job: treeAggregate at GaussianMixture.scala:384
20/04/13 22:26:21 INFO scheduler.DAGScheduler: Registering RDD 20 (treeAggregate at GaussianMixture.scala:384) as input to shuffle 0
20/04/13 22:26:21 INFO scheduler.DAGScheduler: Got job 4 (treeAggregate at GaussianMixture.scala:384) with 3 output partitions
20/04/13 22:26:21 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeAggregate at GaussianMixture.scala:384)
20/04/13 22:26:21 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
20/04/13 22:26:21 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 4)
20/04/13 22:26:21 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at treeAggregate at GaussianMixture.scala:384), which has no missing parents
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 2.5 GB)
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 2.5 GB)
20/04/13 22:26:21 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 178.62.197.156:45529 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:26:21 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1163
20/04/13 22:26:21 INFO scheduler.DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at treeAggregate at GaussianMixture.scala:384) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))
20/04/13 22:26:21 INFO cluster.YarnClusterScheduler: Adding task set 4.0 with 9 tasks
20/04/13 22:26:21 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, 64.227.70.177, executor 2, partition 0, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:26:21 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 4.0 (TID 21, 178.62.197.156, executor 1, partition 2, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:26:21 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 4.0 (TID 22, 64.227.70.177, executor 3, partition 3, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:26:21 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 23, 64.227.70.177, executor 2, partition 1, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:26:21 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 4.0 (TID 24, 178.62.197.156, executor 1, partition 5, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:26:21 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 4.0 (TID 25, 64.227.70.177, executor 3, partition 6, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:26:21 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 4.0 (TID 26, 64.227.70.177, executor 2, partition 4, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:26:21 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 4.0 (TID 27, 178.62.197.156, executor 1, partition 7, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:26:21 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 4.0 (TID 28, 64.227.70.177, executor 3, partition 8, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:26:21 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 64.227.70.177:33507 (size: 11.3 KB, free: 2.9 GB)
20/04/13 22:26:21 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 178.62.197.156:35373 (size: 11.3 KB, free: 2.9 GB)
20/04/13 22:26:21 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 64.227.70.177:43849 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:26:21 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 64.227.70.177:33507 (size: 85.0 B, free: 2.9 GB)
20/04/13 22:26:21 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.197.156:35373 (size: 85.0 B, free: 2.9 GB)
20/04/13 22:26:21 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 64.227.70.177:43849 (size: 85.0 B, free: 3.0 GB)
20/04/13 22:26:21 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 64.227.70.177:33507 (size: 2.7 MB, free: 2.9 GB)
20/04/13 22:26:21 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.197.156:35373 (size: 2.7 MB, free: 2.9 GB)
20/04/13 22:26:21 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 64.227.70.177:43849 (size: 2.7 MB, free: 3.0 GB)
20/04/13 22:26:27 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 1.
20/04/13 22:26:27 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 0)
20/04/13 22:26:27 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
20/04/13 22:26:27 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_7 !
20/04/13 22:26:27 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_2 !
20/04/13 22:26:27 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_5 !
20/04/13 22:26:27 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 178.62.197.156, 35373, None)
20/04/13 22:26:27 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor
20/04/13 22:26:27 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 1 (epoch 0)
20/04/13 22:26:27 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_01_000002 on host: 178.62.197.156 (state: COMPLETE, exit status: 143)
20/04/13 22:26:27 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_01_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:27 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 1 for reason Container from a bad node: container_1586815278733_0007_01_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:27 ERROR cluster.YarnClusterScheduler: Lost executor 1 on 178.62.197.156: Container from a bad node: container_1586815278733_0007_01_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:27 WARN scheduler.TaskSetManager: Lost task 7.0 in stage 4.0 (TID 27, 178.62.197.156, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:27 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 4.0 (TID 21, 178.62.197.156, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:27 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 4.0 (TID 24, 178.62.197.156, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:27 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
20/04/13 22:26:27 INFO storage.BlockManagerMaster: Removal of executor 1 requested
20/04/13 22:26:27 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 1
20/04/13 22:26:28 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 2.
20/04/13 22:26:28 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1)
20/04/13 22:26:28 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/13 22:26:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
20/04/13 22:26:28 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_4 !
20/04/13 22:26:28 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_1 !
20/04/13 22:26:28 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_0 !
20/04/13 22:26:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, 64.227.70.177, 33507, None)
20/04/13 22:26:28 INFO yarn.YarnAllocator: Submitted 1 unlocalized container requests.
20/04/13 22:26:28 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor
20/04/13 22:26:28 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 2 (epoch 1)
20/04/13 22:26:28 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_01_000006 on host 64.227.70.177 for executor with ID 4
20/04/13 22:26:28 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/13 22:26:28 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_01_000003 on host: 64.227.70.177 (state: COMPLETE, exit status: 143)
20/04/13 22:26:28 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_01_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:26:28 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 2 for reason Container from a bad node: container_1586815278733_0007_01_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 ERROR cluster.YarnClusterScheduler: Lost executor 2 on 64.227.70.177: Container from a bad node: container_1586815278733_0007_01_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 4.0 (TID 23, 64.227.70.177, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 4.0 (TID 26, 64.227.70.177, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 4.0 (TID 20, 64.227.70.177, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 INFO storage.BlockManagerMaster: Removal of executor 2 requested
20/04/13 22:26:28 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 2
20/04/13 22:26:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
20/04/13 22:26:28 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 3.
20/04/13 22:26:28 INFO scheduler.DAGScheduler: Executor lost: 3 (epoch 2)
20/04/13 22:26:28 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/13 22:26:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
20/04/13 22:26:28 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_8 !
20/04/13 22:26:28 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_3 !
20/04/13 22:26:28 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_6 !
20/04/13 22:26:28 INFO yarn.YarnAllocator: Submitted 1 unlocalized container requests.
20/04/13 22:26:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(3, 64.227.70.177, 43849, None)
20/04/13 22:26:28 INFO storage.BlockManagerMaster: Removed 3 successfully in removeExecutor
20/04/13 22:26:28 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 3 (epoch 2)
20/04/13 22:26:28 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_01_000007 on host 64.227.70.177 for executor with ID 5
20/04/13 22:26:28 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/13 22:26:28 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_01_000005 on host: 64.227.70.177 (state: COMPLETE, exit status: 143)
20/04/13 22:26:28 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_01_000005 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:26:28 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 3 for reason Container from a bad node: container_1586815278733_0007_01_000005 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 ERROR cluster.YarnClusterScheduler: Lost executor 3 on 64.227.70.177: Container from a bad node: container_1586815278733_0007_01_000005 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 4.0 (TID 22, 64.227.70.177, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000005 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 4.0 (TID 25, 64.227.70.177, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000005 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 WARN scheduler.TaskSetManager: Lost task 8.0 in stage 4.0 (TID 28, 64.227.70.177, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000005 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:28 INFO storage.BlockManagerMaster: Removal of executor 3 requested
20/04/13 22:26:28 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 3
20/04/13 22:26:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
20/04/13 22:26:30 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (64.227.70.177:37568) with ID 4
20/04/13 22:26:30 INFO scheduler.TaskSetManager: Starting task 8.1 in stage 4.0 (TID 29, 64.227.70.177, executor 4, partition 8, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:30 INFO scheduler.TaskSetManager: Starting task 6.1 in stage 4.0 (TID 30, 64.227.70.177, executor 4, partition 6, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:30 INFO scheduler.TaskSetManager: Starting task 3.1 in stage 4.0 (TID 31, 64.227.70.177, executor 4, partition 3, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:30 INFO storage.BlockManagerMasterEndpoint: Registering block manager 64.227.70.177:35943 with 3.0 GB RAM, BlockManagerId(4, 64.227.70.177, 35943, None)
20/04/13 22:26:30 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 64.227.70.177:35943 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:26:30 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (64.227.70.177:37574) with ID 5
20/04/13 22:26:30 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 4.0 (TID 32, 64.227.70.177, executor 5, partition 0, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:30 INFO scheduler.TaskSetManager: Starting task 4.1 in stage 4.0 (TID 33, 64.227.70.177, executor 5, partition 4, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:30 INFO scheduler.TaskSetManager: Starting task 1.1 in stage 4.0 (TID 34, 64.227.70.177, executor 5, partition 1, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:31 INFO storage.BlockManagerMasterEndpoint: Registering block manager 64.227.70.177:36855 with 3.0 GB RAM, BlockManagerId(5, 64.227.70.177, 36855, None)
20/04/13 22:26:31 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 64.227.70.177:35943 (size: 32.4 KB, free: 3.0 GB)
20/04/13 22:26:31 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 64.227.70.177:36855 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:26:31 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/13 22:26:31 INFO yarn.YarnAllocator: Submitted 1 unlocalized container requests.
20/04/13 22:26:32 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 64.227.70.177:36855 (size: 32.4 KB, free: 3.0 GB)
20/04/13 22:26:32 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_01_000008 on host 178.62.197.156 for executor with ID 6
20/04/13 22:26:32 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/13 22:26:32 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:26:32 INFO storage.BlockManagerInfo: Added rdd_4_8 in memory on 64.227.70.177:35943 (size: 1296.6 KB, free: 3.0 GB)
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 19
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 24
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 13
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 16
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 25
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 10
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 1
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 12
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 8
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 3
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 6
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 23
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 15
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 4
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 7
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 22
20/04/13 22:26:33 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 178.62.197.156:45529 in memory (size: 33.1 KB, free: 3.0 GB)
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 21
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 14
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 2
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 18
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 20
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 17
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 9
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 11
20/04/13 22:26:33 INFO spark.ContextCleaner: Cleaned accumulator 5
20/04/13 22:26:33 INFO storage.BlockManagerInfo: Added rdd_4_6 in memory on 64.227.70.177:35943 (size: 33.8 MB, free: 3.0 GB)
20/04/13 22:26:33 INFO storage.BlockManagerInfo: Added rdd_4_3 in memory on 64.227.70.177:35943 (size: 32.5 MB, free: 3.0 GB)
20/04/13 22:26:33 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.197.156:49748) with ID 6
20/04/13 22:26:33 INFO scheduler.TaskSetManager: Starting task 5.1 in stage 4.0 (TID 35, 178.62.197.156, executor 6, partition 5, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:33 INFO scheduler.TaskSetManager: Starting task 2.1 in stage 4.0 (TID 36, 178.62.197.156, executor 6, partition 2, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:33 INFO scheduler.TaskSetManager: Starting task 7.1 in stage 4.0 (TID 37, 178.62.197.156, executor 6, partition 7, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:34 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.197.156:41639 with 3.0 GB RAM, BlockManagerId(6, 178.62.197.156, 41639, None)
20/04/13 22:26:34 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 178.62.197.156:41639 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:26:34 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 64.227.70.177:35943 (size: 85.0 B, free: 3.0 GB)
20/04/13 22:26:34 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 64.227.70.177:35943 (size: 2.7 MB, free: 3.0 GB)
20/04/13 22:26:34 INFO storage.BlockManagerInfo: Added rdd_4_0 in memory on 64.227.70.177:36855 (size: 32.6 MB, free: 3.0 GB)
20/04/13 22:26:34 INFO storage.BlockManagerInfo: Added rdd_4_1 in memory on 64.227.70.177:36855 (size: 32.6 MB, free: 3.0 GB)
20/04/13 22:26:34 INFO storage.BlockManagerInfo: Added rdd_4_4 in memory on 64.227.70.177:36855 (size: 33.1 MB, free: 2.9 GB)
20/04/13 22:26:34 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.197.156:41639 (size: 32.4 KB, free: 3.0 GB)
20/04/13 22:26:35 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 64.227.70.177:36855 (size: 85.0 B, free: 2.9 GB)
20/04/13 22:26:35 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 64.227.70.177:36855 (size: 2.7 MB, free: 2.9 GB)
20/04/13 22:26:36 INFO storage.BlockManagerInfo: Added rdd_4_2 in memory on 178.62.197.156:41639 (size: 32.6 MB, free: 3.0 GB)
20/04/13 22:26:37 INFO storage.BlockManagerInfo: Added rdd_4_7 in memory on 178.62.197.156:41639 (size: 33.4 MB, free: 3.0 GB)
20/04/13 22:26:37 INFO storage.BlockManagerInfo: Added rdd_4_5 in memory on 178.62.197.156:41639 (size: 33.8 MB, free: 2.9 GB)
20/04/13 22:26:37 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.197.156:41639 (size: 85.0 B, free: 2.9 GB)
20/04/13 22:26:37 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.197.156:41639 (size: 2.7 MB, free: 2.9 GB)
20/04/13 22:26:41 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 4.
20/04/13 22:26:41 INFO scheduler.DAGScheduler: Executor lost: 4 (epoch 3)
20/04/13 22:26:41 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
20/04/13 22:26:41 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_8 !
20/04/13 22:26:41 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_3 !
20/04/13 22:26:41 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_6 !
20/04/13 22:26:41 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(4, 64.227.70.177, 35943, None)
20/04/13 22:26:41 INFO storage.BlockManagerMaster: Removed 4 successfully in removeExecutor
20/04/13 22:26:41 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 4 (epoch 3)
20/04/13 22:26:41 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_01_000006 on host: 64.227.70.177 (state: COMPLETE, exit status: 143)
20/04/13 22:26:41 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_01_000006 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:41 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 4 for reason Container from a bad node: container_1586815278733_0007_01_000006 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:41 ERROR cluster.YarnClusterScheduler: Lost executor 4 on 64.227.70.177: Container from a bad node: container_1586815278733_0007_01_000006 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:41 WARN scheduler.TaskSetManager: Lost task 8.1 in stage 4.0 (TID 29, 64.227.70.177, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000006 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:41 WARN scheduler.TaskSetManager: Lost task 3.1 in stage 4.0 (TID 31, 64.227.70.177, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000006 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:41 WARN scheduler.TaskSetManager: Lost task 6.1 in stage 4.0 (TID 30, 64.227.70.177, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000006 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:41 INFO storage.BlockManagerMaster: Removal of executor 4 requested
20/04/13 22:26:41 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 4
20/04/13 22:26:41 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
20/04/13 22:26:43 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 5.
20/04/13 22:26:43 INFO scheduler.DAGScheduler: Executor lost: 5 (epoch 4)
20/04/13 22:26:43 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 5 from BlockManagerMaster.
20/04/13 22:26:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_4 !
20/04/13 22:26:43 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/13 22:26:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_1 !
20/04/13 22:26:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_0 !
20/04/13 22:26:43 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(5, 64.227.70.177, 36855, None)
20/04/13 22:26:43 INFO yarn.YarnAllocator: Submitted 1 unlocalized container requests.
20/04/13 22:26:43 INFO storage.BlockManagerMaster: Removed 5 successfully in removeExecutor
20/04/13 22:26:43 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 5 (epoch 4)
20/04/13 22:26:43 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_01_000009 on host 64.227.70.177 for executor with ID 7
20/04/13 22:26:43 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/13 22:26:43 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:26:43 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_01_000007 on host: 64.227.70.177 (state: COMPLETE, exit status: 143)
20/04/13 22:26:43 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_01_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:43 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 5 for reason Container from a bad node: container_1586815278733_0007_01_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:43 ERROR cluster.YarnClusterScheduler: Lost executor 5 on 64.227.70.177: Container from a bad node: container_1586815278733_0007_01_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:43 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 4.0 (TID 32, 64.227.70.177, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:43 WARN scheduler.TaskSetManager: Lost task 1.1 in stage 4.0 (TID 34, 64.227.70.177, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:43 WARN scheduler.TaskSetManager: Lost task 4.1 in stage 4.0 (TID 33, 64.227.70.177, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:43 INFO storage.BlockManagerMaster: Removal of executor 5 requested
20/04/13 22:26:43 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 5
20/04/13 22:26:43 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 5 from BlockManagerMaster.
20/04/13 22:26:45 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (64.227.70.177:37596) with ID 7
20/04/13 22:26:45 INFO scheduler.TaskSetManager: Starting task 4.2 in stage 4.0 (TID 38, 64.227.70.177, executor 7, partition 4, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:45 INFO scheduler.TaskSetManager: Starting task 1.2 in stage 4.0 (TID 39, 64.227.70.177, executor 7, partition 1, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:45 INFO scheduler.TaskSetManager: Starting task 0.2 in stage 4.0 (TID 40, 64.227.70.177, executor 7, partition 0, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:45 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 6.
20/04/13 22:26:45 INFO scheduler.DAGScheduler: Executor lost: 6 (epoch 5)
20/04/13 22:26:45 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 6 from BlockManagerMaster.
20/04/13 22:26:45 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_7 !
20/04/13 22:26:45 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/13 22:26:45 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_2 !
20/04/13 22:26:45 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_5 !
20/04/13 22:26:45 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(6, 178.62.197.156, 41639, None)
20/04/13 22:26:45 INFO yarn.YarnAllocator: Submitted 1 unlocalized container requests.
20/04/13 22:26:45 INFO storage.BlockManagerMaster: Removed 6 successfully in removeExecutor
20/04/13 22:26:45 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 6 (epoch 5)
20/04/13 22:26:45 INFO storage.BlockManagerMasterEndpoint: Registering block manager 64.227.70.177:37059 with 3.0 GB RAM, BlockManagerId(7, 64.227.70.177, 37059, None)
20/04/13 22:26:45 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 64.227.70.177:37059 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:26:45 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_01_000010 on host 178.62.197.156 for executor with ID 8
20/04/13 22:26:45 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/13 22:26:45 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_01_000008 on host: 178.62.197.156 (state: COMPLETE, exit status: 143)
20/04/13 22:26:45 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_01_000008 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:45 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:26:45 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 6 for reason Container from a bad node: container_1586815278733_0007_01_000008 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:45 ERROR cluster.YarnClusterScheduler: Lost executor 6 on 178.62.197.156: Container from a bad node: container_1586815278733_0007_01_000008 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:45 WARN scheduler.TaskSetManager: Lost task 5.1 in stage 4.0 (TID 35, 178.62.197.156, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000008 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:45 WARN scheduler.TaskSetManager: Lost task 7.1 in stage 4.0 (TID 37, 178.62.197.156, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000008 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:45 WARN scheduler.TaskSetManager: Lost task 2.1 in stage 4.0 (TID 36, 178.62.197.156, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_01_000008 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:26:45 INFO storage.BlockManagerMaster: Removal of executor 6 requested
20/04/13 22:26:45 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 6
20/04/13 22:26:45 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 6 from BlockManagerMaster.
20/04/13 22:26:45 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 64.227.70.177:37059 (size: 32.4 KB, free: 3.0 GB)
20/04/13 22:26:47 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.197.156:49772) with ID 8
20/04/13 22:26:47 INFO scheduler.TaskSetManager: Starting task 2.2 in stage 4.0 (TID 41, 178.62.197.156, executor 8, partition 2, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:47 INFO scheduler.TaskSetManager: Starting task 7.2 in stage 4.0 (TID 42, 178.62.197.156, executor 8, partition 7, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:47 INFO scheduler.TaskSetManager: Starting task 5.2 in stage 4.0 (TID 43, 178.62.197.156, executor 8, partition 5, NODE_LOCAL, 8337 bytes)
20/04/13 22:26:47 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.197.156:44543 with 3.0 GB RAM, BlockManagerId(8, 178.62.197.156, 44543, None)
20/04/13 22:26:47 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 178.62.197.156:44543 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:26:47 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.197.156:44543 (size: 32.4 KB, free: 3.0 GB)
20/04/13 22:26:47 INFO storage.BlockManagerInfo: Added rdd_4_1 in memory on 64.227.70.177:37059 (size: 32.6 MB, free: 3.0 GB)
20/04/13 22:26:48 INFO storage.BlockManagerInfo: Added rdd_4_4 in memory on 64.227.70.177:37059 (size: 33.1 MB, free: 3.0 GB)
20/04/13 22:26:48 INFO storage.BlockManagerInfo: Added rdd_4_0 in memory on 64.227.70.177:37059 (size: 32.6 MB, free: 2.9 GB)
20/04/13 22:26:48 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (6) reached)
20/04/13 22:26:48 INFO spark.SparkContext: Invoking stop() from shutdown hook
20/04/13 22:26:48 INFO server.AbstractConnector: Stopped Spark@87b98ec{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
20/04/13 22:26:48 INFO ui.SparkUI: Stopped Spark web UI at http://178.62.197.156:35903
20/04/13 22:26:48 INFO scheduler.DAGScheduler: Job 4 failed: treeAggregate at GaussianMixture.scala:384, took 27.113122 s
20/04/13 22:26:48 INFO scheduler.DAGScheduler: ShuffleMapStage 4 (treeAggregate at GaussianMixture.scala:384) failed in 27.099 s due to Stage cancelled because SparkContext was shut down
20/04/13 22:26:48 ERROR util.Instrumentation: org.apache.spark.SparkException: Job 4 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:933)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:931)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:931)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2130)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2043)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1143)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.fold(RDD.scala:1137)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1206)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1182)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1.apply(GaussianMixture.scala:384)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1.apply(GaussianMixture.scala:340)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.clustering.GaussianMixture.fit(GaussianMixture.scala:340)
	at org.apache.spark.ml.clustering.GaussianMixture.fit(GaussianMixture.scala:291)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)

20/04/13 22:26:48 INFO yarn.YarnAllocator: Driver requested a total number of 0 executor(s).
20/04/13 22:26:48 INFO cluster.YarnClusterSchedulerBackend: Shutting down all executors
20/04/13 22:26:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/04/13 22:26:48 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
20/04/13 22:26:48 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/04/13 22:26:48 INFO memory.MemoryStore: MemoryStore cleared
20/04/13 22:26:48 INFO storage.BlockManager: BlockManager stopped
20/04/13 22:26:48 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
20/04/13 22:26:48 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/04/13 22:26:48 INFO spark.SparkContext: Successfully stopped SparkContext
20/04/13 22:26:48 INFO util.ShutdownHookManager: Shutdown hook called
20/04/13 22:26:48 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/spark-fb286c1a-d135-4756-a25e-61d5a5ca3f7c/pyspark-7dc7dea0-4e19-4f02-8e93-80a8eb98dfd8
20/04/13 22:26:48 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/spark-fb286c1a-d135-4756-a25e-61d5a5ca3f7c
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1586815278733_0007_02_000002 on 178.62.197.156_36923
===========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:20257
Log Contents:
20/04/13 22:26:54 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22915@178.62.197.156
20/04/13 22:26:54 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:54 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:54 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:54 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:54 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:54 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:54 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:54 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 47 ms (0 ms spent in bootstraps)
20/04/13 22:26:55 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:55 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:55 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:55 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:55 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:55 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 3 ms (0 ms spent in bootstraps)
20/04/13 22:26:55 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-199ac5f8-9771-4486-9f7d-cea59c121e6f
20/04/13 22:26:55 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:55 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@64.227.70.177:45487
20/04/13 22:26:55 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:26:55 INFO executor.Executor: Starting executor ID 1 on host 178.62.197.156
20/04/13 22:26:55 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42931.
20/04/13 22:26:55 INFO netty.NettyBlockTransferService: Server created on 178.62.197.156:42931
20/04/13 22:26:55 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:55 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(1, 178.62.197.156, 42931, None)
20/04/13 22:26:55 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(1, 178.62.197.156, 42931, None)
20/04/13 22:26:55 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(1, 178.62.197.156, 42931, None)
20/04/13 22:26:58 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 0
20/04/13 22:26:58 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
20/04/13 22:26:58 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
20/04/13 22:26:58 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:38753 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:26:58 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.1 KB, free 3.0 GB)
20/04/13 22:26:58 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 90 ms
20/04/13 22:26:58 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 127.0 KB, free 3.0 GB)
20/04/13 22:26:59 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2496 bytes result sent to driver
20/04/13 22:27:04 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3
20/04/13 22:27:04 INFO executor.Executor: Running task 1.0 in stage 2.0 (TID 3)
20/04/13 22:27:04 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 6
20/04/13 22:27:04 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 9
20/04/13 22:27:04 INFO executor.Executor: Running task 4.0 in stage 2.0 (TID 6)
20/04/13 22:27:04 INFO executor.Executor: Running task 7.0 in stage 2.0 (TID 9)
20/04/13 22:27:04 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/13 22:27:04 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:27:04 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 10 ms
20/04/13 22:27:04 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 21.3 KB, free 3.0 GB)
20/04/13 22:27:04 INFO codegen.CodeGenerator: Code generated in 287.025704 ms
20/04/13 22:27:05 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00005-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4950456, partition values: [empty row]
20/04/13 22:27:05 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00003-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4855590, partition values: [empty row]
20/04/13 22:27:05 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00002-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4735846, partition values: [empty row]
20/04/13 22:27:05 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:27:05 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/13 22:27:05 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 10 ms
20/04/13 22:27:05 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:27:05 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:05 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:05 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:05 INFO codegen.CodeGenerator: Code generated in 23.137646 ms
20/04/13 22:27:05 INFO codegen.CodeGenerator: Code generated in 35.299045 ms
20/04/13 22:27:05 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11838 records.
20/04/13 22:27:05 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 6080 records.
20/04/13 22:27:05 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 9550 records.
20/04/13 22:27:05 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:05 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:05 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:05 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:05 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:05 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:05 INFO hadoop.InternalParquetRecordReader: block read in memory in 84 ms. row count = 11838
20/04/13 22:27:05 INFO hadoop.InternalParquetRecordReader: block read in memory in 87 ms. row count = 9550
20/04/13 22:27:05 INFO hadoop.InternalParquetRecordReader: block read in memory in 54 ms. row count = 6080
20/04/13 22:27:06 INFO memory.MemoryStore: Block rdd_4_7 stored as values in memory (estimated size 33.4 MB, free 3.0 GB)
20/04/13 22:27:06 INFO codegen.CodeGenerator: Code generated in 5.928079 ms
20/04/13 22:27:06 INFO codegen.CodeGenerator: Code generated in 26.564433 ms
20/04/13 22:27:06 INFO memory.MemoryStore: Block rdd_4_4 stored as values in memory (estimated size 33.1 MB, free 3.0 GB)
20/04/13 22:27:06 INFO memory.MemoryStore: Block rdd_4_1 stored as values in memory (estimated size 32.6 MB, free 2.9 GB)
20/04/13 22:27:08 INFO codegen.CodeGenerator: Code generated in 23.9504 ms
20/04/13 22:27:08 INFO executor.Executor: Finished task 7.0 in stage 2.0 (TID 9). 1427 bytes result sent to driver
20/04/13 22:27:08 INFO executor.Executor: Finished task 4.0 in stage 2.0 (TID 6). 1427 bytes result sent to driver
20/04/13 22:27:08 INFO executor.Executor: Finished task 1.0 in stage 2.0 (TID 3). 1427 bytes result sent to driver
20/04/13 22:27:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 13
20/04/13 22:27:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 16
20/04/13 22:27:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 19
20/04/13 22:27:09 INFO executor.Executor: Running task 1.0 in stage 3.0 (TID 13)
20/04/13 22:27:09 INFO executor.Executor: Running task 4.0 in stage 3.0 (TID 16)
20/04/13 22:27:09 INFO executor.Executor: Running task 7.0 in stage 3.0 (TID 19)
20/04/13 22:27:09 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/13 22:27:09 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.5 KB, free 2.9 GB)
20/04/13 22:27:09 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 11 ms
20/04/13 22:27:09 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 38.4 KB, free 2.9 GB)
20/04/13 22:27:09 INFO storage.BlockManager: Found block rdd_4_4 locally
20/04/13 22:27:09 INFO storage.BlockManager: Found block rdd_4_1 locally
20/04/13 22:27:09 INFO storage.BlockManager: Found block rdd_4_7 locally
20/04/13 22:27:09 INFO executor.Executor: Finished task 1.0 in stage 3.0 (TID 13). 12932 bytes result sent to driver
20/04/13 22:27:09 INFO executor.Executor: Finished task 4.0 in stage 3.0 (TID 16). 11696 bytes result sent to driver
20/04/13 22:27:09 INFO executor.Executor: Finished task 7.0 in stage 3.0 (TID 19). 1406 bytes result sent to driver
20/04/13 22:27:11 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 21
20/04/13 22:27:11 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 24
20/04/13 22:27:11 INFO executor.Executor: Running task 1.0 in stage 4.0 (TID 21)
20/04/13 22:27:11 INFO executor.Executor: Running task 4.0 in stage 4.0 (TID 24)
20/04/13 22:27:11 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 27
20/04/13 22:27:11 INFO executor.Executor: Running task 7.0 in stage 4.0 (TID 27)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 2.9 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 9 ms
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 2.9 GB)
20/04/13 22:27:11 INFO storage.BlockManager: Found block rdd_4_7 locally
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:27:11 INFO storage.BlockManager: Found block rdd_4_4 locally
20/04/13 22:27:11 INFO storage.BlockManager: Found block rdd_4_1 locally
20/04/13 22:27:11 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:39847 after 8 ms (0 ms spent in bootstraps)
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 2.9 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 59 ms
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 2.9 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:27:11 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:44225 after 1 ms (0 ms spent in bootstraps)
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 2.9 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 140 ms
20/04/13 22:27:12 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:27:18 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:27:18 ERROR executor.Executor: Exception in task 7.0 in stage 4.0 (TID 27)
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:27:18 INFO executor.Executor: Not reporting error to driver during JVM shutdown.
20/04/13 22:27:18 ERROR util.SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 27,5,main]
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:27:18 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:27:18 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 22915"...
End of LogType:stdout



Container: container_1586815278733_0007_01_000002 on 178.62.197.156_36923
===========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:17173
Log Contents:
20/04/13 22:26:04 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22540@178.62.197.156
20/04/13 22:26:04 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:04 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:04 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:05 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:05 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:05 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:05 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:05 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:05 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 46 ms (0 ms spent in bootstraps)
20/04/13 22:26:05 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:05 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:05 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:05 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:05 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:05 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 4 ms (0 ms spent in bootstraps)
20/04/13 22:26:05 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-0fa180f2-29a1-45f6-8249-69b4daa56efe
20/04/13 22:26:05 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:06 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.197.156:39167
20/04/13 22:26:06 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:26:06 INFO executor.Executor: Starting executor ID 1 on host 178.62.197.156
20/04/13 22:26:06 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35373.
20/04/13 22:26:06 INFO netty.NettyBlockTransferService: Server created on 178.62.197.156:35373
20/04/13 22:26:06 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:06 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(1, 178.62.197.156, 35373, None)
20/04/13 22:26:06 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(1, 178.62.197.156, 35373, None)
20/04/13 22:26:06 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(1, 178.62.197.156, 35373, None)
20/04/13 22:26:08 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 0
20/04/13 22:26:08 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
20/04/13 22:26:08 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
20/04/13 22:26:08 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:45529 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:26:09 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.1 KB, free 3.0 GB)
20/04/13 22:26:09 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 210 ms
20/04/13 22:26:09 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 127.0 KB, free 3.0 GB)
20/04/13 22:26:10 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2496 bytes result sent to driver
20/04/13 22:26:15 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 4
20/04/13 22:26:15 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 7
20/04/13 22:26:15 INFO executor.Executor: Running task 2.0 in stage 2.0 (TID 4)
20/04/13 22:26:15 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 9
20/04/13 22:26:15 INFO executor.Executor: Running task 5.0 in stage 2.0 (TID 7)
20/04/13 22:26:15 INFO executor.Executor: Running task 7.0 in stage 2.0 (TID 9)
20/04/13 22:26:15 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/13 22:26:15 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:26:15 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 8 ms
20/04/13 22:26:15 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 21.3 KB, free 3.0 GB)
20/04/13 22:26:15 INFO codegen.CodeGenerator: Code generated in 217.932463 ms
20/04/13 22:26:15 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00000-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4791031, partition values: [empty row]
20/04/13 22:26:15 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00007-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4944913, partition values: [empty row]
20/04/13 22:26:15 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00002-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4735846, partition values: [empty row]
20/04/13 22:26:15 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:26:15 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/13 22:26:15 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 11 ms
20/04/13 22:26:15 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:26:15 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:15 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:15 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:16 INFO codegen.CodeGenerator: Code generated in 25.834459 ms
20/04/13 22:26:16 INFO codegen.CodeGenerator: Code generated in 21.799225 ms
20/04/13 22:26:16 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5980 records.
20/04/13 22:26:16 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11674 records.
20/04/13 22:26:16 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 6080 records.
20/04/13 22:26:16 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:16 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:16 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:16 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:16 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:16 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:16 INFO hadoop.InternalParquetRecordReader: block read in memory in 44 ms. row count = 6080
20/04/13 22:26:16 INFO hadoop.InternalParquetRecordReader: block read in memory in 46 ms. row count = 5980
20/04/13 22:26:16 INFO hadoop.InternalParquetRecordReader: block read in memory in 47 ms. row count = 11674
20/04/13 22:26:17 INFO memory.MemoryStore: Block rdd_4_7 stored as values in memory (estimated size 33.4 MB, free 3.0 GB)
20/04/13 22:26:17 INFO codegen.CodeGenerator: Code generated in 6.616949 ms
20/04/13 22:26:17 INFO codegen.CodeGenerator: Code generated in 34.021994 ms
20/04/13 22:26:17 INFO memory.MemoryStore: Block rdd_4_2 stored as values in memory (estimated size 32.6 MB, free 3.0 GB)
20/04/13 22:26:17 INFO memory.MemoryStore: Block rdd_4_5 stored as values in memory (estimated size 33.8 MB, free 2.9 GB)
20/04/13 22:26:18 INFO codegen.CodeGenerator: Code generated in 14.878991 ms
20/04/13 22:26:18 INFO executor.Executor: Finished task 7.0 in stage 2.0 (TID 9). 1427 bytes result sent to driver
20/04/13 22:26:18 INFO executor.Executor: Finished task 5.0 in stage 2.0 (TID 7). 1427 bytes result sent to driver
20/04/13 22:26:18 INFO executor.Executor: Finished task 2.0 in stage 2.0 (TID 4). 1470 bytes result sent to driver
20/04/13 22:26:18 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 13
20/04/13 22:26:18 INFO executor.Executor: Running task 2.0 in stage 3.0 (TID 13)
20/04/13 22:26:18 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 16
20/04/13 22:26:18 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 19
20/04/13 22:26:18 INFO executor.Executor: Running task 5.0 in stage 3.0 (TID 16)
20/04/13 22:26:18 INFO executor.Executor: Running task 7.0 in stage 3.0 (TID 19)
20/04/13 22:26:18 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/13 22:26:18 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.5 KB, free 2.9 GB)
20/04/13 22:26:18 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 12 ms
20/04/13 22:26:18 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 38.4 KB, free 2.9 GB)
20/04/13 22:26:19 INFO storage.BlockManager: Found block rdd_4_5 locally
20/04/13 22:26:19 INFO storage.BlockManager: Found block rdd_4_2 locally
20/04/13 22:26:19 INFO storage.BlockManager: Found block rdd_4_7 locally
20/04/13 22:26:19 INFO executor.Executor: Finished task 5.0 in stage 3.0 (TID 16). 1363 bytes result sent to driver
20/04/13 22:26:19 INFO executor.Executor: Finished task 7.0 in stage 3.0 (TID 19). 1363 bytes result sent to driver
20/04/13 22:26:19 INFO executor.Executor: Finished task 2.0 in stage 3.0 (TID 13). 28975 bytes result sent to driver
20/04/13 22:26:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 21
20/04/13 22:26:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 24
20/04/13 22:26:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 27
20/04/13 22:26:21 INFO executor.Executor: Running task 5.0 in stage 4.0 (TID 24)
20/04/13 22:26:21 INFO executor.Executor: Running task 2.0 in stage 4.0 (TID 21)
20/04/13 22:26:21 INFO executor.Executor: Running task 7.0 in stage 4.0 (TID 27)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 2.9 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 17 ms
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 2.9 GB)
20/04/13 22:26:21 INFO storage.BlockManager: Found block rdd_4_2 locally
20/04/13 22:26:21 INFO storage.BlockManager: Found block rdd_4_5 locally
20/04/13 22:26:21 INFO storage.BlockManager: Found block rdd_4_7 locally
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 2.9 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 9 ms
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 2.9 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 2.9 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 19 ms
20/04/13 22:26:22 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:26:26 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:26:26 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:26:26 ERROR executor.Executor: Exception in task 2.0 in stage 4.0 (TID 21)
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:26:26 INFO util.ShutdownHookManager: Shutdown hook called
20/04/13 22:26:26 INFO executor.Executor: Not reporting error to driver during JVM shutdown.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 22540"...
End of LogType:stdout



Container: container_1586815278733_0007_01_000009 on 64.227.70.177_41217
==========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:9784
Log Contents:
20/04/13 22:26:44 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22474@64.227.70.177
20/04/13 22:26:44 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:44 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:44 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:44 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:44 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:44 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:44 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:44 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:44 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 48 ms (0 ms spent in bootstraps)
20/04/13 22:26:44 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:44 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:44 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:44 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:44 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:44 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 4 ms (0 ms spent in bootstraps)
20/04/13 22:26:44 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-d9a57931-6e76-4b1c-9432-4a18a8391ccc
20/04/13 22:26:44 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:45 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.197.156:39167
20/04/13 22:26:45 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:26:45 INFO executor.Executor: Starting executor ID 7 on host 64.227.70.177
20/04/13 22:26:45 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37059.
20/04/13 22:26:45 INFO netty.NettyBlockTransferService: Server created on 64.227.70.177:37059
20/04/13 22:26:45 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:45 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(7, 64.227.70.177, 37059, None)
20/04/13 22:26:45 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(7, 64.227.70.177, 37059, None)
20/04/13 22:26:45 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(7, 64.227.70.177, 37059, None)
20/04/13 22:26:45 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 38
20/04/13 22:26:45 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 39
20/04/13 22:26:45 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 40
20/04/13 22:26:45 INFO executor.Executor: Running task 4.2 in stage 4.0 (TID 38)
20/04/13 22:26:45 INFO executor.Executor: Running task 0.2 in stage 4.0 (TID 40)
20/04/13 22:26:45 INFO executor.Executor: Running task 1.2 in stage 4.0 (TID 39)
20/04/13 22:26:45 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:26:45 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:45529 after 1 ms (0 ms spent in bootstraps)
20/04/13 22:26:45 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 3.0 GB)
20/04/13 22:26:45 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 68 ms
20/04/13 22:26:45 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 3.0 GB)
20/04/13 22:26:45 INFO codegen.CodeGenerator: Code generated in 233.979597 ms
20/04/13 22:26:45 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00005-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4950456, partition values: [empty row]
20/04/13 22:26:45 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00006-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4956444, partition values: [empty row]
20/04/13 22:26:45 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00003-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4855590, partition values: [empty row]
20/04/13 22:26:45 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:26:45 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/13 22:26:45 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 9 ms
20/04/13 22:26:45 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:26:46 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:46 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:46 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:46 INFO codegen.CodeGenerator: Code generated in 15.274177 ms
20/04/13 22:26:46 INFO codegen.CodeGenerator: Code generated in 17.498412 ms
20/04/13 22:26:46 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 9550 records.
20/04/13 22:26:46 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11838 records.
20/04/13 22:26:46 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11734 records.
20/04/13 22:26:47 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:47 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:47 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:47 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:47 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:47 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:47 INFO hadoop.InternalParquetRecordReader: block read in memory in 31 ms. row count = 11838
20/04/13 22:26:47 INFO hadoop.InternalParquetRecordReader: block read in memory in 32 ms. row count = 11734
20/04/13 22:26:47 INFO hadoop.InternalParquetRecordReader: block read in memory in 32 ms. row count = 9550
20/04/13 22:26:47 INFO memory.MemoryStore: Block rdd_4_1 stored as values in memory (estimated size 32.6 MB, free 3.0 GB)
20/04/13 22:26:47 INFO codegen.CodeGenerator: Code generated in 5.131044 ms
20/04/13 22:26:47 INFO codegen.CodeGenerator: Code generated in 20.229583 ms
20/04/13 22:26:48 INFO memory.MemoryStore: Block rdd_4_4 stored as values in memory (estimated size 33.1 MB, free 3.0 GB)
20/04/13 22:26:48 INFO memory.MemoryStore: Block rdd_4_0 stored as values in memory (estimated size 32.6 MB, free 2.9 GB)
20/04/13 22:26:48 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/04/13 22:26:48 INFO memory.MemoryStore: MemoryStore cleared
20/04/13 22:26:48 INFO storage.BlockManager: BlockManager stopped
20/04/13 22:26:48 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1586815278733_0007_01_000007 on 64.227.70.177_41217
==========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:16263
Log Contents:
20/04/13 22:26:29 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22326@64.227.70.177
20/04/13 22:26:29 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:29 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:29 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:30 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:30 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:30 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:30 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:30 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:30 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 65 ms (0 ms spent in bootstraps)
20/04/13 22:26:30 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:30 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:30 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:30 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:30 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:30 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 9 ms (0 ms spent in bootstraps)
20/04/13 22:26:30 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-ed446d30-5439-4498-a919-7b361727842f
20/04/13 22:26:30 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:30 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.197.156:39167
20/04/13 22:26:30 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:26:30 INFO executor.Executor: Starting executor ID 5 on host 64.227.70.177
20/04/13 22:26:31 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36855.
20/04/13 22:26:31 INFO netty.NettyBlockTransferService: Server created on 64.227.70.177:36855
20/04/13 22:26:31 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:31 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(5, 64.227.70.177, 36855, None)
20/04/13 22:26:31 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(5, 64.227.70.177, 36855, None)
20/04/13 22:26:31 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(5, 64.227.70.177, 36855, None)
20/04/13 22:26:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 32
20/04/13 22:26:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 33
20/04/13 22:26:31 INFO executor.Executor: Running task 0.1 in stage 4.0 (TID 32)
20/04/13 22:26:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 34
20/04/13 22:26:31 INFO executor.Executor: Running task 4.1 in stage 4.0 (TID 33)
20/04/13 22:26:31 INFO executor.Executor: Running task 1.1 in stage 4.0 (TID 34)
20/04/13 22:26:31 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:26:31 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:35943 after 6 ms (0 ms spent in bootstraps)
20/04/13 22:26:31 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 3.0 GB)
20/04/13 22:26:31 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 120 ms
20/04/13 22:26:31 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 3.0 GB)
20/04/13 22:26:32 INFO codegen.CodeGenerator: Code generated in 284.764661 ms
20/04/13 22:26:32 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00003-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4855590, partition values: [empty row]
20/04/13 22:26:32 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00005-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4950456, partition values: [empty row]
20/04/13 22:26:32 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00006-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4956444, partition values: [empty row]
20/04/13 22:26:32 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:26:32 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/13 22:26:32 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 11 ms
20/04/13 22:26:32 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:26:33 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:33 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:33 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:33 INFO codegen.CodeGenerator: Code generated in 25.752613 ms
20/04/13 22:26:33 INFO codegen.CodeGenerator: Code generated in 22.279627 ms
20/04/13 22:26:33 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11734 records.
20/04/13 22:26:33 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11838 records.
20/04/13 22:26:33 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 9550 records.
20/04/13 22:26:33 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:33 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:33 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:33 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:33 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:33 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:33 INFO hadoop.InternalParquetRecordReader: block read in memory in 37 ms. row count = 11734
20/04/13 22:26:33 INFO hadoop.InternalParquetRecordReader: block read in memory in 37 ms. row count = 9550
20/04/13 22:26:33 INFO hadoop.InternalParquetRecordReader: block read in memory in 40 ms. row count = 11838
20/04/13 22:26:34 INFO memory.MemoryStore: Block rdd_4_0 stored as values in memory (estimated size 32.6 MB, free 3.0 GB)
20/04/13 22:26:34 INFO codegen.CodeGenerator: Code generated in 15.447501 ms
20/04/13 22:26:34 INFO memory.MemoryStore: Block rdd_4_1 stored as values in memory (estimated size 32.6 MB, free 3.0 GB)
20/04/13 22:26:34 INFO codegen.CodeGenerator: Code generated in 55.27853 ms
20/04/13 22:26:34 INFO memory.MemoryStore: Block rdd_4_4 stored as values in memory (estimated size 33.1 MB, free 2.9 GB)
20/04/13 22:26:35 INFO codegen.CodeGenerator: Code generated in 18.363411 ms
20/04/13 22:26:35 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:26:35 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 2.9 GB)
20/04/13 22:26:35 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 17 ms
20/04/13 22:26:35 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 2.9 GB)
20/04/13 22:26:35 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:26:35 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 2.9 GB)
20/04/13 22:26:35 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 22 ms
20/04/13 22:26:36 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:26:42 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:26:42 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:26:42 INFO util.ShutdownHookManager: Shutdown hook called
20/04/13 22:26:42 ERROR executor.Executor: Exception in task 1.1 in stage 4.0 (TID 34)
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:26:42 INFO executor.Executor: Not reporting error to driver during JVM shutdown.
20/04/13 22:26:42 ERROR util.SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 34,5,main]
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 22326"...
End of LogType:stdout



Container: container_1586815278733_0007_01_000005 on 64.227.70.177_41217
==========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:19392
Log Contents:
20/04/13 22:26:06 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22125@64.227.70.177
20/04/13 22:26:06 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:06 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:06 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:07 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:07 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:07 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:07 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:07 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:07 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 43 ms (0 ms spent in bootstraps)
20/04/13 22:26:07 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:07 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:07 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:07 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:07 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:07 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:26:07 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-a4645fc7-ec1f-4afd-8b82-043b1760003c
20/04/13 22:26:07 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:07 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.197.156:39167
20/04/13 22:26:07 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:26:07 INFO executor.Executor: Starting executor ID 3 on host 64.227.70.177
20/04/13 22:26:07 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43849.
20/04/13 22:26:07 INFO netty.NettyBlockTransferService: Server created on 64.227.70.177:43849
20/04/13 22:26:07 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:07 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(3, 64.227.70.177, 43849, None)
20/04/13 22:26:07 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(3, 64.227.70.177, 43849, None)
20/04/13 22:26:07 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(3, 64.227.70.177, 43849, None)
20/04/13 22:26:15 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 5
20/04/13 22:26:15 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 8
20/04/13 22:26:15 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 10
20/04/13 22:26:15 INFO executor.Executor: Running task 6.0 in stage 2.0 (TID 8)
20/04/13 22:26:15 INFO executor.Executor: Running task 3.0 in stage 2.0 (TID 5)
20/04/13 22:26:15 INFO executor.Executor: Running task 8.0 in stage 2.0 (TID 10)
20/04/13 22:26:15 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/13 22:26:15 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:33507 after 24 ms (0 ms spent in bootstraps)
20/04/13 22:26:15 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:26:15 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 165 ms
20/04/13 22:26:15 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 21.3 KB, free 3.0 GB)
20/04/13 22:26:16 INFO codegen.CodeGenerator: Code generated in 184.091396 ms
20/04/13 22:26:16 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00001-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4785170, partition values: [empty row]
20/04/13 22:26:16 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00004-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4935172, partition values: [empty row]
20/04/13 22:26:16 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00008-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-213844, partition values: [empty row]
20/04/13 22:26:16 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:26:16 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/13 22:26:16 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 9 ms
20/04/13 22:26:16 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:26:17 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:17 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:17 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:17 INFO codegen.CodeGenerator: Code generated in 14.830603 ms
20/04/13 22:26:17 INFO codegen.CodeGenerator: Code generated in 11.334106 ms
20/04/13 22:26:17 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 472 records.
20/04/13 22:26:17 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11557 records.
20/04/13 22:26:17 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5926 records.
20/04/13 22:26:17 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:17 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:17 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:17 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:17 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:17 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:17 INFO hadoop.InternalParquetRecordReader: block read in memory in 28 ms. row count = 472
20/04/13 22:26:17 INFO hadoop.InternalParquetRecordReader: block read in memory in 29 ms. row count = 11557
20/04/13 22:26:17 INFO hadoop.InternalParquetRecordReader: block read in memory in 30 ms. row count = 5926
20/04/13 22:26:17 INFO memory.MemoryStore: Block rdd_4_8 stored as values in memory (estimated size 1296.6 KB, free 3.0 GB)
20/04/13 22:26:17 INFO codegen.CodeGenerator: Code generated in 5.839491 ms
20/04/13 22:26:17 INFO codegen.CodeGenerator: Code generated in 23.534006 ms
20/04/13 22:26:18 INFO memory.MemoryStore: Block rdd_4_3 stored as values in memory (estimated size 32.5 MB, free 3.0 GB)
20/04/13 22:26:18 INFO memory.MemoryStore: Block rdd_4_6 stored as values in memory (estimated size 33.8 MB, free 3.0 GB)
20/04/13 22:26:18 INFO codegen.CodeGenerator: Code generated in 9.851413 ms
20/04/13 22:26:18 INFO executor.Executor: Finished task 8.0 in stage 2.0 (TID 10). 1427 bytes result sent to driver
20/04/13 22:26:18 INFO executor.Executor: Finished task 6.0 in stage 2.0 (TID 8). 1427 bytes result sent to driver
20/04/13 22:26:18 INFO executor.Executor: Finished task 3.0 in stage 2.0 (TID 5). 1427 bytes result sent to driver
20/04/13 22:26:18 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 12
20/04/13 22:26:18 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 15
20/04/13 22:26:18 INFO executor.Executor: Running task 3.0 in stage 3.0 (TID 12)
20/04/13 22:26:18 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 18
20/04/13 22:26:18 INFO executor.Executor: Running task 6.0 in stage 3.0 (TID 15)
20/04/13 22:26:18 INFO executor.Executor: Running task 8.0 in stage 3.0 (TID 18)
20/04/13 22:26:18 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/13 22:26:18 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.5 KB, free 3.0 GB)
20/04/13 22:26:18 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 9 ms
20/04/13 22:26:19 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 38.4 KB, free 3.0 GB)
20/04/13 22:26:19 INFO storage.BlockManager: Found block rdd_4_6 locally
20/04/13 22:26:19 INFO storage.BlockManager: Found block rdd_4_3 locally
20/04/13 22:26:19 INFO storage.BlockManager: Found block rdd_4_8 locally
20/04/13 22:26:19 INFO executor.Executor: Finished task 8.0 in stage 3.0 (TID 18). 1363 bytes result sent to driver
20/04/13 22:26:19 INFO executor.Executor: Finished task 3.0 in stage 3.0 (TID 12). 20680 bytes result sent to driver
20/04/13 22:26:19 INFO executor.Executor: Finished task 6.0 in stage 3.0 (TID 15). 8331 bytes result sent to driver
20/04/13 22:26:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 22
20/04/13 22:26:21 INFO executor.Executor: Running task 3.0 in stage 4.0 (TID 22)
20/04/13 22:26:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 25
20/04/13 22:26:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 28
20/04/13 22:26:21 INFO executor.Executor: Running task 8.0 in stage 4.0 (TID 28)
20/04/13 22:26:21 INFO executor.Executor: Running task 6.0 in stage 4.0 (TID 25)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:26:21 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:45529 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 3.0 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 21 ms
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 3.0 GB)
20/04/13 22:26:21 INFO storage.BlockManager: Found block rdd_4_6 locally
20/04/13 22:26:21 INFO storage.BlockManager: Found block rdd_4_8 locally
20/04/13 22:26:21 INFO storage.BlockManager: Found block rdd_4_3 locally
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 3.0 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 8 ms
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 3.0 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 3.0 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 42 ms
20/04/13 22:26:22 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:26:27 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:26:28 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:26:28 INFO util.ShutdownHookManager: Shutdown hook called
20/04/13 22:26:28 ERROR executor.Executor: Exception in task 8.0 in stage 4.0 (TID 28)
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:26:28 INFO executor.Executor: Not reporting error to driver during JVM shutdown.
20/04/13 22:26:28 ERROR util.SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 28,5,main]
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 22125"...
End of LogType:stdout



Container: container_1586815278733_0007_01_000006 on 64.227.70.177_41217
==========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:16260
Log Contents:
20/04/13 22:26:28 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22291@64.227.70.177
20/04/13 22:26:28 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:28 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:28 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:29 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:29 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:29 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:29 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:29 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:29 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 50 ms (0 ms spent in bootstraps)
20/04/13 22:26:29 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:29 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:29 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:29 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:29 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:29 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:26:29 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-613067e9-a3f3-4dbc-a818-c2429be1c823
20/04/13 22:26:30 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:30 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.197.156:39167
20/04/13 22:26:30 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:26:30 INFO executor.Executor: Starting executor ID 4 on host 64.227.70.177
20/04/13 22:26:30 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35943.
20/04/13 22:26:30 INFO netty.NettyBlockTransferService: Server created on 64.227.70.177:35943
20/04/13 22:26:30 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:30 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(4, 64.227.70.177, 35943, None)
20/04/13 22:26:30 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(4, 64.227.70.177, 35943, None)
20/04/13 22:26:30 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(4, 64.227.70.177, 35943, None)
20/04/13 22:26:30 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 29
20/04/13 22:26:30 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 30
20/04/13 22:26:30 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 31
20/04/13 22:26:30 INFO executor.Executor: Running task 6.1 in stage 4.0 (TID 30)
20/04/13 22:26:30 INFO executor.Executor: Running task 3.1 in stage 4.0 (TID 31)
20/04/13 22:26:30 INFO executor.Executor: Running task 8.1 in stage 4.0 (TID 29)
20/04/13 22:26:30 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:26:30 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:45529 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:26:30 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 3.0 GB)
20/04/13 22:26:30 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 71 ms
20/04/13 22:26:30 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 3.0 GB)
20/04/13 22:26:31 INFO codegen.CodeGenerator: Code generated in 268.236576 ms
20/04/13 22:26:31 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00008-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-213844, partition values: [empty row]
20/04/13 22:26:31 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00004-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4935172, partition values: [empty row]
20/04/13 22:26:31 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00001-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4785170, partition values: [empty row]
20/04/13 22:26:31 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:26:31 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/13 22:26:31 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 10 ms
20/04/13 22:26:31 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:26:32 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:32 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:32 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:32 INFO codegen.CodeGenerator: Code generated in 22.498217 ms
20/04/13 22:26:32 INFO codegen.CodeGenerator: Code generated in 16.915228 ms
20/04/13 22:26:32 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11557 records.
20/04/13 22:26:32 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 472 records.
20/04/13 22:26:32 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5926 records.
20/04/13 22:26:32 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:32 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:32 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:32 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:32 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:32 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:32 INFO hadoop.InternalParquetRecordReader: block read in memory in 44 ms. row count = 472
20/04/13 22:26:32 INFO hadoop.InternalParquetRecordReader: block read in memory in 48 ms. row count = 11557
20/04/13 22:26:32 INFO hadoop.InternalParquetRecordReader: block read in memory in 48 ms. row count = 5926
20/04/13 22:26:32 INFO memory.MemoryStore: Block rdd_4_8 stored as values in memory (estimated size 1296.6 KB, free 3.0 GB)
20/04/13 22:26:33 INFO codegen.CodeGenerator: Code generated in 6.780278 ms
20/04/13 22:26:33 INFO codegen.CodeGenerator: Code generated in 29.160067 ms
20/04/13 22:26:33 INFO memory.MemoryStore: Block rdd_4_6 stored as values in memory (estimated size 33.8 MB, free 3.0 GB)
20/04/13 22:26:33 INFO memory.MemoryStore: Block rdd_4_3 stored as values in memory (estimated size 32.5 MB, free 3.0 GB)
20/04/13 22:26:34 INFO codegen.CodeGenerator: Code generated in 14.539191 ms
20/04/13 22:26:34 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:26:34 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 3.0 GB)
20/04/13 22:26:34 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 10 ms
20/04/13 22:26:34 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 3.0 GB)
20/04/13 22:26:34 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:26:34 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 3.0 GB)
20/04/13 22:26:34 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 23 ms
20/04/13 22:26:35 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:26:39 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:26:39 ERROR executor.Executor: Exception in task 6.1 in stage 4.0 (TID 30)
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:26:39 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:26:40 INFO executor.Executor: Not reporting error to driver during JVM shutdown.
20/04/13 22:26:40 ERROR util.SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 30,5,main]
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:26:40 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 22291"...
End of LogType:stdout



Container: container_1586815278733_0007_02_000007 on 64.227.70.177_41217
==========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:16256
Log Contents:
20/04/13 22:27:24 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22838@64.227.70.177
20/04/13 22:27:24 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:27:24 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:27:24 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:27:24 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:27:24 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:27:24 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:27:24 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:27:24 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:27:25 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 48 ms (0 ms spent in bootstraps)
20/04/13 22:27:25 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:27:25 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:27:25 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:27:25 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:27:25 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:27:25 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 3 ms (0 ms spent in bootstraps)
20/04/13 22:27:25 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-31eb79a8-f57d-4518-93b0-e8833a839e75
20/04/13 22:27:25 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:27:25 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@64.227.70.177:45487
20/04/13 22:27:25 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:27:25 INFO executor.Executor: Starting executor ID 6 on host 64.227.70.177
20/04/13 22:27:25 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39225.
20/04/13 22:27:25 INFO netty.NettyBlockTransferService: Server created on 64.227.70.177:39225
20/04/13 22:27:25 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:27:25 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(6, 64.227.70.177, 39225, None)
20/04/13 22:27:25 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(6, 64.227.70.177, 39225, None)
20/04/13 22:27:25 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(6, 64.227.70.177, 39225, None)
20/04/13 22:27:25 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 35
20/04/13 22:27:25 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 36
20/04/13 22:27:25 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 37
20/04/13 22:27:25 INFO executor.Executor: Running task 5.1 in stage 4.0 (TID 35)
20/04/13 22:27:25 INFO executor.Executor: Running task 0.1 in stage 4.0 (TID 37)
20/04/13 22:27:25 INFO executor.Executor: Running task 2.1 in stage 4.0 (TID 36)
20/04/13 22:27:25 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:27:25 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:38753 after 1 ms (0 ms spent in bootstraps)
20/04/13 22:27:25 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 3.0 GB)
20/04/13 22:27:25 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 67 ms
20/04/13 22:27:25 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 3.0 GB)
20/04/13 22:27:26 INFO codegen.CodeGenerator: Code generated in 265.646373 ms
20/04/13 22:27:26 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00006-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4956444, partition values: [empty row]
20/04/13 22:27:26 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00007-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4944913, partition values: [empty row]
20/04/13 22:27:26 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00000-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4791031, partition values: [empty row]
20/04/13 22:27:26 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:27:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/13 22:27:26 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 11 ms
20/04/13 22:27:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:27:27 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:27 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:27 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:27 INFO codegen.CodeGenerator: Code generated in 14.898554 ms
20/04/13 22:27:27 INFO codegen.CodeGenerator: Code generated in 10.641298 ms
20/04/13 22:27:27 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11674 records.
20/04/13 22:27:27 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5980 records.
20/04/13 22:27:27 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11734 records.
20/04/13 22:27:27 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:27 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:27 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:27 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:27 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:27 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:27 INFO hadoop.InternalParquetRecordReader: block read in memory in 31 ms. row count = 5980
20/04/13 22:27:27 INFO hadoop.InternalParquetRecordReader: block read in memory in 33 ms. row count = 11734
20/04/13 22:27:27 INFO hadoop.InternalParquetRecordReader: block read in memory in 32 ms. row count = 11674
20/04/13 22:27:28 INFO memory.MemoryStore: Block rdd_4_0 stored as values in memory (estimated size 32.6 MB, free 3.0 GB)
20/04/13 22:27:28 INFO memory.MemoryStore: Block rdd_4_5 stored as values in memory (estimated size 33.8 MB, free 3.0 GB)
20/04/13 22:27:28 INFO codegen.CodeGenerator: Code generated in 6.895841 ms
20/04/13 22:27:28 INFO codegen.CodeGenerator: Code generated in 18.933993 ms
20/04/13 22:27:28 INFO memory.MemoryStore: Block rdd_4_2 stored as values in memory (estimated size 32.6 MB, free 2.9 GB)
20/04/13 22:27:29 INFO codegen.CodeGenerator: Code generated in 8.74892 ms
20/04/13 22:27:29 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:27:29 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 2.9 GB)
20/04/13 22:27:29 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 8 ms
20/04/13 22:27:29 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 2.9 GB)
20/04/13 22:27:29 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:27:29 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 2.9 GB)
20/04/13 22:27:29 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 14 ms
20/04/13 22:27:30 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:27:34 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:27:34 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:27:34 INFO util.ShutdownHookManager: Shutdown hook called
20/04/13 22:27:34 ERROR executor.Executor: Exception in task 0.1 in stage 4.0 (TID 37)
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:27:34 INFO executor.Executor: Not reporting error to driver during JVM shutdown.
20/04/13 22:27:34 ERROR util.SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 37,5,main]
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 22838"...
End of LogType:stdout



Container: container_1586815278733_0007_01_000003 on 64.227.70.177_41217
==========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:20049
Log Contents:
20/04/13 22:26:05 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22095@64.227.70.177
20/04/13 22:26:05 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:05 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:05 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:06 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:06 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:06 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:06 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:06 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:06 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 49 ms (0 ms spent in bootstraps)
20/04/13 22:26:06 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:06 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:06 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:06 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:06 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:06 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:39167 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:26:06 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-3317739d-c9d0-47a4-a068-a531ee26f3c4
20/04/13 22:26:06 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:06 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@178.62.197.156:39167
20/04/13 22:26:06 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:26:06 INFO executor.Executor: Starting executor ID 2 on host 64.227.70.177
20/04/13 22:26:06 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33507.
20/04/13 22:26:06 INFO netty.NettyBlockTransferService: Server created on 64.227.70.177:33507
20/04/13 22:26:06 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:06 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(2, 64.227.70.177, 33507, None)
20/04/13 22:26:06 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(2, 64.227.70.177, 33507, None)
20/04/13 22:26:06 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(2, 64.227.70.177, 33507, None)
20/04/13 22:26:12 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1
20/04/13 22:26:12 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)
20/04/13 22:26:12 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
20/04/13 22:26:12 INFO client.TransportClientFactory: Successfully created connection to /178.62.197.156:45529 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:26:12 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:26:12 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 79 ms
20/04/13 22:26:12 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 21.5 KB, free 3.0 GB)
20/04/13 22:26:12 INFO codegen.CodeGenerator: Code generated in 156.211329 ms
20/04/13 22:26:12 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00006-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4956444, partition values: [empty row]
20/04/13 22:26:12 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:26:12 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.4 KB, free 3.0 GB)
20/04/13 22:26:12 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 11 ms
20/04/13 22:26:12 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:26:13 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:13 INFO codegen.CodeGenerator: Code generated in 45.939759 ms
20/04/13 22:26:13 INFO codegen.CodeGenerator: Code generated in 12.946094 ms
20/04/13 22:26:13 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11734 records.
20/04/13 22:26:13 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:13 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:13 INFO hadoop.InternalParquetRecordReader: block read in memory in 28 ms. row count = 11734
20/04/13 22:26:14 INFO memory.MemoryStore: Block rdd_4_0 stored as values in memory (estimated size 32.6 MB, free 3.0 GB)
20/04/13 22:26:14 INFO codegen.CodeGenerator: Code generated in 4.639333 ms
20/04/13 22:26:14 INFO codegen.CodeGenerator: Code generated in 15.337753 ms
20/04/13 22:26:15 INFO codegen.CodeGenerator: Code generated in 8.415754 ms
20/04/13 22:26:15 INFO executor.Executor: 1 block locks were not released by TID = 1:
[rdd_4_0]
20/04/13 22:26:15 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 5425 bytes result sent to driver
20/04/13 22:26:15 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2
20/04/13 22:26:15 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3
20/04/13 22:26:15 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 6
20/04/13 22:26:15 INFO executor.Executor: Running task 1.0 in stage 2.0 (TID 3)
20/04/13 22:26:15 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 2)
20/04/13 22:26:15 INFO executor.Executor: Running task 4.0 in stage 2.0 (TID 6)
20/04/13 22:26:15 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/13 22:26:15 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:26:15 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 10 ms
20/04/13 22:26:15 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 21.3 KB, free 3.0 GB)
20/04/13 22:26:15 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00005-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4950456, partition values: [empty row]
20/04/13 22:26:15 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00003-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4855590, partition values: [empty row]
20/04/13 22:26:15 INFO storage.BlockManager: Found block rdd_4_0 locally
20/04/13 22:26:15 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:15 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 9550 records.
20/04/13 22:26:15 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:15 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:26:15 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11838 records.
20/04/13 22:26:15 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:26:15 INFO hadoop.InternalParquetRecordReader: block read in memory in 31 ms. row count = 9550
20/04/13 22:26:15 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:26:15 INFO hadoop.InternalParquetRecordReader: block read in memory in 19 ms. row count = 11838
20/04/13 22:26:15 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 2). 1427 bytes result sent to driver
20/04/13 22:26:16 INFO memory.MemoryStore: Block rdd_4_4 stored as values in memory (estimated size 33.1 MB, free 3.0 GB)
20/04/13 22:26:16 INFO memory.MemoryStore: Block rdd_4_1 stored as values in memory (estimated size 32.6 MB, free 2.9 GB)
20/04/13 22:26:16 INFO executor.Executor: Finished task 4.0 in stage 2.0 (TID 6). 1427 bytes result sent to driver
20/04/13 22:26:16 INFO executor.Executor: Finished task 1.0 in stage 2.0 (TID 3). 1427 bytes result sent to driver
20/04/13 22:26:18 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 11
20/04/13 22:26:18 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 14
20/04/13 22:26:18 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 11)
20/04/13 22:26:18 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 17
20/04/13 22:26:18 INFO executor.Executor: Running task 1.0 in stage 3.0 (TID 14)
20/04/13 22:26:18 INFO executor.Executor: Running task 4.0 in stage 3.0 (TID 17)
20/04/13 22:26:18 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/13 22:26:18 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.5 KB, free 2.9 GB)
20/04/13 22:26:18 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 11 ms
20/04/13 22:26:18 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 38.4 KB, free 2.9 GB)
20/04/13 22:26:19 INFO storage.BlockManager: Found block rdd_4_4 locally
20/04/13 22:26:19 INFO storage.BlockManager: Found block rdd_4_0 locally
20/04/13 22:26:19 INFO storage.BlockManager: Found block rdd_4_1 locally
20/04/13 22:26:19 INFO executor.Executor: Finished task 1.0 in stage 3.0 (TID 14). 12932 bytes result sent to driver
20/04/13 22:26:19 INFO executor.Executor: Finished task 4.0 in stage 3.0 (TID 17). 11696 bytes result sent to driver
20/04/13 22:26:19 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 11). 26344 bytes result sent to driver
20/04/13 22:26:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 20
20/04/13 22:26:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 23
20/04/13 22:26:21 INFO executor.Executor: Running task 0.0 in stage 4.0 (TID 20)
20/04/13 22:26:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 26
20/04/13 22:26:21 INFO executor.Executor: Running task 1.0 in stage 4.0 (TID 23)
20/04/13 22:26:21 INFO executor.Executor: Running task 4.0 in stage 4.0 (TID 26)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 2.9 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 10 ms
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 2.9 GB)
20/04/13 22:26:21 INFO storage.BlockManager: Found block rdd_4_0 locally
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:26:21 INFO storage.BlockManager: Found block rdd_4_1 locally
20/04/13 22:26:21 INFO storage.BlockManager: Found block rdd_4_4 locally
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 2.9 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 19 ms
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 2.9 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:26:21 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 2.9 GB)
20/04/13 22:26:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 19 ms
20/04/13 22:26:22 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:26:27 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:26:27 ERROR executor.Executor: Exception in task 0.0 in stage 4.0 (TID 20)
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:26:27 INFO executor.Executor: Not reporting error to driver during JVM shutdown.
20/04/13 22:26:27 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:26:27 ERROR util.SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 20,5,main]
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:26:27 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 22095"...
End of LogType:stdout



Container: container_1586815278733_0007_02_000003 on 64.227.70.177_41217
==========================================================================
LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:20041
Log Contents:
20/04/13 22:26:54 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22671@64.227.70.177
20/04/13 22:26:54 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:54 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:54 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:54 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:54 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:54 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:54 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:54 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 45 ms (0 ms spent in bootstraps)
20/04/13 22:26:55 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:55 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:55 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:55 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:55 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:55 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:45487 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:26:55 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-f733b4bc-bf66-4d19-9bff-c16e87efa243
20/04/13 22:26:55 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:55 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@64.227.70.177:45487
20/04/13 22:26:55 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/13 22:26:55 INFO executor.Executor: Starting executor ID 2 on host 64.227.70.177
20/04/13 22:26:55 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39847.
20/04/13 22:26:55 INFO netty.NettyBlockTransferService: Server created on 64.227.70.177:39847
20/04/13 22:26:55 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:55 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(2, 64.227.70.177, 39847, None)
20/04/13 22:26:55 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(2, 64.227.70.177, 39847, None)
20/04/13 22:26:55 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(2, 64.227.70.177, 39847, None)
20/04/13 22:27:01 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1
20/04/13 22:27:01 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)
20/04/13 22:27:01 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
20/04/13 22:27:01 INFO client.TransportClientFactory: Successfully created connection to /64.227.70.177:38753 after 2 ms (0 ms spent in bootstraps)
20/04/13 22:27:01 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:27:01 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 86 ms
20/04/13 22:27:01 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 21.5 KB, free 3.0 GB)
20/04/13 22:27:01 INFO codegen.CodeGenerator: Code generated in 217.671837 ms
20/04/13 22:27:01 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00006-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4956444, partition values: [empty row]
20/04/13 22:27:01 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/04/13 22:27:01 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/13 22:27:01 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 11 ms
20/04/13 22:27:01 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 540.2 KB, free 3.0 GB)
20/04/13 22:27:02 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:02 INFO codegen.CodeGenerator: Code generated in 15.766897 ms
20/04/13 22:27:02 INFO codegen.CodeGenerator: Code generated in 11.6816 ms
20/04/13 22:27:02 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11734 records.
20/04/13 22:27:02 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:02 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:02 INFO hadoop.InternalParquetRecordReader: block read in memory in 28 ms. row count = 11734
20/04/13 22:27:03 INFO memory.MemoryStore: Block rdd_4_0 stored as values in memory (estimated size 32.6 MB, free 3.0 GB)
20/04/13 22:27:03 INFO codegen.CodeGenerator: Code generated in 4.448918 ms
20/04/13 22:27:03 INFO codegen.CodeGenerator: Code generated in 14.974238 ms
20/04/13 22:27:04 INFO codegen.CodeGenerator: Code generated in 8.341281 ms
20/04/13 22:27:04 INFO executor.Executor: 1 block locks were not released by TID = 1:
[rdd_4_0]
20/04/13 22:27:04 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 5382 bytes result sent to driver
20/04/13 22:27:04 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2
20/04/13 22:27:04 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 2)
20/04/13 22:27:04 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 4
20/04/13 22:27:04 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 7
20/04/13 22:27:04 INFO executor.Executor: Running task 2.0 in stage 2.0 (TID 4)
20/04/13 22:27:04 INFO executor.Executor: Running task 5.0 in stage 2.0 (TID 7)
20/04/13 22:27:04 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/04/13 22:27:04 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:27:04 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 11 ms
20/04/13 22:27:04 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 21.3 KB, free 3.0 GB)
20/04/13 22:27:04 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00007-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4944913, partition values: [empty row]
20/04/13 22:27:04 INFO storage.BlockManager: Found block rdd_4_0 locally
20/04/13 22:27:04 INFO datasources.FileScanRDD: Reading File path: hdfs://178.62.197.108:9000/data/df_3-shingles_sparse-binary-vectors.parquet/part-00000-4972d68d-2114-4d85-9d6a-980041937c5b-c000.snappy.parquet, range: 0-4791031, partition values: [empty row]
20/04/13 22:27:04 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:04 INFO parquet.ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary entry (UTF8);
  optional binary entry_name (UTF8);
  optional group features {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
}

Catalyst form:
StructType(StructField(entry,StringType,true), StructField(entry_name,StringType,true), StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))
       
20/04/13 22:27:04 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 11674 records.
20/04/13 22:27:04 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:04 INFO hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 5980 records.
20/04/13 22:27:04 INFO hadoop.InternalParquetRecordReader: at row 0. reading next block
20/04/13 22:27:04 INFO hadoop.InternalParquetRecordReader: block read in memory in 11 ms. row count = 11674
20/04/13 22:27:04 INFO compress.CodecPool: Got brand-new decompressor [.snappy]
20/04/13 22:27:04 INFO hadoop.InternalParquetRecordReader: block read in memory in 27 ms. row count = 5980
20/04/13 22:27:04 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 2). 1427 bytes result sent to driver
20/04/13 22:27:04 INFO memory.MemoryStore: Block rdd_4_2 stored as values in memory (estimated size 32.6 MB, free 3.0 GB)
20/04/13 22:27:04 INFO executor.Executor: Finished task 2.0 in stage 2.0 (TID 4). 1470 bytes result sent to driver
20/04/13 22:27:05 INFO memory.MemoryStore: Block rdd_4_5 stored as values in memory (estimated size 33.8 MB, free 2.9 GB)
20/04/13 22:27:05 INFO executor.Executor: Finished task 5.0 in stage 2.0 (TID 7). 1427 bytes result sent to driver
20/04/13 22:27:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 11
20/04/13 22:27:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 14
20/04/13 22:27:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 17
20/04/13 22:27:09 INFO executor.Executor: Running task 5.0 in stage 3.0 (TID 17)
20/04/13 22:27:09 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 11)
20/04/13 22:27:09 INFO executor.Executor: Running task 2.0 in stage 3.0 (TID 14)
20/04/13 22:27:09 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/04/13 22:27:09 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.5 KB, free 2.9 GB)
20/04/13 22:27:09 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 12 ms
20/04/13 22:27:09 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 38.4 KB, free 2.9 GB)
20/04/13 22:27:09 INFO storage.BlockManager: Found block rdd_4_2 locally
20/04/13 22:27:09 INFO storage.BlockManager: Found block rdd_4_0 locally
20/04/13 22:27:09 INFO storage.BlockManager: Found block rdd_4_5 locally
20/04/13 22:27:09 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 11). 26301 bytes result sent to driver
20/04/13 22:27:09 INFO executor.Executor: Finished task 2.0 in stage 3.0 (TID 14). 28975 bytes result sent to driver
20/04/13 22:27:09 INFO executor.Executor: Finished task 5.0 in stage 3.0 (TID 17). 1449 bytes result sent to driver
20/04/13 22:27:11 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 22
20/04/13 22:27:11 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 25
20/04/13 22:27:11 INFO executor.Executor: Running task 0.0 in stage 4.0 (TID 22)
20/04/13 22:27:11 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 28
20/04/13 22:27:11 INFO executor.Executor: Running task 2.0 in stage 4.0 (TID 25)
20/04/13 22:27:11 INFO executor.Executor: Running task 5.0 in stage 4.0 (TID 28)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 2.9 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 10 ms
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 2.9 GB)
20/04/13 22:27:11 INFO storage.BlockManager: Found block rdd_4_2 locally
20/04/13 22:27:11 INFO storage.BlockManager: Found block rdd_4_5 locally
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/04/13 22:27:11 INFO storage.BlockManager: Found block rdd_4_0 locally
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 2.9 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 8 ms
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 2.9 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 2.9 GB)
20/04/13 22:27:11 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 13 ms
20/04/13 22:27:12 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.4 GB)
20/04/13 22:27:16 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/13 22:27:16 ERROR executor.Executor: Exception in task 0.0 in stage 4.0 (TID 22)
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:27:16 INFO storage.DiskBlockManager: Shutdown hook called
20/04/13 22:27:16 INFO executor.Executor: Not reporting error to driver during JVM shutdown.
20/04/13 22:27:16 ERROR util.SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 22,5,main]
java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:141)
	at scala.reflect.ManifestFactory$$anon$12.newArray(Manifest.scala:139)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:345)
	at breeze.linalg.DenseMatrix$.zeros(DenseMatrix.scala:333)
	at breeze.linalg.MatrixConstructors$class.tabulate(Matrix.scala:228)
	at breeze.linalg.DenseMatrix$.tabulate(DenseMatrix.scala:333)
	at breeze.linalg.package$.lowerTriangular(package.scala:205)
	at breeze.linalg.eigSym$.breeze$linalg$eigSym$$doEigSym(eig.scala:124)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:96)
	at breeze.linalg.eigSym$EigSym_DM_Impl$.apply(eig.scala:94)
	at breeze.generic.UFunc$class.apply(UFunc.scala:48)
	at breeze.linalg.eigSym$.apply(eig.scala:91)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.calculateCovarianceConstants(MultivariateGaussian.scala:117)
	at org.apache.spark.ml.stat.distribution.MultivariateGaussian.<init>(MultivariateGaussian.scala:58)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:610)
	at org.apache.spark.ml.clustering.ExpectationAggregator$$anonfun$oldGaussians$1.apply(GaussianMixture.scala:608)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians$lzycompute(GaussianMixture.scala:608)
	at org.apache.spark.ml.clustering.ExpectationAggregator.oldGaussians(GaussianMixture.scala:607)
	at org.apache.spark.ml.clustering.ExpectationAggregator.add(GaussianMixture.scala:633)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:386)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1$$anonfun$11.apply(GaussianMixture.scala:385)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
20/04/13 22:27:16 INFO util.ShutdownHookManager: Shutdown hook called
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:124
Log Contents:
#
# java.lang.OutOfMemoryError: Java heap space
# -XX:OnOutOfMemoryError="kill %p"
#   Executing /bin/sh -c "kill 22671"...
End of LogType:stdout



Container: container_1586815278733_0007_02_000001 on 64.227.70.177_41217
==========================================================================
LogType:pyspark.log
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:23295
Log Contents:
[PYTHON] 2020-04-13 22:26:57,572.572 INFO clustering - wrapper: perform_experiment keyword arguments:
[PYTHON] 2020-04-13 22:26:57,574.574 INFO clustering - wrapper: in_files: ['/data/df_3-shingles_sparse-binary-vectors.parquet']
[PYTHON] 2020-04-13 22:26:57,574.574 INFO clustering - wrapper: distances: ['euclidean', 'cosine']
[PYTHON] 2020-04-13 22:26:57,574.574 INFO clustering - wrapper: ks: [2, 4]
[PYTHON] 2020-04-13 22:26:57,574.574 INFO clustering - wrapper: models: [<class 'pyspark.ml.clustering.GaussianMixture'>]
[PYTHON] 2020-04-13 22:26:57,574.574 INFO clustering - wrapper: result_dfs_list: []
[PYTHON] 2020-04-13 22:27:38,389.389 INFO java_gateway - send_command: Error while receiving.
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1159, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
[PYTHON] 2020-04-13 22:27:38,391.391 ERROR java_gateway - send_command: Exception while sending command.
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1159, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 985, in send_command
    response = connection.send_command(command)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1164, in send_command
    "Error while receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while receiving
[PYTHON] 2020-04-13 22:27:38,393.393 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,393.393 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,393.393 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,393.393 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,394.394 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,394.394 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,394.394 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,394.394 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,394.394 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,394.394 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,395.395 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,395.395 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,395.395 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,395.395 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,395.395 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,395.395 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,395.395 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,396.396 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,396.396 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,396.396 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,397.397 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,397.397 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,397.397 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,397.397 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,398.398 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,398.398 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,398.398 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,398.398 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,468.468 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
[PYTHON] 2020-04-13 22:27:38,474.474 ERROR java_gateway - start: An error occurred while trying to connect to the Java server (127.0.0.1:44751)
Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
End of LogType:pyspark.log

LogType:stderr
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:86483
Log Contents:
20/04/13 22:26:49 INFO util.SignalUtils: Registered signal handler for TERM
20/04/13 22:26:49 INFO util.SignalUtils: Registered signal handler for HUP
20/04/13 22:26:49 INFO util.SignalUtils: Registered signal handler for INT
20/04/13 22:26:49 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:49 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:49 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:49 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:49 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:49 INFO yarn.ApplicationMaster: Preparing Local resources
20/04/13 22:26:50 INFO yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1586815278733_0007_000002
20/04/13 22:26:50 INFO yarn.ApplicationMaster: Starting the user application in a separate Thread
20/04/13 22:26:50 INFO yarn.ApplicationMaster: Waiting for spark context initialization...
20/04/13 22:26:50 INFO spark.SparkContext: Running Spark version 2.4.5
20/04/13 22:26:50 INFO spark.SparkContext: Submitted application: ClusteringExperiment
20/04/13 22:26:51 INFO spark.SecurityManager: Changing view acls to: root
20/04/13 22:26:51 INFO spark.SecurityManager: Changing modify acls to: root
20/04/13 22:26:51 INFO spark.SecurityManager: Changing view acls groups to: 
20/04/13 22:26:51 INFO spark.SecurityManager: Changing modify acls groups to: 
20/04/13 22:26:51 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
20/04/13 22:26:51 INFO util.Utils: Successfully started service 'sparkDriver' on port 45487.
20/04/13 22:26:51 INFO spark.SparkEnv: Registering MapOutputTracker
20/04/13 22:26:51 INFO spark.SparkEnv: Registering BlockManagerMaster
20/04/13 22:26:51 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/04/13 22:26:51 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/04/13 22:26:51 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/blockmgr-b1e58b07-0e6f-4ef6-a5fe-4e54a0cc46f3
20/04/13 22:26:51 INFO memory.MemoryStore: MemoryStore started with capacity 3.0 GB
20/04/13 22:26:51 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/04/13 22:26:51 INFO util.log: Logging initialized @2478ms
20/04/13 22:26:51 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/04/13 22:26:51 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
20/04/13 22:26:51 INFO server.Server: Started @2562ms
20/04/13 22:26:51 INFO server.AbstractConnector: Started ServerConnector@535570b2{HTTP/1.1,[http/1.1]}{0.0.0.0:38283}
20/04/13 22:26:51 INFO util.Utils: Successfully started service 'SparkUI' on port 38283.
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1eda1675{/jobs,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7c0acb48{/jobs/json,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@46d2df4a{/jobs/job,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@400e01d3{/jobs/job/json,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6a74c211{/stages,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a0c789a{/stages/json,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@73d513c3{/stages/stage,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@565cc31f{/stages/stage/json,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@dcc891c{/stages/pool,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6261c64a{/stages/pool/json,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@588350{/storage,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30acec7f{/storage/json,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59c1071f{/storage/rdd,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35fed9fb{/storage/rdd/json,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@71f88e17{/environment,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26604b43{/environment/json,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7748596f{/executors,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@343a677c{/executors/json,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@187dfda{/executors/threadDump,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2519b6fa{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10af0017{/static,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f578d46{/,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@53f1e871{/api,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c862ede{/jobs/job/kill,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26c3b686{/stages/stage/kill,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://64.227.70.177:38283
20/04/13 22:26:51 INFO cluster.YarnClusterScheduler: Created YarnClusterScheduler
20/04/13 22:26:51 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1586815278733_0007 and attemptId Some(appattempt_1586815278733_0007_000002)
20/04/13 22:26:51 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38753.
20/04/13 22:26:51 INFO netty.NettyBlockTransferService: Server created on 64.227.70.177:38753
20/04/13 22:26:51 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/13 22:26:51 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 64.227.70.177, 38753, None)
20/04/13 22:26:51 INFO storage.BlockManagerMasterEndpoint: Registering block manager 64.227.70.177:38753 with 3.0 GB RAM, BlockManagerId(driver, 64.227.70.177, 38753, None)
20/04/13 22:26:51 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 64.227.70.177, 38753, None)
20/04/13 22:26:51 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 64.227.70.177, 38753, None)
20/04/13 22:26:51 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/04/13 22:26:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@43366204{/metrics/json,null,AVAILABLE,@Spark}
20/04/13 22:26:51 INFO client.RMProxy: Connecting to ResourceManager at /178.62.197.108:8030
20/04/13 22:26:51 INFO yarn.YarnRMClient: Registering the ApplicationMaster
20/04/13 22:26:52 INFO yarn.ApplicationMaster: 
===============================================================================
YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>$HADOOP_CONF_DIR<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/*<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/lib/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<CPS>/usr/src/hadoop-2.8.5/etc/hadoop:/usr/src/hadoop-2.8.5/share/hadoop/common/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/common/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/*:/usr/src/hadoop-2.8.5/contrib/capacity-scheduler/*.jar<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_DIST_CLASSPATH -> /usr/src/hadoop-2.8.5/etc/hadoop:/usr/src/hadoop-2.8.5/share/hadoop/common/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/common/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/hdfs/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/yarn/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/lib/*:/usr/src/hadoop-2.8.5/share/hadoop/mapreduce/*:/usr/src/hadoop-2.8.5/contrib/capacity-scheduler/*.jar
    SPARK_YARN_STAGING_DIR -> hdfs://178.62.197.108:9000/user/root/.sparkStaging/application_1586815278733_0007
    SPARK_USER -> root
    PYTHONPATH -> /usr/src/spark-2.4.5-bin-without-hadoop/python:/usr/src/spark-2.4.5-bin-without-hadoop/python/build:/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/pyspark.zip:/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.7-src.zip

  command:
    {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx6144m \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.driver.port=45487' \ 
      '-Dspark.ui.port=0' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.CoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@64.227.70.177:45487 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      3 \ 
      --app-id \ 
      application_1586815278733_0007 \ 
      --user-class-path \ 
      file:$PWD/__app__.jar \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    pyspark.zip -> resource { scheme: "hdfs" host: "178.62.197.108" port: 9000 file: "/user/root/.sparkStaging/application_1586815278733_0007/pyspark.zip" } size: 591945 timestamp: 1586816756842 type: FILE visibility: PRIVATE
    py4j-0.10.7-src.zip -> resource { scheme: "hdfs" host: "178.62.197.108" port: 9000 file: "/user/root/.sparkStaging/application_1586815278733_0007/py4j-0.10.7-src.zip" } size: 42437 timestamp: 1586816756866 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "178.62.197.108" port: 9000 file: "/user/root/.sparkStaging/application_1586815278733_0007/__spark_libs__4999350945858927134.zip" } size: 168822862 timestamp: 1586816756677 type: ARCHIVE visibility: PRIVATE
    __spark_conf__ -> resource { scheme: "hdfs" host: "178.62.197.108" port: 9000 file: "/user/root/.sparkStaging/application_1586815278733_0007/__spark_conf__.zip" } size: 233332 timestamp: 1586816756990 type: ARCHIVE visibility: PRIVATE

===============================================================================
20/04/13 22:26:52 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@64.227.70.177:45487)
20/04/13 22:26:52 INFO yarn.YarnAllocator: Will request 3 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/13 22:26:52 INFO yarn.YarnAllocator: Submitted 3 unlocalized container requests.
20/04/13 22:26:52 INFO yarn.ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
20/04/13 22:26:53 INFO impl.AMRMClientImpl: Received new token for : 64.227.70.177:41217
20/04/13 22:26:53 INFO impl.AMRMClientImpl: Received new token for : 178.62.197.156:36923
20/04/13 22:26:53 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_02_000002 on host 178.62.197.156 for executor with ID 1
20/04/13 22:26:53 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_02_000003 on host 64.227.70.177 for executor with ID 2
20/04/13 22:26:53 INFO yarn.YarnAllocator: Received 2 containers from YARN, launching executors on 2 of them.
20/04/13 22:26:53 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:26:53 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:26:55 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_02_000004 on host 178.62.197.156 for executor with ID 3
20/04/13 22:26:55 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/13 22:26:55 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:26:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (64.227.70.177:55004) with ID 2
20/04/13 22:26:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.197.156:54844) with ID 1
20/04/13 22:26:55 INFO storage.BlockManagerMasterEndpoint: Registering block manager 64.227.70.177:39847 with 3.0 GB RAM, BlockManagerId(2, 64.227.70.177, 39847, None)
20/04/13 22:26:55 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.197.156:42931 with 3.0 GB RAM, BlockManagerId(1, 178.62.197.156, 42931, None)
20/04/13 22:26:56 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.197.156:54848) with ID 3
20/04/13 22:26:57 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.197.156:44225 with 3.0 GB RAM, BlockManagerId(3, 178.62.197.156, 44225, None)
20/04/13 22:26:57 INFO cluster.YarnClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
20/04/13 22:26:57 INFO cluster.YarnClusterScheduler: YarnClusterScheduler.postStartHook done
20/04/13 22:26:57 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/container_1586815278733_0007_02_000001/spark-warehouse').
20/04/13 22:26:57 INFO internal.SharedState: Warehouse path is 'file:/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/container_1586815278733_0007_02_000001/spark-warehouse'.
20/04/13 22:26:57 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.
20/04/13 22:26:57 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7e29a8d3{/SQL,null,AVAILABLE,@Spark}
20/04/13 22:26:57 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.
20/04/13 22:26:57 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@658e59ac{/SQL/json,null,AVAILABLE,@Spark}
20/04/13 22:26:57 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.
20/04/13 22:26:57 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@309a346c{/SQL/execution,null,AVAILABLE,@Spark}
20/04/13 22:26:57 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.
20/04/13 22:26:57 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c72dbe9{/SQL/execution/json,null,AVAILABLE,@Spark}
20/04/13 22:26:57 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.
20/04/13 22:26:57 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3e0a7bf5{/static/sql,null,AVAILABLE,@Spark}
20/04/13 22:26:57 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
20/04/13 22:26:57 INFO datasources.InMemoryFileIndex: It took 98 ms to list leaf files for 1 paths.
20/04/13 22:26:57 INFO spark.SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
20/04/13 22:26:57 INFO scheduler.DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/04/13 22:26:57 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
20/04/13 22:26:57 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/04/13 22:26:57 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/13 22:26:57 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
20/04/13 22:26:58 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 127.0 KB, free 3.0 GB)
20/04/13 22:26:58 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.1 KB, free 3.0 GB)
20/04/13 22:26:58 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 64.227.70.177:38753 (size: 33.1 KB, free: 3.0 GB)
20/04/13 22:26:58 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1163
20/04/13 22:26:58 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/04/13 22:26:58 INFO cluster.YarnClusterScheduler: Adding task set 0.0 with 1 tasks
20/04/13 22:26:58 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 178.62.197.156, executor 1, partition 0, PROCESS_LOCAL, 8099 bytes)
20/04/13 22:26:58 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 178.62.197.156:42931 (size: 33.1 KB, free: 3.0 GB)
20/04/13 22:26:59 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1301 ms on 178.62.197.156 (executor 1) (1/1)
20/04/13 22:26:59 INFO cluster.YarnClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/04/13 22:26:59 INFO scheduler.DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.541 s
20/04/13 22:26:59 INFO scheduler.DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.570909 s
20/04/13 22:27:00 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/04/13 22:27:00 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/04/13 22:27:00 INFO datasources.FileSourceStrategy: Output Data Schema: struct<entry: string, entry_name: string, features: vector ... 1 more fields>
20/04/13 22:27:00 INFO execution.FileSourceScanExec: Pushed Filters: 
20/04/13 22:27:00 INFO codegen.CodeGenerator: Code generated in 169.580164 ms
20/04/13 22:27:00 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 341.6 KB, free 3.0 GB)
20/04/13 22:27:00 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 32.5 KB, free 3.0 GB)
20/04/13 22:27:00 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 64.227.70.177:38753 (size: 32.5 KB, free: 3.0 GB)
20/04/13 22:27:00 INFO spark.SparkContext: Created broadcast 1 from rdd at GaussianMixture.scala:348
20/04/13 22:27:00 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 8546355 bytes, open cost is considered as scanning 4194304 bytes.
20/04/13 22:27:01 INFO spark.SparkContext: Starting job: first at GaussianMixture.scala:357
20/04/13 22:27:01 INFO scheduler.DAGScheduler: Got job 1 (first at GaussianMixture.scala:357) with 1 output partitions
20/04/13 22:27:01 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (first at GaussianMixture.scala:357)
20/04/13 22:27:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/04/13 22:27:01 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/13 22:27:01 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at map at GaussianMixture.scala:348), which has no missing parents
20/04/13 22:27:01 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 21.5 KB, free 3.0 GB)
20/04/13 22:27:01 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:27:01 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 64.227.70.177:38753 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:27:01 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1163
20/04/13 22:27:01 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at map at GaussianMixture.scala:348) (first 15 tasks are for partitions Vector(0))
20/04/13 22:27:01 INFO cluster.YarnClusterScheduler: Adding task set 1.0 with 1 tasks
20/04/13 22:27:01 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 64.227.70.177, executor 2, partition 0, NODE_LOCAL, 8348 bytes)
20/04/13 22:27:01 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 64.227.70.177:39847 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:27:01 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 64.227.70.177:39847 (size: 32.5 KB, free: 3.0 GB)
20/04/13 22:27:03 INFO storage.BlockManagerInfo: Added rdd_4_0 in memory on 64.227.70.177:39847 (size: 32.6 MB, free: 3.0 GB)
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3245 ms on 64.227.70.177 (executor 2) (1/1)
20/04/13 22:27:04 INFO cluster.YarnClusterScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/04/13 22:27:04 INFO scheduler.DAGScheduler: ResultStage 1 (first at GaussianMixture.scala:357) finished in 3.254 s
20/04/13 22:27:04 INFO scheduler.DAGScheduler: Job 1 finished: first at GaussianMixture.scala:357, took 3.261756 s
20/04/13 22:27:04 INFO util.Instrumentation: [27cd7556] Stage class: GaussianMixture
20/04/13 22:27:04 INFO util.Instrumentation: [27cd7556] Stage uid: GaussianMixture_a63494c2d4a3
20/04/13 22:27:04 INFO util.Instrumentation: [27cd7556] training: numPartitions=9 storageLevel=StorageLevel(1 replicas)
20/04/13 22:27:04 INFO util.Instrumentation: [27cd7556] {"featuresCol":"features","predictionCol":"cluster","k":2,"seed":42}
20/04/13 22:27:04 INFO util.Instrumentation: [27cd7556] {"numFeatures":8502}
20/04/13 22:27:04 INFO spark.SparkContext: Starting job: takeSample at GaussianMixture.scala:470
20/04/13 22:27:04 INFO scheduler.DAGScheduler: Got job 2 (takeSample at GaussianMixture.scala:470) with 9 output partitions
20/04/13 22:27:04 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (takeSample at GaussianMixture.scala:470)
20/04/13 22:27:04 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/04/13 22:27:04 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/13 22:27:04 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at map at GaussianMixture.scala:348), which has no missing parents
20/04/13 22:27:04 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 21.3 KB, free 3.0 GB)
20/04/13 22:27:04 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.7 KB, free 3.0 GB)
20/04/13 22:27:04 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 64.227.70.177:38753 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:27:04 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1163
20/04/13 22:27:04 INFO scheduler.DAGScheduler: Submitting 9 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at map at GaussianMixture.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))
20/04/13 22:27:04 INFO cluster.YarnClusterScheduler: Adding task set 2.0 with 9 tasks
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 64.227.70.177, executor 2, partition 0, PROCESS_LOCAL, 8348 bytes)
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, 178.62.197.156, executor 1, partition 1, NODE_LOCAL, 8348 bytes)
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4, 64.227.70.177, executor 2, partition 2, NODE_LOCAL, 8348 bytes)
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5, 178.62.197.156, executor 3, partition 3, NODE_LOCAL, 8348 bytes)
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 2.0 (TID 6, 178.62.197.156, executor 1, partition 4, NODE_LOCAL, 8348 bytes)
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 2.0 (TID 7, 64.227.70.177, executor 2, partition 5, NODE_LOCAL, 8348 bytes)
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 2.0 (TID 8, 178.62.197.156, executor 3, partition 6, NODE_LOCAL, 8348 bytes)
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 2.0 (TID 9, 178.62.197.156, executor 1, partition 7, NODE_LOCAL, 8348 bytes)
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 2.0 (TID 10, 178.62.197.156, executor 3, partition 8, NODE_LOCAL, 8348 bytes)
20/04/13 22:27:04 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 64.227.70.177:39847 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:27:04 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.197.156:42931 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:27:04 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 178.62.197.156:44225 (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 328 ms on 64.227.70.177 (executor 2) (1/9)
20/04/13 22:27:04 INFO storage.BlockManagerInfo: Added rdd_4_2 in memory on 64.227.70.177:39847 (size: 32.6 MB, free: 3.0 GB)
20/04/13 22:27:04 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 610 ms on 64.227.70.177 (executor 2) (2/9)
20/04/13 22:27:05 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.197.156:42931 (size: 32.5 KB, free: 3.0 GB)
20/04/13 22:27:05 INFO storage.BlockManagerInfo: Added rdd_4_5 in memory on 64.227.70.177:39847 (size: 33.8 MB, free: 2.9 GB)
20/04/13 22:27:05 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 2.0 (TID 7) in 721 ms on 64.227.70.177 (executor 2) (3/9)
20/04/13 22:27:05 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.197.156:44225 (size: 32.5 KB, free: 3.0 GB)
20/04/13 22:27:06 INFO storage.BlockManagerInfo: Added rdd_4_7 in memory on 178.62.197.156:42931 (size: 33.4 MB, free: 3.0 GB)
20/04/13 22:27:06 INFO storage.BlockManagerInfo: Added rdd_4_4 in memory on 178.62.197.156:42931 (size: 33.1 MB, free: 3.0 GB)
20/04/13 22:27:06 INFO storage.BlockManagerInfo: Added rdd_4_1 in memory on 178.62.197.156:42931 (size: 32.6 MB, free: 2.9 GB)
20/04/13 22:27:07 INFO storage.BlockManagerInfo: Added rdd_4_8 in memory on 178.62.197.156:44225 (size: 1296.6 KB, free: 3.0 GB)
20/04/13 22:27:08 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 2.0 (TID 9) in 3948 ms on 178.62.197.156 (executor 1) (4/9)
20/04/13 22:27:08 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 2.0 (TID 6) in 3957 ms on 178.62.197.156 (executor 1) (5/9)
20/04/13 22:27:08 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 3967 ms on 178.62.197.156 (executor 1) (6/9)
20/04/13 22:27:08 INFO storage.BlockManagerInfo: Added rdd_4_6 in memory on 178.62.197.156:44225 (size: 33.8 MB, free: 3.0 GB)
20/04/13 22:27:08 INFO storage.BlockManagerInfo: Added rdd_4_3 in memory on 178.62.197.156:44225 (size: 32.5 MB, free: 3.0 GB)
20/04/13 22:27:08 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 2.0 (TID 10) in 4529 ms on 178.62.197.156 (executor 3) (7/9)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 2.0 (TID 8) in 4710 ms on 178.62.197.156 (executor 3) (8/9)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 4718 ms on 178.62.197.156 (executor 3) (9/9)
20/04/13 22:27:09 INFO cluster.YarnClusterScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/04/13 22:27:09 INFO scheduler.DAGScheduler: ResultStage 2 (takeSample at GaussianMixture.scala:470) finished in 4.725 s
20/04/13 22:27:09 INFO scheduler.DAGScheduler: Job 2 finished: takeSample at GaussianMixture.scala:470, took 4.731352 s
20/04/13 22:27:09 INFO spark.SparkContext: Starting job: takeSample at GaussianMixture.scala:470
20/04/13 22:27:09 INFO scheduler.DAGScheduler: Got job 3 (takeSample at GaussianMixture.scala:470) with 9 output partitions
20/04/13 22:27:09 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (takeSample at GaussianMixture.scala:470)
20/04/13 22:27:09 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/04/13 22:27:09 INFO scheduler.DAGScheduler: Missing parents: List()
20/04/13 22:27:09 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (PartitionwiseSampledRDD[18] at takeSample at GaussianMixture.scala:470), which has no missing parents
20/04/13 22:27:09 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 38.4 KB, free 3.0 GB)
20/04/13 22:27:09 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.5 KB, free 3.0 GB)
20/04/13 22:27:09 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 64.227.70.177:38753 (size: 18.5 KB, free: 3.0 GB)
20/04/13 22:27:09 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1163
20/04/13 22:27:09 INFO scheduler.DAGScheduler: Submitting 9 missing tasks from ResultStage 3 (PartitionwiseSampledRDD[18] at takeSample at GaussianMixture.scala:470) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))
20/04/13 22:27:09 INFO cluster.YarnClusterScheduler: Adding task set 3.0 with 9 tasks
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 11, 64.227.70.177, executor 2, partition 0, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 3.0 (TID 12, 178.62.197.156, executor 3, partition 3, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 13, 178.62.197.156, executor 1, partition 1, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 3.0 (TID 14, 64.227.70.177, executor 2, partition 2, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 3.0 (TID 15, 178.62.197.156, executor 3, partition 6, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 3.0 (TID 16, 178.62.197.156, executor 1, partition 4, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 3.0 (TID 17, 64.227.70.177, executor 2, partition 5, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 3.0 (TID 18, 178.62.197.156, executor 3, partition 8, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 3.0 (TID 19, 178.62.197.156, executor 1, partition 7, PROCESS_LOCAL, 8457 bytes)
20/04/13 22:27:09 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.197.156:42931 (size: 18.5 KB, free: 2.9 GB)
20/04/13 22:27:09 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 64.227.70.177:39847 (size: 18.5 KB, free: 2.9 GB)
20/04/13 22:27:09 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 178.62.197.156:44225 (size: 18.5 KB, free: 3.0 GB)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 3.0 (TID 18) in 128 ms on 178.62.197.156 (executor 3) (1/9)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 11) in 146 ms on 64.227.70.177 (executor 2) (2/9)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 3.0 (TID 14) in 147 ms on 64.227.70.177 (executor 2) (3/9)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 3.0 (TID 17) in 152 ms on 64.227.70.177 (executor 2) (4/9)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 13) in 183 ms on 178.62.197.156 (executor 1) (5/9)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 3.0 (TID 16) in 185 ms on 178.62.197.156 (executor 1) (6/9)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 3.0 (TID 15) in 189 ms on 178.62.197.156 (executor 3) (7/9)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 3.0 (TID 19) in 196 ms on 178.62.197.156 (executor 1) (8/9)
20/04/13 22:27:09 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 3.0 (TID 12) in 209 ms on 178.62.197.156 (executor 3) (9/9)
20/04/13 22:27:09 INFO cluster.YarnClusterScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/04/13 22:27:09 INFO scheduler.DAGScheduler: ResultStage 3 (takeSample at GaussianMixture.scala:470) finished in 0.214 s
20/04/13 22:27:09 INFO scheduler.DAGScheduler: Job 3 finished: takeSample at GaussianMixture.scala:470, took 0.217851 s
20/04/13 22:27:09 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
20/04/13 22:27:09 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 89
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 74
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 35
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 69
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 72
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 96
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 66
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 93
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 103
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 99
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 54
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 53
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 83
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 34
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 38
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 81
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 88
20/04/13 22:27:10 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 178.62.197.156:42931 in memory (size: 18.5 KB, free: 2.9 GB)
20/04/13 22:27:10 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 178.62.197.156:44225 in memory (size: 18.5 KB, free: 3.0 GB)
20/04/13 22:27:10 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 64.227.70.177:38753 in memory (size: 18.5 KB, free: 3.0 GB)
20/04/13 22:27:10 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 64.227.70.177:39847 in memory (size: 18.5 KB, free: 2.9 GB)
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 79
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 101
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 92
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 43
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 40
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 71
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 98
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 73
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 62
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 39
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 90
20/04/13 22:27:10 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 64.227.70.177:38753 in memory (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:27:10 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 178.62.197.156:42931 in memory (size: 9.7 KB, free: 2.9 GB)
20/04/13 22:27:10 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 178.62.197.156:44225 in memory (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:27:10 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 64.227.70.177:39847 in memory (size: 9.7 KB, free: 2.9 GB)
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 47
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 56
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 85
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 46
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 70
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 58
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 57
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 104
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 51
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 64
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 37
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 76
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 110
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 50
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 97
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 36
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 107
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 65
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 63
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 108
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 87
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 61
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 75
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 78
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 102
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 67
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 109
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 41
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 86
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 105
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 68
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 94
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 52
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 48
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 80
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 42
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 77
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 82
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 55
20/04/13 22:27:10 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 64.227.70.177:38753 in memory (size: 9.7 KB, free: 3.0 GB)
20/04/13 22:27:10 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 64.227.70.177:39847 in memory (size: 9.7 KB, free: 2.9 GB)
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 106
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 45
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 100
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 91
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 95
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 84
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 44
20/04/13 22:27:10 INFO spark.ContextCleaner: Cleaned accumulator 49
20/04/13 22:27:10 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 3.0 GB)
20/04/13 22:27:10 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 3.0 GB)
20/04/13 22:27:10 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 64.227.70.177:38753 (size: 85.0 B, free: 3.0 GB)
20/04/13 22:27:10 INFO spark.SparkContext: Created broadcast 5 from broadcast at GaussianMixture.scala:379
20/04/13 22:27:10 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 551.7 MB, free 2.5 GB)
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.7 MB, free 2.5 GB)
20/04/13 22:27:11 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 64.227.70.177:38753 (size: 2.7 MB, free: 3.0 GB)
20/04/13 22:27:11 INFO spark.SparkContext: Created broadcast 6 from broadcast at GaussianMixture.scala:380
20/04/13 22:27:11 INFO spark.SparkContext: Starting job: treeAggregate at GaussianMixture.scala:384
20/04/13 22:27:11 INFO scheduler.DAGScheduler: Registering RDD 20 (treeAggregate at GaussianMixture.scala:384) as input to shuffle 0
20/04/13 22:27:11 INFO scheduler.DAGScheduler: Got job 4 (treeAggregate at GaussianMixture.scala:384) with 3 output partitions
20/04/13 22:27:11 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeAggregate at GaussianMixture.scala:384)
20/04/13 22:27:11 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
20/04/13 22:27:11 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 4)
20/04/13 22:27:11 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at treeAggregate at GaussianMixture.scala:384), which has no missing parents
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 2.5 GB)
20/04/13 22:27:11 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.3 KB, free 2.5 GB)
20/04/13 22:27:11 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 64.227.70.177:38753 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:27:11 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1163
20/04/13 22:27:11 INFO scheduler.DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at treeAggregate at GaussianMixture.scala:384) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))
20/04/13 22:27:11 INFO cluster.YarnClusterScheduler: Adding task set 4.0 with 9 tasks
20/04/13 22:27:11 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 4.0 (TID 20, 178.62.197.156, executor 3, partition 3, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:27:11 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, 178.62.197.156, executor 1, partition 1, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:27:11 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 22, 64.227.70.177, executor 2, partition 0, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:27:11 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 4.0 (TID 23, 178.62.197.156, executor 3, partition 6, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:27:11 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, 178.62.197.156, executor 1, partition 4, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:27:11 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 4.0 (TID 25, 64.227.70.177, executor 2, partition 2, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:27:11 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 4.0 (TID 26, 178.62.197.156, executor 3, partition 8, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:27:11 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 4.0 (TID 27, 178.62.197.156, executor 1, partition 7, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:27:11 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 4.0 (TID 28, 64.227.70.177, executor 2, partition 5, PROCESS_LOCAL, 8337 bytes)
20/04/13 22:27:11 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 178.62.197.156:42931 (size: 11.3 KB, free: 2.9 GB)
20/04/13 22:27:11 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 64.227.70.177:39847 (size: 11.3 KB, free: 2.9 GB)
20/04/13 22:27:11 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 178.62.197.156:44225 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:27:11 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 64.227.70.177:39847 (size: 85.0 B, free: 2.9 GB)
20/04/13 22:27:11 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 64.227.70.177:39847 (size: 2.7 MB, free: 2.9 GB)
20/04/13 22:27:11 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.197.156:44225 (size: 85.0 B, free: 3.0 GB)
20/04/13 22:27:11 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.197.156:42931 (size: 85.0 B, free: 2.9 GB)
20/04/13 22:27:11 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.197.156:44225 (size: 2.7 MB, free: 3.0 GB)
20/04/13 22:27:11 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.197.156:42931 (size: 2.7 MB, free: 2.9 GB)
20/04/13 22:27:17 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 2.
20/04/13 22:27:17 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 0)
20/04/13 22:27:17 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
20/04/13 22:27:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_2 !
20/04/13 22:27:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_0 !
20/04/13 22:27:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_5 !
20/04/13 22:27:17 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, 64.227.70.177, 39847, None)
20/04/13 22:27:17 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor
20/04/13 22:27:17 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 2 (epoch 0)
20/04/13 22:27:17 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_02_000003 on host: 64.227.70.177 (state: COMPLETE, exit status: 143)
20/04/13 22:27:17 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_02_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:17 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 2 for reason Container from a bad node: container_1586815278733_0007_02_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:17 ERROR cluster.YarnClusterScheduler: Lost executor 2 on 64.227.70.177: Container from a bad node: container_1586815278733_0007_02_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:17 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 4.0 (TID 22, 64.227.70.177, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:17 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 4.0 (TID 25, 64.227.70.177, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:17 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 4.0 (TID 28, 64.227.70.177, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000003 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:17 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
20/04/13 22:27:17 INFO storage.BlockManagerMaster: Removal of executor 2 requested
20/04/13 22:27:17 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 2
20/04/13 22:27:18 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 3.
20/04/13 22:27:18 INFO scheduler.DAGScheduler: Executor lost: 3 (epoch 1)
20/04/13 22:27:18 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/13 22:27:18 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
20/04/13 22:27:18 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_8 !
20/04/13 22:27:18 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_3 !
20/04/13 22:27:18 INFO yarn.YarnAllocator: Submitted 1 unlocalized container requests.
20/04/13 22:27:18 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_6 !
20/04/13 22:27:18 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(3, 178.62.197.156, 44225, None)
20/04/13 22:27:18 INFO storage.BlockManagerMaster: Removed 3 successfully in removeExecutor
20/04/13 22:27:18 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 3 (epoch 1)
20/04/13 22:27:18 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_02_000005 on host 178.62.197.156 for executor with ID 4
20/04/13 22:27:18 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/13 22:27:18 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_02_000004 on host: 178.62.197.156 (state: COMPLETE, exit status: 143)
20/04/13 22:27:18 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_02_000004 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:18 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:27:18 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 3 for reason Container from a bad node: container_1586815278733_0007_02_000004 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:18 ERROR cluster.YarnClusterScheduler: Lost executor 3 on 178.62.197.156: Container from a bad node: container_1586815278733_0007_02_000004 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:18 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 4.0 (TID 23, 178.62.197.156, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000004 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:18 WARN scheduler.TaskSetManager: Lost task 8.0 in stage 4.0 (TID 26, 178.62.197.156, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000004 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:18 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 4.0 (TID 20, 178.62.197.156, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000004 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:18 INFO storage.BlockManagerMaster: Removal of executor 3 requested
20/04/13 22:27:18 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
20/04/13 22:27:18 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 3
20/04/13 22:27:19 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 1.
20/04/13 22:27:19 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/13 22:27:19 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 2)
20/04/13 22:27:19 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
20/04/13 22:27:19 INFO yarn.YarnAllocator: Submitted 1 unlocalized container requests.
20/04/13 22:27:19 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_4 !
20/04/13 22:27:19 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_7 !
20/04/13 22:27:19 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_1 !
20/04/13 22:27:19 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 178.62.197.156, 42931, None)
20/04/13 22:27:19 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor
20/04/13 22:27:19 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 1 (epoch 2)
20/04/13 22:27:19 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_02_000006 on host 178.62.197.156 for executor with ID 5
20/04/13 22:27:19 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/13 22:27:19 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_02_000002 on host: 178.62.197.156 (state: COMPLETE, exit status: 143)
20/04/13 22:27:19 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_02_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:19 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:27:19 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 1 for reason Container from a bad node: container_1586815278733_0007_02_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:19 ERROR cluster.YarnClusterScheduler: Lost executor 1 on 178.62.197.156: Container from a bad node: container_1586815278733_0007_02_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:19 WARN scheduler.TaskSetManager: Lost task 7.0 in stage 4.0 (TID 27, 178.62.197.156, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:19 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 4.0 (TID 21, 178.62.197.156, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:19 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 4.0 (TID 24, 178.62.197.156, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000002 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:19 INFO storage.BlockManagerMaster: Removal of executor 1 requested
20/04/13 22:27:19 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
20/04/13 22:27:19 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 1
20/04/13 22:27:20 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.197.156:54882) with ID 4
20/04/13 22:27:20 INFO scheduler.TaskSetManager: Starting task 4.1 in stage 4.0 (TID 29, 178.62.197.156, executor 4, partition 4, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:20 INFO scheduler.TaskSetManager: Starting task 1.1 in stage 4.0 (TID 30, 178.62.197.156, executor 4, partition 1, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:20 INFO scheduler.TaskSetManager: Starting task 7.1 in stage 4.0 (TID 31, 178.62.197.156, executor 4, partition 7, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:20 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.197.156:43885 with 3.0 GB RAM, BlockManagerId(4, 178.62.197.156, 43885, None)
20/04/13 22:27:20 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 178.62.197.156:43885 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:27:21 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.197.156:43885 (size: 32.5 KB, free: 3.0 GB)
20/04/13 22:27:21 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.197.156:54890) with ID 5
20/04/13 22:27:21 INFO scheduler.TaskSetManager: Starting task 3.1 in stage 4.0 (TID 32, 178.62.197.156, executor 5, partition 3, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:21 INFO scheduler.TaskSetManager: Starting task 8.1 in stage 4.0 (TID 33, 178.62.197.156, executor 5, partition 8, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:21 INFO scheduler.TaskSetManager: Starting task 6.1 in stage 4.0 (TID 34, 178.62.197.156, executor 5, partition 6, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:21 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.197.156:39129 with 3.0 GB RAM, BlockManagerId(5, 178.62.197.156, 39129, None)
20/04/13 22:27:22 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 178.62.197.156:39129 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:27:22 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/13 22:27:22 INFO yarn.YarnAllocator: Submitted 1 unlocalized container requests.
20/04/13 22:27:22 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.197.156:39129 (size: 32.5 KB, free: 3.0 GB)
20/04/13 22:27:24 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_02_000007 on host 64.227.70.177 for executor with ID 6
20/04/13 22:27:24 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/13 22:27:24 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:27:24 INFO storage.BlockManagerInfo: Added rdd_4_1 in memory on 178.62.197.156:43885 (size: 32.6 MB, free: 3.0 GB)
20/04/13 22:27:24 INFO storage.BlockManagerInfo: Added rdd_4_4 in memory on 178.62.197.156:43885 (size: 33.1 MB, free: 3.0 GB)
20/04/13 22:27:24 INFO storage.BlockManagerInfo: Added rdd_4_7 in memory on 178.62.197.156:43885 (size: 33.4 MB, free: 2.9 GB)
20/04/13 22:27:24 INFO storage.BlockManagerInfo: Added rdd_4_8 in memory on 178.62.197.156:39129 (size: 1296.6 KB, free: 3.0 GB)
20/04/13 22:27:25 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.197.156:43885 (size: 85.0 B, free: 2.9 GB)
20/04/13 22:27:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.197.156:43885 (size: 2.7 MB, free: 2.9 GB)
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 1
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 25
20/04/13 22:27:25 INFO storage.BlockManagerInfo: Added rdd_4_6 in memory on 178.62.197.156:39129 (size: 33.8 MB, free: 3.0 GB)
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 20
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 2
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 3
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 23
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 24
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 16
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 11
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 5
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 21
20/04/13 22:27:25 INFO storage.BlockManagerInfo: Added rdd_4_3 in memory on 178.62.197.156:39129 (size: 32.5 MB, free: 3.0 GB)
20/04/13 22:27:25 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 64.227.70.177:38753 in memory (size: 33.1 KB, free: 3.0 GB)
20/04/13 22:27:25 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (64.227.70.177:55026) with ID 6
20/04/13 22:27:25 INFO scheduler.TaskSetManager: Starting task 5.1 in stage 4.0 (TID 35, 64.227.70.177, executor 6, partition 5, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:25 INFO scheduler.TaskSetManager: Starting task 2.1 in stage 4.0 (TID 36, 64.227.70.177, executor 6, partition 2, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:25 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 4.0 (TID 37, 64.227.70.177, executor 6, partition 0, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:25 INFO storage.BlockManagerMasterEndpoint: Registering block manager 64.227.70.177:39225 with 3.0 GB RAM, BlockManagerId(6, 64.227.70.177, 39225, None)
20/04/13 22:27:25 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 64.227.70.177:39225 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 17
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 6
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 14
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 18
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 10
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 15
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 9
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 4
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 22
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 7
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 19
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 8
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 12
20/04/13 22:27:25 INFO spark.ContextCleaner: Cleaned accumulator 13
20/04/13 22:27:26 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 178.62.197.156:39129 (size: 85.0 B, free: 3.0 GB)
20/04/13 22:27:26 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 178.62.197.156:39129 (size: 2.7 MB, free: 3.0 GB)
20/04/13 22:27:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 64.227.70.177:39225 (size: 32.5 KB, free: 3.0 GB)
20/04/13 22:27:28 INFO storage.BlockManagerInfo: Added rdd_4_0 in memory on 64.227.70.177:39225 (size: 32.6 MB, free: 3.0 GB)
20/04/13 22:27:28 INFO storage.BlockManagerInfo: Added rdd_4_5 in memory on 64.227.70.177:39225 (size: 33.8 MB, free: 3.0 GB)
20/04/13 22:27:28 INFO storage.BlockManagerInfo: Added rdd_4_2 in memory on 64.227.70.177:39225 (size: 32.6 MB, free: 2.9 GB)
20/04/13 22:27:29 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 64.227.70.177:39225 (size: 85.0 B, free: 2.9 GB)
20/04/13 22:27:29 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 64.227.70.177:39225 (size: 2.7 MB, free: 2.9 GB)
20/04/13 22:27:33 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 4.
20/04/13 22:27:33 INFO scheduler.DAGScheduler: Executor lost: 4 (epoch 3)
20/04/13 22:27:33 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
20/04/13 22:27:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_4 !
20/04/13 22:27:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_7 !
20/04/13 22:27:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_1 !
20/04/13 22:27:33 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(4, 178.62.197.156, 43885, None)
20/04/13 22:27:33 INFO storage.BlockManagerMaster: Removed 4 successfully in removeExecutor
20/04/13 22:27:33 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 4 (epoch 3)
20/04/13 22:27:33 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_02_000005 on host: 178.62.197.156 (state: COMPLETE, exit status: 143)
20/04/13 22:27:33 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_02_000005 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:33 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 4 for reason Container from a bad node: container_1586815278733_0007_02_000005 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:33 ERROR cluster.YarnClusterScheduler: Lost executor 4 on 178.62.197.156: Container from a bad node: container_1586815278733_0007_02_000005 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:33 WARN scheduler.TaskSetManager: Lost task 4.1 in stage 4.0 (TID 29, 178.62.197.156, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000005 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:33 WARN scheduler.TaskSetManager: Lost task 7.1 in stage 4.0 (TID 31, 178.62.197.156, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000005 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:33 WARN scheduler.TaskSetManager: Lost task 1.1 in stage 4.0 (TID 30, 178.62.197.156, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000005 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:33 INFO storage.BlockManagerMaster: Removal of executor 4 requested
20/04/13 22:27:33 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 4
20/04/13 22:27:33 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
20/04/13 22:27:35 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 5.
20/04/13 22:27:35 INFO scheduler.DAGScheduler: Executor lost: 5 (epoch 4)
20/04/13 22:27:35 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 3 core(s) and 6758 MB memory (including 614 MB of overhead)
20/04/13 22:27:35 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 5 from BlockManagerMaster.
20/04/13 22:27:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_8 !
20/04/13 22:27:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_3 !
20/04/13 22:27:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_6 !
20/04/13 22:27:35 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(5, 178.62.197.156, 39129, None)
20/04/13 22:27:35 INFO storage.BlockManagerMaster: Removed 5 successfully in removeExecutor
20/04/13 22:27:35 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 5 (epoch 4)
20/04/13 22:27:35 INFO yarn.YarnAllocator: Submitted 1 unlocalized container requests.
20/04/13 22:27:35 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 6.
20/04/13 22:27:35 INFO scheduler.DAGScheduler: Executor lost: 6 (epoch 5)
20/04/13 22:27:35 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 6 from BlockManagerMaster.
20/04/13 22:27:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_2 !
20/04/13 22:27:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_0 !
20/04/13 22:27:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_4_5 !
20/04/13 22:27:35 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(6, 64.227.70.177, 39225, None)
20/04/13 22:27:35 INFO storage.BlockManagerMaster: Removed 6 successfully in removeExecutor
20/04/13 22:27:35 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 6 (epoch 5)
20/04/13 22:27:35 INFO yarn.YarnAllocator: Launching container container_1586815278733_0007_02_000008 on host 178.62.197.156 for executor with ID 7
20/04/13 22:27:35 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/04/13 22:27:35 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_02_000007 on host: 64.227.70.177 (state: COMPLETE, exit status: 143)
20/04/13 22:27:35 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_02_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
20/04/13 22:27:35 INFO yarn.YarnAllocator: Completed container container_1586815278733_0007_02_000006 on host: 178.62.197.156 (state: COMPLETE, exit status: 143)
20/04/13 22:27:35 WARN yarn.YarnAllocator: Container from a bad node: container_1586815278733_0007_02_000006 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 6 for reason Container from a bad node: container_1586815278733_0007_02_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 5 for reason Container from a bad node: container_1586815278733_0007_02_000006 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 ERROR cluster.YarnClusterScheduler: Lost executor 6 on 64.227.70.177: Container from a bad node: container_1586815278733_0007_02_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 WARN scheduler.TaskSetManager: Lost task 5.1 in stage 4.0 (TID 35, 64.227.70.177, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 4.0 (TID 37, 64.227.70.177, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 WARN scheduler.TaskSetManager: Lost task 2.1 in stage 4.0 (TID 36, 64.227.70.177, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000007 on host: 64.227.70.177. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 ERROR cluster.YarnClusterScheduler: Lost executor 5 on 178.62.197.156: Container from a bad node: container_1586815278733_0007_02_000006 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 WARN scheduler.TaskSetManager: Lost task 3.1 in stage 4.0 (TID 32, 178.62.197.156, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000006 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 WARN scheduler.TaskSetManager: Lost task 6.1 in stage 4.0 (TID 34, 178.62.197.156, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000006 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 WARN scheduler.TaskSetManager: Lost task 8.1 in stage 4.0 (TID 33, 178.62.197.156, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1586815278733_0007_02_000006 on host: 178.62.197.156. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal
.
20/04/13 22:27:35 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 6 from BlockManagerMaster.
20/04/13 22:27:35 INFO storage.BlockManagerMaster: Removal of executor 6 requested
20/04/13 22:27:35 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 6
20/04/13 22:27:35 INFO storage.BlockManagerMaster: Removal of executor 5 requested
20/04/13 22:27:35 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 5
20/04/13 22:27:35 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 5 from BlockManagerMaster.
20/04/13 22:27:36 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (178.62.197.156:54924) with ID 7
20/04/13 22:27:36 INFO scheduler.TaskSetManager: Starting task 8.2 in stage 4.0 (TID 38, 178.62.197.156, executor 7, partition 8, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:36 INFO scheduler.TaskSetManager: Starting task 6.2 in stage 4.0 (TID 39, 178.62.197.156, executor 7, partition 6, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:36 INFO scheduler.TaskSetManager: Starting task 3.2 in stage 4.0 (TID 40, 178.62.197.156, executor 7, partition 3, NODE_LOCAL, 8337 bytes)
20/04/13 22:27:37 INFO storage.BlockManagerMasterEndpoint: Registering block manager 178.62.197.156:40191 with 3.0 GB RAM, BlockManagerId(7, 178.62.197.156, 40191, None)
20/04/13 22:27:37 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 178.62.197.156:40191 (size: 11.3 KB, free: 3.0 GB)
20/04/13 22:27:37 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 178.62.197.156:40191 (size: 32.5 KB, free: 3.0 GB)
20/04/13 22:27:38 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (6) reached)
20/04/13 22:27:38 INFO spark.SparkContext: Invoking stop() from shutdown hook
20/04/13 22:27:38 INFO server.AbstractConnector: Stopped Spark@535570b2{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
20/04/13 22:27:38 INFO ui.SparkUI: Stopped Spark web UI at http://64.227.70.177:38283
20/04/13 22:27:38 INFO scheduler.DAGScheduler: Job 4 failed: treeAggregate at GaussianMixture.scala:384, took 27.016484 s
20/04/13 22:27:38 INFO scheduler.DAGScheduler: ShuffleMapStage 4 (treeAggregate at GaussianMixture.scala:384) failed in 27.007 s due to Stage cancelled because SparkContext was shut down
20/04/13 22:27:38 ERROR util.Instrumentation: org.apache.spark.SparkException: Job 4 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:933)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:931)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:931)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2130)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2043)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1143)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.fold(RDD.scala:1137)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1206)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1182)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1.apply(GaussianMixture.scala:384)
	at org.apache.spark.ml.clustering.GaussianMixture$$anonfun$fit$1.apply(GaussianMixture.scala:340)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.clustering.GaussianMixture.fit(GaussianMixture.scala:340)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)

20/04/13 22:27:38 INFO yarn.YarnAllocator: Driver requested a total number of 0 executor(s).
20/04/13 22:27:38 INFO cluster.YarnClusterSchedulerBackend: Shutting down all executors
20/04/13 22:27:38 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/04/13 22:27:38 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
20/04/13 22:27:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/04/13 22:27:38 INFO memory.MemoryStore: MemoryStore cleared
20/04/13 22:27:38 INFO storage.BlockManager: BlockManager stopped
20/04/13 22:27:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
20/04/13 22:27:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/04/13 22:27:38 INFO spark.SparkContext: Successfully stopped SparkContext
20/04/13 22:27:38 INFO yarn.ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Max number of executor failures (6) reached)
20/04/13 22:27:38 INFO impl.AMRMClientImpl: Waiting for application to be successfully unregistered.
20/04/13 22:27:38 INFO yarn.ApplicationMaster: Deleting staging directory hdfs://178.62.197.108:9000/user/root/.sparkStaging/application_1586815278733_0007
20/04/13 22:27:38 INFO util.ShutdownHookManager: Shutdown hook called
20/04/13 22:27:38 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/spark-1f1bebb1-b2a4-445e-b952-ec016f728fb9
20/04/13 22:27:38 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1586815278733_0007/spark-1f1bebb1-b2a4-445e-b952-ec016f728fb9/pyspark-93ef145a-f69d-492d-8322-5f6a14bc3d4b
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Apr 13 22:27:39 +0000 2020
LogLength:1474
Log Contents:
Traceback (most recent call last):
  File "clustering.py", line 293, in <module>
    result_dfs_list=result_dfs,
  File "clustering.py", line 54, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 72, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 255, in perform_experiment
    result_df = perform_clustering_gaussian(in_file=in_file, k=k)
  File "clustering.py", line 191, in perform_clustering_gaussian
    model = fit(model_algo, df)
  File "clustering.py", line 54, in wrapper
    ret = func(*args, **kwargs)
  File "clustering.py", line 80, in fit
    model = model_algo.fit(df)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/ml/base.py", line 132, in fit
    return self._fit(dataset)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/ml/wrapper.py", line 295, in _fit
    java_model = self._fit_java(dataset)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/ml/wrapper.py", line 292, in _fit_java
    return self._java_obj.fit(dataset._jdf)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/usr/src/spark-2.4.5-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 336, in get_return_value
py4j.protocol.Py4JError: An error occurred while calling o48.fit
End of LogType:stdout

