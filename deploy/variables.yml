# variables shared by all plays in the playbook.yml
apache_download_proxy: "http://ftp.man.poznan.pl/apache"
prefix: "/usr/src"
hadoop_version: "hadoop-2.8.5"
spark_version: "spark-2.4.5"
paths:
  java: "/usr/lib/jvm/java-8-openjdk-amd64"
  hadoop: "{{ prefix }}/{{ hadoop_version }}"
  hdfs: "/hdfsdata"
  spark: "{{ prefix }}/{{ spark_version }}-bin-without-hadoop"
  jupyter_notebooks: "{{ prefix }}/notebooks"
# https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.6.4/bk_command-line-installation/content/determine-hdp-memory-config.html
# https://www.alibabacloud.com/help/doc-detail/28124.htm
# or even better: https://c2fo.io/c2fo/spark/aws/emr/2016/07/06/apache-spark-config-cheatsheet/
# node_config:  # for slaves: 2x C-2 droplet
#   mapreduce_map_memory: 3072
#   mapreduce_map_java_heapsize: 2560  # ~80% of mapreduce_map_memory
#   mapreduce_reduce_memory: 6144
#   mapreduce_reduce_java_heap_size: 5120  # ~80% of mapreduce_reduce_memory
#   yarn_resource_memory: 7168
#   yarn_scheduler_min_allocation_memory: 512
#   yarn_scheduler_max_allocation_memory: 7168
#   spark_submit_driver_memory: "2g"
#   spark_submit_executor_memory: "1g"
#   spark_submit_executor_cores: "2"
#   spark_submit_num_executors: "2"
# node_config:  # for slaves: 2x C-4 droplet
#   mapreduce_map_memory: 7168
#   mapreduce_map_java_heapsize: 6144  # ~80% of mapreduce_map_memory
#   mapreduce_reduce_memory: 14336
#   mapreduce_reduce_java_heap_size: 12288  # ~80% of mapreduce_reduce_memory
#   yarn_resource_memory: 15360
#   yarn_scheduler_min_allocation_memory: 1024
#   yarn_scheduler_max_allocation_memory: 15360
#   spark_submit_driver_memory: "2g"
#   spark_submit_executor_memory: "3g"
#   spark_submit_executor_cores: "2"
#   spark_submit_num_executors: "3"
node_config:  # for slaves: 2x C-8 droplet
  mapreduce_map_memory: 9216
  mapreduce_map_java_heapsize: 7372  # ~80% of mapreduce_map_memory
  mapreduce_reduce_memory: 9216
  mapreduce_reduce_java_heap_size: 7372  # ~80% of mapreduce_reduce_memory
  yarn_resource_memory: 15360
  yarn_scheduler_min_allocation_memory: 4096
  yarn_scheduler_max_allocation_memory: 12288
  spark_submit_driver_memory: "6g"
  spark_submit_driver_cores: "3"
  spark_submit_executor_memory: "6g"
  spark_submit_executor_cores: "3"
  spark_submit_num_executors: "3"

# Num Container=3
#  Container Ram=4608MB
#  Used Ram=13GB
#  Unused Ram=2GB
#  yarn.scheduler.minimum-allocation-mb=4608
#  yarn.scheduler.maximum-allocation-mb=13824
#  yarn.nodemanager.resource.memory-mb=13824
#  mapreduce.map.memory.mb=4608
#  mapreduce.map.java.opts=-Xmx3686m
#  mapreduce.reduce.memory.mb=4608
#  mapreduce.reduce.java.opts=-Xmx3686m
#  yarn.app.mapreduce.am.resource.mb=4608
#  yarn.app.mapreduce.am.command-opts=-Xmx3686m
#  mapreduce.task.io.sort.mb=1843
