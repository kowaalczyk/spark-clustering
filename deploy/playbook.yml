# install hadoop
- hosts: all
  become: yes
  vars_files:
    - variables.yml
  vars:
    master_host: "{{ groups['master'][0] }}"
    slaves: "{{ groups['slaves'] }}"
  environment:
    JAVA_HOME: "{{ paths.java }}"
    HADOOP_HOME: "{{ paths.hadoop }}"
    HADOOP_PREFIX: "{{ paths.hadoop }}"
    HADOOP_INSTALL: "{{ paths.hadoop }}"
    HADOOP_MAPRED_HOME: "{{ paths.hadoop }}"
    HADOOP_COMMON_HOME: "{{ paths.hadoop }}"
    HADOOP_HDFS_HOME: "{{ paths.hadoop }}"
    YARN_HOME: "{{ paths.hadoop }}"
    HADOOP_COMMON_LIB_NATIVE_DIR: "{{ paths.hadoop }}/lib/native"
    HADOOP_OPTS: "-Djava.library.path={{ paths.hadoop }}/lib/native"
    PATH: "{{ ansible_env.PATH }}:{{ paths.hadoop }}/sbin:{{ paths.hadoop }}/bin"
  tasks:
    - name: Set hostname to prevent yarn nodemanager connection errors
      hostname:
        name: "{{ inventory_hostname }}"
    - name: Install ssh server
      apt:
        name: openssh-server
        state: present
        update_cache: yes
    - name: Copy ssh config
      copy:
        src: "all/ssh/config"
        dest: "~/.ssh/config"
    - name: Install java
      apt:
        name: openjdk-8-jdk
        state: present
        update_cache: yes
    - name: Download & extract Hadoop
      unarchive:
        remote_src: yes
        src: "{{ apache_download_proxy }}/hadoop/common/{{ hadoop_version }}/{{ hadoop_version }}.tar.gz"
        dest: "{{ prefix }}"
        creates: "{{ paths.hadoop }}"
    - name: Create directories for NameNode and DataNode
      file:
        path: "{{ paths.hdfs }}/{{ item }}"
        state: directory
        mode: "0755"
      with_items:
        - "namenode"
        - "datanode"
    - name: Create hadoop config files
      template:
        src: "all/hadoop/{{ item }}.j2"
        dest: "{{ paths.hadoop }}/etc/hadoop/{{ item }}"
      with_items:
        - "hadoop-env.sh"
        - "core-site.xml"
        - "hdfs-site.xml"
        - "mapred-site.xml"
        - "yarn-site.xml"
        - "slaves"

# generate ssh key for hadoop
- hosts: master
  become: yes
  vars_files:
    - variables.yml
  tasks:
    - name: Generate ssh key pair
      openssh_keypair:
        path: "~/.ssh/id_rsa"
      register: ssh_key

# configure access between nodes
- hosts: all
  become: yes
  vars:
    master_host: "{{ groups['master'][0] }}"
  vars_files:
    - variables.yml
  tasks:
    - name: Add master key to authorized keys
      authorized_key:
        user: root
        key: "{{ hostvars[master_host]['ssh_key']['public_key'] }}"
    - name: Enable firewall with ssh
      ufw:
        rule: allow
        port: ssh
        state: enabled
    - name: Restart ssh server with new config
      service:
        name: ssh
        state: restarted
- hosts: master
  become: yes
  vars:
    master_host: "{{ groups['master'][0] }}"
    slave_hosts: "{{ groups['slaves'] }}"
  tasks:
    - name: Open GUI ports to the public
      ufw:
        rule: allow
        port: "{{ item }}"
        proto: tcp
        state: reloaded
      with_items:
        - "8888"  # pyspark jupyter notebook
        - "4040"  # spark ui port
        - "8088"
        - "50070"
        - "50090"
    - name: Open all ports to slaves and master
      ufw:
        rule: allow
        src: "{{ item }}"
        state: reloaded
      with_items: "{{ slave_hosts + [master_host] }}"
    - name: Debug ufw status
      command: "ufw status verbose"
      register: ufw_status
    - debug:
        var: ufw_status
- hosts: slaves
  become: yes
  vars:
    master_host: "{{ groups['master'][0] }}"
    slave_hosts: "{{ groups['slaves'] }}"
  tasks:
    - name: Open GUI ports to the public
      ufw:
        rule: allow
        port: "{{ item }}"
        proto: tcp
        state: reloaded
      with_items:
        - "50075"
    - name: Open all ports to slaves and master
      ufw:
        rule: allow
        src: "{{ item }}"
        state: reloaded
      with_items: "{{ slave_hosts + [master_host] }}"

# start hdfs
- hosts: master
  become: yes
  vars_files:
    - variables.yml
  environment:
    JAVA_HOME: "{{ paths.java }}"
    HADOOP_HOME: "{{ paths.hadoop }}"
    HADOOP_PREFIX: "{{ paths.hadoop }}"
    HADOOP_INSTALL: "{{ paths.hadoop }}"
    HADOOP_MAPRED_HOME: "{{ paths.hadoop }}"
    HADOOP_COMMON_HOME: "{{ paths.hadoop }}"
    HADOOP_HDFS_HOME: "{{ paths.hadoop }}"
    YARN_HOME: "{{ paths.hadoop }}"
    HADOOP_COMMON_LIB_NATIVE_DIR: "{{ paths.hadoop }}/lib/native"
    HADOOP_OPTS: "-Djava.library.path={{ paths.hadoop }}/lib/native"
    LD_LIBRARY_PATH: "{{ paths.hadoop }}/lib/native"
    PATH: "{{ ansible_env.PATH }}:{{ paths.hadoop }}/sbin:{{ paths.hadoop }}/bin"
  tasks:
    - name: Debug printenv
      command: printenv
      register: printenv
    - debug:
        var: printenv
    - name: Start HDFS if not running
      block:
        - name: Generate DFS Admin report
          command: "hdfs dfsadmin -report"
          register: dfsadmin_log
        - debug:
            var: dfsadmin_log.stdout_lines
      rescue:
        - name: Clear tmp
          command:
            cmd: "rm -rf /tmp/*"
            removes: "/tmp/*"
        - name: Format HDFS Namenode
          command: "hdfs namenode -format"
        - name: Start DFS
          command: start-dfs.sh
          register: dfs_log
        - debug:
            var: dfs_log.stdout_lines
        - name: Start Yarn
          command: start-yarn.sh
          register: yarn_log
        - debug:
            var: yarn_log.stdout_lines
        - pause:
            seconds: 30
        - name: Generate DFS Admin report
          command: "hdfs dfsadmin -report"
          register: dfsadmin_log
        - debug:
            var: dfsadmin_log.stdout_lines

# install python, spark and pyspark + run jupyter notebook
- hosts: master
  become: yes
  vars_files:
    - variables.yml
  environment:
    JAVA_HOME: "{{ paths.java }}"
    HADOOP_HOME: "{{ paths.hadoop }}"
    HADOOP_PREFIX: "{{ paths.hadoop }}"
    HADOOP_INSTALL: "{{ paths.hadoop }}"
    HADOOP_MAPRED_HOME: "{{ paths.hadoop }}"
    HADOOP_COMMON_HOME: "{{ paths.hadoop }}"
    HADOOP_HDFS_HOME: "{{ paths.hadoop }}"
    YARN_HOME: "{{ paths.hadoop }}"
    HADOOP_COMMON_LIB_NATIVE_DIR: "{{ paths.hadoop }}/lib/native"
    HADOOP_OPTS: "-Djava.library.path={{ paths.hadoop }}/lib/native"
    LD_LIBRARY_PATH: "{{ paths.hadoop }}/lib/native"
    PATH: "{{ ansible_env.PATH }}:~/.local/bin:{{ paths.hadoop }}/sbin:{{ paths.hadoop }}/bin"
    YARN_CONF_DIR: "{{ paths.hadoop }}/etc/hadoop"
    SPARK_HOME: "{{ paths.spark }}"
  tasks:
    - name: Download & extract Spark
      unarchive:
        remote_src: yes
        src: "{{ apache_download_proxy }}/spark/{{ spark_version }}/{{ spark_version }}-bin-without-hadoop.tgz"
        dest: "{{ prefix }}"
        creates: "{{ paths.spark }}"
    - name: Install python
      apt:
        name:
          - "python3"
          - "python3-pip"
        state: present
        update_cache: yes
    - name: Install python packages
      pip:
        executable: pip3
        name:
          - "jupyter"
          - "numpy"
          - "pandas"
          - "matplotlib"
          - "py4j"
    - name: Create workdir for jupyter
      file:
        path: "{{ paths.jupyter_notebooks }}"
        state: directory
        mode: "0755"
    - name: Get hadoop classpath
      command: "hdfs classpath"
      register: hdfs_classpath
    - name: Get environment for jupyter service
      environment:
        PATH: "{{ paths.spark }}:{{ paths.spark }}/bin:{{ ansible_env.PATH }}:{{ paths.java }}/bin:{{ paths.java }}/jre/bin"
        SPARK_DIST_CLASSPATH: "{{ hdfs_classpath.stdout }}"
        PYTHONPATH: "{{ paths.spark }}/python"  # no pre-existing PYTHONPATH
        PYSPARK_DRIVER_PYTHON: "jupyter"
        PYSPARK_DRIVER_PYTHON_OPTS: "notebook --allow-root --port=8888 --no-browser --notebook-dir={{ paths.jupyter_notebooks }} --ip=0.0.0.0"
        PYSPARK_PYTHON: "python3"
      shell: "printenv | grep 'PATH\\|SPARK\\|PYTHON\\|HADOOP\\|JAVA'"
      register: printenv
    - debug:
        var: printenv.stdout_lines
    - name: Create env file for jupyter service
      copy:
        content: '{{ printenv.stdout }}'
        dest: "/etc/systemd/system/jupyter.env"
    - name: Create jupyter service
      # https://programming.vip/docs/running-jupyter-jupyterhub-jupyterlab-as-a-system-service.html
      vars:
        # TODO: Debug these options on the larger instance (get as much ram and cores as possible)
        jupyter_cmd: "{{ paths.spark }}/bin/pyspark --master yarn --executor-cores 2 --num-executors 2 --executor-memory 3G"
      template:
        src: "master/jupyter.service.j2"
        dest: "/etc/systemd/system/jupyter.service"
    - name: Start jupyter service
      systemd:
        name: jupyter
        state: restarted
        daemon_reload: yes
        enabled: yes  # start on boot
    - pause:
        seconds: 10
    - name: Get jupyter logs with password/token
      command: "systemctl status jupyter --no-pager"
      register: jupyter_logs
    - debug:
        var: jupyter_logs.stdout_lines
    # TODO: Deploy and run the application instead:
    - name: Run spark example
      environment:
        PATH: "{{ paths.spark }}:{{ paths.spark }}/bin:{{ ansible_env.PATH }}:{{ paths.java }}/bin:{{ paths.java }}/jre/bin"
        SPARK_DIST_CLASSPATH: "{{ hdfs_classpath.stdout }}"
      script: "master/run-spark-example.sh"
      register: example
    - debug:
        var: example.stdout_lines
